{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminaries\n",
    "\n",
    "from __future__ import absolute_import, division, print_function  # Python 2/3 compatibility\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models  import Sequential, K\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set (remember to download diabetes.csv )\n",
    "diabetes_df = pd.read_csv(\"diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>7</td>\n",
       "      <td>114</td>\n",
       "      <td>76</td>\n",
       "      <td>17</td>\n",
       "      <td>110</td>\n",
       "      <td>23.8</td>\n",
       "      <td>0.466</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>7</td>\n",
       "      <td>83</td>\n",
       "      <td>78</td>\n",
       "      <td>26</td>\n",
       "      <td>71</td>\n",
       "      <td>29.3</td>\n",
       "      <td>0.767</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.022</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>9</td>\n",
       "      <td>106</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>0.380</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>86</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.143</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "477            7      114             76             17      110  23.8   \n",
       "82             7       83             78             26       71  29.3   \n",
       "464           10      115             98              0        0  24.0   \n",
       "250            9      106             52              0        0  31.2   \n",
       "249            1      111             86             19        0  30.1   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "477                     0.466   31        0  \n",
       "82                      0.767   36        0  \n",
       "464                     1.022   34        0  \n",
       "250                     0.380   42        0  \n",
       "249                     0.143   23        0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"Outcome\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.781\n",
      "roc-auc is 0.829\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\baren\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, relu activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential([\n",
    "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "Yes, since there is 96 connections (8 x 12) between the input layer and the hidden layer which also creates 12 new inputs for the next layer which equates to 108 params between the input and hidden layer. The hidden to output layer has 12 connections to each ther but also creates the final neuron which creates 13 params in total here. In total there should be 121 params.\n",
    "\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/200\n",
      "576/576 [==============================] - 0s 209us/step - loss: 0.4184 - accuracy: 0.7986 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 2/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4183 - accuracy: 0.7969 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 3/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4183 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 4/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4183 - accuracy: 0.7969 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 5/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4183 - accuracy: 0.7986 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 6/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4183 - accuracy: 0.7969 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 7/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4183 - accuracy: 0.7969 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 8/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4182 - accuracy: 0.7986 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 9/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4182 - accuracy: 0.7986 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 10/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4182 - accuracy: 0.7986 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 11/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4182 - accuracy: 0.7986 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 12/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4181 - accuracy: 0.7986 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 13/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4181 - accuracy: 0.8003 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 14/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4181 - accuracy: 0.7986 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 15/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4181 - accuracy: 0.7986 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 16/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4180 - accuracy: 0.8003 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 17/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4181 - accuracy: 0.7986 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 18/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4180 - accuracy: 0.7986 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 19/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4180 - accuracy: 0.7986 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 20/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4180 - accuracy: 0.8003 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 21/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4180 - accuracy: 0.7986 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 22/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4179 - accuracy: 0.7986 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 23/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4179 - accuracy: 0.7986 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 24/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4179 - accuracy: 0.7986 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 25/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4179 - accuracy: 0.8021 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 26/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4178 - accuracy: 0.7986 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 27/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4179 - accuracy: 0.7986 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 28/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4178 - accuracy: 0.7986 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 29/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4178 - accuracy: 0.8003 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 30/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4178 - accuracy: 0.7986 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 31/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4178 - accuracy: 0.7969 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 32/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4177 - accuracy: 0.8003 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 33/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4177 - accuracy: 0.7986 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 34/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4177 - accuracy: 0.7986 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 35/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4177 - accuracy: 0.7986 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 36/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4176 - accuracy: 0.8003 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 37/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4177 - accuracy: 0.7986 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 38/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4176 - accuracy: 0.8003 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 39/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4176 - accuracy: 0.7986 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 40/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4176 - accuracy: 0.8003 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 41/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4176 - accuracy: 0.7986 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 42/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4175 - accuracy: 0.8003 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 43/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4175 - accuracy: 0.7986 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 44/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4175 - accuracy: 0.7986 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 45/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4175 - accuracy: 0.7986 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 46/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4175 - accuracy: 0.8003 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 47/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4175 - accuracy: 0.8021 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 48/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4174 - accuracy: 0.8003 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 49/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4174 - accuracy: 0.7986 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 50/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4174 - accuracy: 0.8003 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 51/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4174 - accuracy: 0.8003 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 52/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4174 - accuracy: 0.7986 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 53/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4174 - accuracy: 0.8021 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 54/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4173 - accuracy: 0.8003 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 55/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4173 - accuracy: 0.8003 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 56/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4173 - accuracy: 0.8003 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 57/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4172 - accuracy: 0.8003 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 58/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4172 - accuracy: 0.7986 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 59/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4172 - accuracy: 0.8021 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 60/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4172 - accuracy: 0.8021 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 61/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4172 - accuracy: 0.8003 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 62/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4172 - accuracy: 0.7986 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 63/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4172 - accuracy: 0.8003 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 64/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4171 - accuracy: 0.8003 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 65/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4171 - accuracy: 0.8021 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 66/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4171 - accuracy: 0.8003 - val_loss: 0.5193 - val_accuracy: 0.7552\n",
      "Epoch 67/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4171 - accuracy: 0.8021 - val_loss: 0.5193 - val_accuracy: 0.7552\n",
      "Epoch 68/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4171 - accuracy: 0.8021 - val_loss: 0.5193 - val_accuracy: 0.7552\n",
      "Epoch 69/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4171 - accuracy: 0.7986 - val_loss: 0.5194 - val_accuracy: 0.7552\n",
      "Epoch 70/200\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4170 - accuracy: 0.7986 - val_loss: 0.5194 - val_accuracy: 0.7552\n",
      "Epoch 71/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4170 - accuracy: 0.8003 - val_loss: 0.5194 - val_accuracy: 0.7552\n",
      "Epoch 72/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4170 - accuracy: 0.8003 - val_loss: 0.5194 - val_accuracy: 0.7552\n",
      "Epoch 73/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4170 - accuracy: 0.8003 - val_loss: 0.5194 - val_accuracy: 0.7552\n",
      "Epoch 74/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4169 - accuracy: 0.8003 - val_loss: 0.5194 - val_accuracy: 0.7552\n",
      "Epoch 75/200\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4169 - accuracy: 0.8003 - val_loss: 0.5195 - val_accuracy: 0.7552\n",
      "Epoch 76/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4169 - accuracy: 0.8003 - val_loss: 0.5195 - val_accuracy: 0.7552\n",
      "Epoch 77/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4169 - accuracy: 0.8003 - val_loss: 0.5195 - val_accuracy: 0.7552\n",
      "Epoch 78/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4168 - accuracy: 0.7986 - val_loss: 0.5196 - val_accuracy: 0.7552\n",
      "Epoch 79/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4168 - accuracy: 0.8003 - val_loss: 0.5196 - val_accuracy: 0.7552\n",
      "Epoch 80/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4168 - accuracy: 0.7986 - val_loss: 0.5196 - val_accuracy: 0.7552\n",
      "Epoch 81/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4168 - accuracy: 0.8003 - val_loss: 0.5196 - val_accuracy: 0.7552\n",
      "Epoch 82/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4168 - accuracy: 0.8003 - val_loss: 0.5196 - val_accuracy: 0.7552\n",
      "Epoch 83/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4167 - accuracy: 0.8003 - val_loss: 0.5197 - val_accuracy: 0.7552\n",
      "Epoch 84/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4167 - accuracy: 0.8003 - val_loss: 0.5197 - val_accuracy: 0.7552\n",
      "Epoch 85/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4167 - accuracy: 0.8021 - val_loss: 0.5197 - val_accuracy: 0.7552\n",
      "Epoch 86/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4167 - accuracy: 0.8003 - val_loss: 0.5197 - val_accuracy: 0.7552\n",
      "Epoch 87/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4167 - accuracy: 0.7986 - val_loss: 0.5198 - val_accuracy: 0.7552\n",
      "Epoch 88/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4167 - accuracy: 0.8003 - val_loss: 0.5198 - val_accuracy: 0.7552\n",
      "Epoch 89/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4166 - accuracy: 0.8003 - val_loss: 0.5198 - val_accuracy: 0.7552\n",
      "Epoch 90/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4166 - accuracy: 0.7986 - val_loss: 0.5198 - val_accuracy: 0.7552\n",
      "Epoch 91/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4166 - accuracy: 0.8003 - val_loss: 0.5198 - val_accuracy: 0.7552\n",
      "Epoch 92/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4166 - accuracy: 0.8003 - val_loss: 0.5198 - val_accuracy: 0.7552\n",
      "Epoch 93/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4165 - accuracy: 0.8021 - val_loss: 0.5199 - val_accuracy: 0.7552\n",
      "Epoch 94/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4165 - accuracy: 0.7986 - val_loss: 0.5199 - val_accuracy: 0.7552\n",
      "Epoch 95/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4165 - accuracy: 0.8003 - val_loss: 0.5199 - val_accuracy: 0.7552\n",
      "Epoch 96/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4165 - accuracy: 0.7986 - val_loss: 0.5199 - val_accuracy: 0.7552\n",
      "Epoch 97/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4165 - accuracy: 0.7986 - val_loss: 0.5200 - val_accuracy: 0.7552\n",
      "Epoch 98/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4165 - accuracy: 0.8003 - val_loss: 0.5200 - val_accuracy: 0.7552\n",
      "Epoch 99/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4164 - accuracy: 0.8003 - val_loss: 0.5200 - val_accuracy: 0.7552\n",
      "Epoch 100/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4164 - accuracy: 0.7986 - val_loss: 0.5200 - val_accuracy: 0.7552\n",
      "Epoch 101/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4164 - accuracy: 0.7986 - val_loss: 0.5200 - val_accuracy: 0.7552\n",
      "Epoch 102/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4164 - accuracy: 0.7986 - val_loss: 0.5201 - val_accuracy: 0.7552\n",
      "Epoch 103/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4163 - accuracy: 0.7986 - val_loss: 0.5201 - val_accuracy: 0.7552\n",
      "Epoch 104/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4164 - accuracy: 0.7986 - val_loss: 0.5201 - val_accuracy: 0.7552\n",
      "Epoch 105/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4163 - accuracy: 0.7986 - val_loss: 0.5201 - val_accuracy: 0.7552\n",
      "Epoch 106/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4163 - accuracy: 0.7969 - val_loss: 0.5202 - val_accuracy: 0.7552\n",
      "Epoch 107/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4163 - accuracy: 0.7986 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 108/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4162 - accuracy: 0.7986 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 109/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4162 - accuracy: 0.8021 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 110/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4162 - accuracy: 0.7969 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 111/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4162 - accuracy: 0.7986 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 112/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4161 - accuracy: 0.8003 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 33us/step - loss: 0.4161 - accuracy: 0.7969 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 114/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4161 - accuracy: 0.7986 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 115/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4161 - accuracy: 0.7986 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 116/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 117/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4160 - accuracy: 0.7969 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 118/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 119/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4159 - accuracy: 0.7969 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 120/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4159 - accuracy: 0.7969 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 121/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4159 - accuracy: 0.7951 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 122/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 123/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4158 - accuracy: 0.7969 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 124/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4158 - accuracy: 0.7986 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 125/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4158 - accuracy: 0.7986 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 126/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4158 - accuracy: 0.7969 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 127/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4157 - accuracy: 0.7986 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 128/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4157 - accuracy: 0.7969 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 129/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4157 - accuracy: 0.7969 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 130/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4156 - accuracy: 0.8003 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 131/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4156 - accuracy: 0.7969 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 132/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4156 - accuracy: 0.7969 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 133/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4156 - accuracy: 0.7986 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 134/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4156 - accuracy: 0.7969 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 135/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4155 - accuracy: 0.7969 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 136/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4155 - accuracy: 0.8003 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 137/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4155 - accuracy: 0.7986 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 138/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4154 - accuracy: 0.7969 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 139/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4154 - accuracy: 0.7969 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 140/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4154 - accuracy: 0.7969 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 141/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4154 - accuracy: 0.7969 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 142/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4153 - accuracy: 0.7969 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 143/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4154 - accuracy: 0.7969 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 144/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4153 - accuracy: 0.7986 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 145/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4153 - accuracy: 0.7969 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 146/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4153 - accuracy: 0.7969 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 147/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4152 - accuracy: 0.7969 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 148/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4152 - accuracy: 0.7969 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 149/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4152 - accuracy: 0.7969 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 150/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4152 - accuracy: 0.7969 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 151/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4151 - accuracy: 0.7969 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 152/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4151 - accuracy: 0.7969 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 153/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4151 - accuracy: 0.7969 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 154/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4151 - accuracy: 0.7969 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 155/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4151 - accuracy: 0.7969 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 156/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4150 - accuracy: 0.7969 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 157/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4150 - accuracy: 0.7986 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 158/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4150 - accuracy: 0.7969 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 159/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4150 - accuracy: 0.7969 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 160/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4150 - accuracy: 0.7969 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 161/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4149 - accuracy: 0.7969 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 162/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4149 - accuracy: 0.7969 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 163/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4148 - accuracy: 0.7969 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 164/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4149 - accuracy: 0.7986 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 165/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4148 - accuracy: 0.7969 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 166/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4148 - accuracy: 0.7969 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 167/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4148 - accuracy: 0.7969 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 168/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4148 - accuracy: 0.7969 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 169/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4147 - accuracy: 0.7969 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
      "Epoch 170/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4147 - accuracy: 0.7969 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
      "Epoch 171/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4147 - accuracy: 0.7969 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
      "Epoch 172/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4147 - accuracy: 0.7986 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
      "Epoch 173/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4147 - accuracy: 0.7969 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
      "Epoch 174/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4147 - accuracy: 0.7986 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
      "Epoch 175/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4146 - accuracy: 0.7969 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
      "Epoch 176/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4146 - accuracy: 0.7969 - val_loss: 0.5208 - val_accuracy: 0.7500\n",
      "Epoch 177/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4145 - accuracy: 0.7969 - val_loss: 0.5208 - val_accuracy: 0.7500\n",
      "Epoch 178/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4145 - accuracy: 0.7969 - val_loss: 0.5208 - val_accuracy: 0.7500\n",
      "Epoch 179/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4145 - accuracy: 0.7969 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
      "Epoch 180/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4145 - accuracy: 0.7969 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
      "Epoch 181/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4144 - accuracy: 0.7969 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
      "Epoch 182/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4144 - accuracy: 0.7969 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
      "Epoch 183/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4144 - accuracy: 0.7969 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
      "Epoch 184/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4144 - accuracy: 0.7986 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
      "Epoch 185/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4144 - accuracy: 0.7969 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 186/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4144 - accuracy: 0.7969 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 187/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4143 - accuracy: 0.7986 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 188/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4143 - accuracy: 0.7969 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 189/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4143 - accuracy: 0.7986 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 190/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4143 - accuracy: 0.7969 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 191/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4143 - accuracy: 0.7969 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 192/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4142 - accuracy: 0.7969 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 193/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4142 - accuracy: 0.7969 - val_loss: 0.5211 - val_accuracy: 0.7552\n",
      "Epoch 194/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4142 - accuracy: 0.7969 - val_loss: 0.5211 - val_accuracy: 0.7552\n",
      "Epoch 195/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4142 - accuracy: 0.7969 - val_loss: 0.5211 - val_accuracy: 0.7552\n",
      "Epoch 196/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4142 - accuracy: 0.7969 - val_loss: 0.5211 - val_accuracy: 0.7552\n",
      "Epoch 197/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4141 - accuracy: 0.7969 - val_loss: 0.5212 - val_accuracy: 0.7552\n",
      "Epoch 198/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4141 - accuracy: 0.7969 - val_loss: 0.5212 - val_accuracy: 0.7552\n",
      "Epoch 199/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4141 - accuracy: 0.7969 - val_loss: 0.5212 - val_accuracy: 0.7552\n",
      "Epoch 200/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4141 - accuracy: 0.7969 - val_loss: 0.5212 - val_accuracy: 0.7552\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46299684],\n",
       "       [0.79895157],\n",
       "       [0.30744654],\n",
       "       [0.28148106],\n",
       "       [0.23271576],\n",
       "       [0.5688626 ],\n",
       "       [0.06217992],\n",
       "       [0.32292894],\n",
       "       [0.7935041 ],\n",
       "       [0.140264  ]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.745\n",
      "roc-auc is 0.806\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x21b8d426240>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4653 - accuracy: 0.7726 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
      "Epoch 2/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4651 - accuracy: 0.7708 - val_loss: 0.5104 - val_accuracy: 0.7448\n",
      "Epoch 3/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4649 - accuracy: 0.7708 - val_loss: 0.5103 - val_accuracy: 0.7448\n",
      "Epoch 4/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4647 - accuracy: 0.7708 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
      "Epoch 5/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4646 - accuracy: 0.7708 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
      "Epoch 6/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4644 - accuracy: 0.7708 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
      "Epoch 7/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4642 - accuracy: 0.7708 - val_loss: 0.5099 - val_accuracy: 0.7448\n",
      "Epoch 8/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4641 - accuracy: 0.7708 - val_loss: 0.5098 - val_accuracy: 0.7448\n",
      "Epoch 9/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4639 - accuracy: 0.7708 - val_loss: 0.5097 - val_accuracy: 0.7448\n",
      "Epoch 10/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4637 - accuracy: 0.7708 - val_loss: 0.5096 - val_accuracy: 0.7448\n",
      "Epoch 11/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4636 - accuracy: 0.7726 - val_loss: 0.5095 - val_accuracy: 0.7448\n",
      "Epoch 12/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4634 - accuracy: 0.7726 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
      "Epoch 13/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4632 - accuracy: 0.7726 - val_loss: 0.5093 - val_accuracy: 0.7448\n",
      "Epoch 14/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4631 - accuracy: 0.7726 - val_loss: 0.5093 - val_accuracy: 0.7448\n",
      "Epoch 15/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4629 - accuracy: 0.7743 - val_loss: 0.5092 - val_accuracy: 0.7448\n",
      "Epoch 16/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4627 - accuracy: 0.7743 - val_loss: 0.5091 - val_accuracy: 0.7448\n",
      "Epoch 17/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4626 - accuracy: 0.7743 - val_loss: 0.5090 - val_accuracy: 0.7448\n",
      "Epoch 18/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4624 - accuracy: 0.7743 - val_loss: 0.5090 - val_accuracy: 0.7448\n",
      "Epoch 19/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4623 - accuracy: 0.7743 - val_loss: 0.5089 - val_accuracy: 0.7448\n",
      "Epoch 20/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4621 - accuracy: 0.7743 - val_loss: 0.5088 - val_accuracy: 0.7500\n",
      "Epoch 21/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4619 - accuracy: 0.7743 - val_loss: 0.5087 - val_accuracy: 0.7500\n",
      "Epoch 22/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4618 - accuracy: 0.7743 - val_loss: 0.5087 - val_accuracy: 0.7500\n",
      "Epoch 23/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4616 - accuracy: 0.7743 - val_loss: 0.5086 - val_accuracy: 0.7552\n",
      "Epoch 24/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4615 - accuracy: 0.7743 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 25/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4614 - accuracy: 0.7760 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 26/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4612 - accuracy: 0.7743 - val_loss: 0.5084 - val_accuracy: 0.7552\n",
      "Epoch 27/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4611 - accuracy: 0.7760 - val_loss: 0.5083 - val_accuracy: 0.7552\n",
      "Epoch 28/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4610 - accuracy: 0.7760 - val_loss: 0.5083 - val_accuracy: 0.7552\n",
      "Epoch 29/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4608 - accuracy: 0.7760 - val_loss: 0.5082 - val_accuracy: 0.7552\n",
      "Epoch 30/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4607 - accuracy: 0.7760 - val_loss: 0.5082 - val_accuracy: 0.7552\n",
      "Epoch 31/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4606 - accuracy: 0.7760 - val_loss: 0.5081 - val_accuracy: 0.7552\n",
      "Epoch 32/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4604 - accuracy: 0.7760 - val_loss: 0.5081 - val_accuracy: 0.7552\n",
      "Epoch 33/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4603 - accuracy: 0.7760 - val_loss: 0.5080 - val_accuracy: 0.7552\n",
      "Epoch 34/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4602 - accuracy: 0.7760 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 35/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4600 - accuracy: 0.7743 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 36/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4599 - accuracy: 0.7760 - val_loss: 0.5078 - val_accuracy: 0.7552\n",
      "Epoch 37/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4598 - accuracy: 0.7743 - val_loss: 0.5078 - val_accuracy: 0.7552\n",
      "Epoch 38/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4597 - accuracy: 0.7760 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 39/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4595 - accuracy: 0.7760 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 40/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4594 - accuracy: 0.7760 - val_loss: 0.5076 - val_accuracy: 0.7552\n",
      "Epoch 41/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4593 - accuracy: 0.7760 - val_loss: 0.5076 - val_accuracy: 0.7552\n",
      "Epoch 42/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.5075 - val_accuracy: 0.7552\n",
      "Epoch 43/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.5075 - val_accuracy: 0.7552\n",
      "Epoch 44/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.5075 - val_accuracy: 0.7552\n",
      "Epoch 45/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.5074 - val_accuracy: 0.7552\n",
      "Epoch 46/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4587 - accuracy: 0.7778 - val_loss: 0.5074 - val_accuracy: 0.7552\n",
      "Epoch 47/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4586 - accuracy: 0.7778 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 48/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4585 - accuracy: 0.7778 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 49/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4584 - accuracy: 0.7778 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 50/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4583 - accuracy: 0.7778 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 51/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4582 - accuracy: 0.7778 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 52/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4581 - accuracy: 0.7778 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
      "Epoch 53/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4580 - accuracy: 0.7778 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
      "Epoch 54/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4578 - accuracy: 0.7778 - val_loss: 0.5070 - val_accuracy: 0.7552\n",
      "Epoch 55/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4577 - accuracy: 0.7778 - val_loss: 0.5070 - val_accuracy: 0.7552\n",
      "Epoch 56/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4576 - accuracy: 0.7778 - val_loss: 0.5069 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4575 - accuracy: 0.7778 - val_loss: 0.5069 - val_accuracy: 0.7604\n",
      "Epoch 58/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.5068 - val_accuracy: 0.7604\n",
      "Epoch 59/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4573 - accuracy: 0.7778 - val_loss: 0.5068 - val_accuracy: 0.7604\n",
      "Epoch 60/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.5067 - val_accuracy: 0.7604\n",
      "Epoch 61/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.5067 - val_accuracy: 0.7604\n",
      "Epoch 62/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4570 - accuracy: 0.7778 - val_loss: 0.5067 - val_accuracy: 0.7604\n",
      "Epoch 63/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4569 - accuracy: 0.7778 - val_loss: 0.5066 - val_accuracy: 0.7604\n",
      "Epoch 64/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.5066 - val_accuracy: 0.7604\n",
      "Epoch 65/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.5065 - val_accuracy: 0.7604\n",
      "Epoch 66/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.5065 - val_accuracy: 0.7604\n",
      "Epoch 67/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.5064 - val_accuracy: 0.7604\n",
      "Epoch 68/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.5064 - val_accuracy: 0.7604\n",
      "Epoch 69/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.5064 - val_accuracy: 0.7604\n",
      "Epoch 70/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4562 - accuracy: 0.7778 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 71/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4561 - accuracy: 0.7795 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 72/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4560 - accuracy: 0.7795 - val_loss: 0.5062 - val_accuracy: 0.7604\n",
      "Epoch 73/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4559 - accuracy: 0.7795 - val_loss: 0.5062 - val_accuracy: 0.7604\n",
      "Epoch 74/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4559 - accuracy: 0.7778 - val_loss: 0.5062 - val_accuracy: 0.7604\n",
      "Epoch 75/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4557 - accuracy: 0.7795 - val_loss: 0.5061 - val_accuracy: 0.7604\n",
      "Epoch 76/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4557 - accuracy: 0.7778 - val_loss: 0.5061 - val_accuracy: 0.7604\n",
      "Epoch 77/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4556 - accuracy: 0.7795 - val_loss: 0.5060 - val_accuracy: 0.7604\n",
      "Epoch 78/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4555 - accuracy: 0.7795 - val_loss: 0.5060 - val_accuracy: 0.7604\n",
      "Epoch 79/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4554 - accuracy: 0.7795 - val_loss: 0.5059 - val_accuracy: 0.7604\n",
      "Epoch 80/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4553 - accuracy: 0.7778 - val_loss: 0.5059 - val_accuracy: 0.7604\n",
      "Epoch 81/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4552 - accuracy: 0.7795 - val_loss: 0.5059 - val_accuracy: 0.7604\n",
      "Epoch 82/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4551 - accuracy: 0.7778 - val_loss: 0.5058 - val_accuracy: 0.7604\n",
      "Epoch 83/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4550 - accuracy: 0.7795 - val_loss: 0.5058 - val_accuracy: 0.7604\n",
      "Epoch 84/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4549 - accuracy: 0.7812 - val_loss: 0.5058 - val_accuracy: 0.7604\n",
      "Epoch 85/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4548 - accuracy: 0.7795 - val_loss: 0.5057 - val_accuracy: 0.7604\n",
      "Epoch 86/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4547 - accuracy: 0.7795 - val_loss: 0.5057 - val_accuracy: 0.7604\n",
      "Epoch 87/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4547 - accuracy: 0.7830 - val_loss: 0.5056 - val_accuracy: 0.7604\n",
      "Epoch 88/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4546 - accuracy: 0.7812 - val_loss: 0.5056 - val_accuracy: 0.7604\n",
      "Epoch 89/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4545 - accuracy: 0.7830 - val_loss: 0.5056 - val_accuracy: 0.7604\n",
      "Epoch 90/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4544 - accuracy: 0.7830 - val_loss: 0.5055 - val_accuracy: 0.7604\n",
      "Epoch 91/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4543 - accuracy: 0.7830 - val_loss: 0.5055 - val_accuracy: 0.7604\n",
      "Epoch 92/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4542 - accuracy: 0.7830 - val_loss: 0.5054 - val_accuracy: 0.7604\n",
      "Epoch 93/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4541 - accuracy: 0.7830 - val_loss: 0.5054 - val_accuracy: 0.7604\n",
      "Epoch 94/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4541 - accuracy: 0.7830 - val_loss: 0.5054 - val_accuracy: 0.7604\n",
      "Epoch 95/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4540 - accuracy: 0.7830 - val_loss: 0.5053 - val_accuracy: 0.7604\n",
      "Epoch 96/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4538 - accuracy: 0.7830 - val_loss: 0.5053 - val_accuracy: 0.7604\n",
      "Epoch 97/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4538 - accuracy: 0.7847 - val_loss: 0.5053 - val_accuracy: 0.7604\n",
      "Epoch 98/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4537 - accuracy: 0.7847 - val_loss: 0.5052 - val_accuracy: 0.7604\n",
      "Epoch 99/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4536 - accuracy: 0.7847 - val_loss: 0.5052 - val_accuracy: 0.7604\n",
      "Epoch 100/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4535 - accuracy: 0.7847 - val_loss: 0.5051 - val_accuracy: 0.7604\n",
      "Epoch 101/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4534 - accuracy: 0.7847 - val_loss: 0.5051 - val_accuracy: 0.7604\n",
      "Epoch 102/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4533 - accuracy: 0.7847 - val_loss: 0.5051 - val_accuracy: 0.7604\n",
      "Epoch 103/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4533 - accuracy: 0.7847 - val_loss: 0.5050 - val_accuracy: 0.7604\n",
      "Epoch 104/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4532 - accuracy: 0.7847 - val_loss: 0.5050 - val_accuracy: 0.7604\n",
      "Epoch 105/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4531 - accuracy: 0.7847 - val_loss: 0.5050 - val_accuracy: 0.7604\n",
      "Epoch 106/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4530 - accuracy: 0.7847 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 107/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4529 - accuracy: 0.7847 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 108/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4528 - accuracy: 0.7847 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 109/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4528 - accuracy: 0.7847 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 110/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4527 - accuracy: 0.7847 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 111/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4526 - accuracy: 0.7847 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 112/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4525 - accuracy: 0.7830 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 29us/step - loss: 0.4525 - accuracy: 0.7847 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 114/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4524 - accuracy: 0.7847 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 115/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4523 - accuracy: 0.7830 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 116/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4523 - accuracy: 0.7847 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 117/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4522 - accuracy: 0.7830 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 118/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4521 - accuracy: 0.7830 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 119/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4520 - accuracy: 0.7830 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 120/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4520 - accuracy: 0.7847 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 121/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4519 - accuracy: 0.7830 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 122/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4518 - accuracy: 0.7830 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 123/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4517 - accuracy: 0.7830 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 124/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4517 - accuracy: 0.7830 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 125/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4516 - accuracy: 0.7830 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 126/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4515 - accuracy: 0.7847 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 127/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4515 - accuracy: 0.7830 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 128/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4514 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 129/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4514 - accuracy: 0.7830 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 130/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4512 - accuracy: 0.7830 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 131/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4512 - accuracy: 0.7795 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 132/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4511 - accuracy: 0.7830 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
      "Epoch 133/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4510 - accuracy: 0.7812 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
      "Epoch 134/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4509 - accuracy: 0.7795 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
      "Epoch 135/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4509 - accuracy: 0.7795 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
      "Epoch 136/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4508 - accuracy: 0.7812 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
      "Epoch 137/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4507 - accuracy: 0.7812 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
      "Epoch 138/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4507 - accuracy: 0.7812 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 139/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4506 - accuracy: 0.7812 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 140/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4506 - accuracy: 0.7812 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 141/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4505 - accuracy: 0.7795 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 142/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4504 - accuracy: 0.7812 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 143/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4504 - accuracy: 0.7795 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
      "Epoch 144/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4503 - accuracy: 0.7812 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
      "Epoch 145/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4502 - accuracy: 0.7812 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
      "Epoch 146/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4502 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
      "Epoch 147/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4501 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
      "Epoch 148/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4500 - accuracy: 0.7830 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
      "Epoch 149/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4500 - accuracy: 0.7830 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
      "Epoch 150/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4499 - accuracy: 0.7830 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
      "Epoch 151/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4498 - accuracy: 0.7812 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
      "Epoch 152/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4497 - accuracy: 0.7830 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
      "Epoch 153/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4496 - accuracy: 0.7830 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 154/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4496 - accuracy: 0.7830 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 155/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4495 - accuracy: 0.7812 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 156/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4495 - accuracy: 0.7830 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 157/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4494 - accuracy: 0.7830 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 158/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4493 - accuracy: 0.7830 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 159/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4493 - accuracy: 0.7812 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 160/1000\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3308 - accuracy: 0.87 - 0s 33us/step - loss: 0.4492 - accuracy: 0.7830 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 161/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4491 - accuracy: 0.7830 - val_loss: 0.5036 - val_accuracy: 0.7604\n",
      "Epoch 162/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4490 - accuracy: 0.7830 - val_loss: 0.5036 - val_accuracy: 0.7604\n",
      "Epoch 163/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4489 - accuracy: 0.7847 - val_loss: 0.5036 - val_accuracy: 0.7604\n",
      "Epoch 164/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4489 - accuracy: 0.7830 - val_loss: 0.5036 - val_accuracy: 0.7604\n",
      "Epoch 165/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4488 - accuracy: 0.7830 - val_loss: 0.5036 - val_accuracy: 0.7604\n",
      "Epoch 166/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4487 - accuracy: 0.7830 - val_loss: 0.5035 - val_accuracy: 0.7604\n",
      "Epoch 167/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4487 - accuracy: 0.7847 - val_loss: 0.5035 - val_accuracy: 0.7604\n",
      "Epoch 168/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4486 - accuracy: 0.7847 - val_loss: 0.5035 - val_accuracy: 0.7604\n",
      "Epoch 169/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4486 - accuracy: 0.7847 - val_loss: 0.5035 - val_accuracy: 0.7604\n",
      "Epoch 170/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4485 - accuracy: 0.7847 - val_loss: 0.5035 - val_accuracy: 0.7604\n",
      "Epoch 171/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4484 - accuracy: 0.7847 - val_loss: 0.5035 - val_accuracy: 0.7604\n",
      "Epoch 172/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4483 - accuracy: 0.7847 - val_loss: 0.5034 - val_accuracy: 0.7604\n",
      "Epoch 173/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4483 - accuracy: 0.7847 - val_loss: 0.5034 - val_accuracy: 0.7604\n",
      "Epoch 174/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4482 - accuracy: 0.7847 - val_loss: 0.5034 - val_accuracy: 0.7604\n",
      "Epoch 175/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4482 - accuracy: 0.7847 - val_loss: 0.5034 - val_accuracy: 0.7604\n",
      "Epoch 176/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4481 - accuracy: 0.7847 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 177/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4480 - accuracy: 0.7847 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 178/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4479 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 179/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4479 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 180/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4478 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 181/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4478 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 182/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4477 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 183/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4476 - accuracy: 0.7882 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 184/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4475 - accuracy: 0.7882 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 185/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4475 - accuracy: 0.7882 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 186/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4474 - accuracy: 0.7882 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 187/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4474 - accuracy: 0.7882 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 188/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4473 - accuracy: 0.7882 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 189/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4472 - accuracy: 0.7882 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 190/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4472 - accuracy: 0.7882 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 191/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4471 - accuracy: 0.7882 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 192/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4470 - accuracy: 0.7882 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 193/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4470 - accuracy: 0.7882 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 194/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4469 - accuracy: 0.7882 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 195/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4469 - accuracy: 0.7882 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 196/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4468 - accuracy: 0.7882 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 197/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4468 - accuracy: 0.7882 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 198/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4467 - accuracy: 0.7882 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 199/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4466 - accuracy: 0.7882 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 200/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4466 - accuracy: 0.7882 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 201/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4465 - accuracy: 0.7882 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 202/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4464 - accuracy: 0.7882 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 203/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4464 - accuracy: 0.7865 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 204/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4464 - accuracy: 0.7882 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 205/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4463 - accuracy: 0.7865 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 206/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4462 - accuracy: 0.7882 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 207/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4462 - accuracy: 0.7882 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 208/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4461 - accuracy: 0.7882 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 209/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4461 - accuracy: 0.7882 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 210/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4460 - accuracy: 0.7865 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 211/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4460 - accuracy: 0.7865 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 212/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4459 - accuracy: 0.7865 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 213/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4458 - accuracy: 0.7865 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 214/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4458 - accuracy: 0.7882 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 215/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4457 - accuracy: 0.7865 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 216/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4456 - accuracy: 0.7865 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 217/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4456 - accuracy: 0.7865 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 218/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4455 - accuracy: 0.7865 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 219/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4455 - accuracy: 0.7865 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 220/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4454 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 221/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4454 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 222/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4453 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 223/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4452 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4452 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 225/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4451 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 226/1000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4450 - accuracy: 0.7865 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 227/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4450 - accuracy: 0.7865 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 228/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4449 - accuracy: 0.7865 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 229/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4449 - accuracy: 0.7865 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 230/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4448 - accuracy: 0.7865 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 231/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4447 - accuracy: 0.7865 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 232/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4447 - accuracy: 0.7865 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 233/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4446 - accuracy: 0.7865 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 234/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4446 - accuracy: 0.7847 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 235/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4445 - accuracy: 0.7865 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 236/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4444 - accuracy: 0.7865 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 237/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4444 - accuracy: 0.7865 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 238/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4443 - accuracy: 0.7847 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 239/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4443 - accuracy: 0.7847 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 240/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4442 - accuracy: 0.7847 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 241/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4442 - accuracy: 0.7830 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 242/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4441 - accuracy: 0.7847 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 243/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4440 - accuracy: 0.7847 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 244/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4440 - accuracy: 0.7847 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 245/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4439 - accuracy: 0.7847 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 246/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4439 - accuracy: 0.7847 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 247/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4438 - accuracy: 0.7847 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 248/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4437 - accuracy: 0.7847 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 249/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4437 - accuracy: 0.7847 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 250/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4437 - accuracy: 0.7847 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 251/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4436 - accuracy: 0.7847 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 252/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4436 - accuracy: 0.7847 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 253/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4435 - accuracy: 0.7847 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 254/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4434 - accuracy: 0.7847 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 255/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4434 - accuracy: 0.7847 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 256/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4434 - accuracy: 0.7847 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 257/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4433 - accuracy: 0.7830 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 258/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4432 - accuracy: 0.7847 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 259/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4432 - accuracy: 0.7847 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 260/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4431 - accuracy: 0.7847 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 261/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4431 - accuracy: 0.7847 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 262/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4430 - accuracy: 0.7847 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 263/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4430 - accuracy: 0.7847 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 264/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4429 - accuracy: 0.7847 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 265/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4429 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 266/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4428 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 267/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4428 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 268/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4427 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 269/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4426 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 270/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4426 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 271/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4426 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 272/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4425 - accuracy: 0.7847 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
      "Epoch 273/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4424 - accuracy: 0.7830 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
      "Epoch 274/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4424 - accuracy: 0.7847 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
      "Epoch 275/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4423 - accuracy: 0.7847 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
      "Epoch 276/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4423 - accuracy: 0.7847 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
      "Epoch 277/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4422 - accuracy: 0.7847 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
      "Epoch 278/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4422 - accuracy: 0.7830 - val_loss: 0.5042 - val_accuracy: 0.7604\n",
      "Epoch 279/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4421 - accuracy: 0.7830 - val_loss: 0.5042 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4421 - accuracy: 0.7847 - val_loss: 0.5042 - val_accuracy: 0.7604\n",
      "Epoch 281/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4420 - accuracy: 0.7847 - val_loss: 0.5042 - val_accuracy: 0.7604\n",
      "Epoch 282/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4420 - accuracy: 0.7830 - val_loss: 0.5042 - val_accuracy: 0.7604\n",
      "Epoch 283/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4419 - accuracy: 0.7847 - val_loss: 0.5042 - val_accuracy: 0.7604\n",
      "Epoch 284/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4418 - accuracy: 0.7830 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 285/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4418 - accuracy: 0.7830 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 286/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4417 - accuracy: 0.7830 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 287/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4417 - accuracy: 0.7830 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 288/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4417 - accuracy: 0.7830 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 289/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4416 - accuracy: 0.7830 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 290/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4415 - accuracy: 0.7830 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 291/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4415 - accuracy: 0.7830 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 292/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4414 - accuracy: 0.7830 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 293/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4414 - accuracy: 0.7830 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 294/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4414 - accuracy: 0.7847 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 295/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4413 - accuracy: 0.7847 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 296/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4412 - accuracy: 0.7847 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 297/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4412 - accuracy: 0.7830 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 298/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4411 - accuracy: 0.7830 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 299/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4411 - accuracy: 0.7830 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 300/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4410 - accuracy: 0.7830 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 301/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4410 - accuracy: 0.7847 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 302/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4410 - accuracy: 0.7830 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 303/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4409 - accuracy: 0.7847 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 304/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4409 - accuracy: 0.7865 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 305/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4408 - accuracy: 0.7847 - val_loss: 0.5047 - val_accuracy: 0.7552\n",
      "Epoch 306/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4408 - accuracy: 0.7847 - val_loss: 0.5047 - val_accuracy: 0.7552\n",
      "Epoch 307/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4407 - accuracy: 0.7847 - val_loss: 0.5047 - val_accuracy: 0.7552\n",
      "Epoch 308/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4407 - accuracy: 0.7865 - val_loss: 0.5047 - val_accuracy: 0.7500\n",
      "Epoch 309/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4407 - accuracy: 0.7847 - val_loss: 0.5047 - val_accuracy: 0.7500\n",
      "Epoch 310/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4406 - accuracy: 0.7830 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
      "Epoch 311/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4405 - accuracy: 0.7847 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
      "Epoch 312/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4405 - accuracy: 0.7847 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
      "Epoch 313/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4405 - accuracy: 0.7830 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
      "Epoch 314/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4404 - accuracy: 0.7847 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
      "Epoch 315/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4404 - accuracy: 0.7847 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
      "Epoch 316/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4403 - accuracy: 0.7847 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
      "Epoch 317/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4403 - accuracy: 0.7847 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
      "Epoch 318/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4402 - accuracy: 0.7847 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
      "Epoch 319/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4402 - accuracy: 0.7847 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
      "Epoch 320/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4402 - accuracy: 0.7847 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
      "Epoch 321/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4401 - accuracy: 0.7847 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
      "Epoch 322/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4401 - accuracy: 0.7865 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
      "Epoch 323/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4401 - accuracy: 0.7847 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
      "Epoch 324/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4400 - accuracy: 0.7847 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
      "Epoch 325/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4400 - accuracy: 0.7865 - val_loss: 0.5051 - val_accuracy: 0.7448\n",
      "Epoch 326/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4399 - accuracy: 0.7882 - val_loss: 0.5051 - val_accuracy: 0.7448\n",
      "Epoch 327/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4399 - accuracy: 0.7882 - val_loss: 0.5051 - val_accuracy: 0.7448\n",
      "Epoch 328/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4398 - accuracy: 0.7865 - val_loss: 0.5051 - val_accuracy: 0.7448\n",
      "Epoch 329/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4398 - accuracy: 0.7882 - val_loss: 0.5051 - val_accuracy: 0.7448\n",
      "Epoch 330/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4398 - accuracy: 0.7882 - val_loss: 0.5052 - val_accuracy: 0.7448\n",
      "Epoch 331/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4397 - accuracy: 0.7882 - val_loss: 0.5052 - val_accuracy: 0.7448\n",
      "Epoch 332/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4396 - accuracy: 0.7882 - val_loss: 0.5052 - val_accuracy: 0.7448\n",
      "Epoch 333/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4396 - accuracy: 0.7882 - val_loss: 0.5052 - val_accuracy: 0.7448\n",
      "Epoch 334/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4396 - accuracy: 0.7882 - val_loss: 0.5052 - val_accuracy: 0.7448\n",
      "Epoch 335/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4395 - accuracy: 0.7882 - val_loss: 0.5052 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4395 - accuracy: 0.7882 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
      "Epoch 337/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4395 - accuracy: 0.7882 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
      "Epoch 338/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4394 - accuracy: 0.7882 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
      "Epoch 339/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4394 - accuracy: 0.7882 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
      "Epoch 340/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4393 - accuracy: 0.7865 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
      "Epoch 341/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4393 - accuracy: 0.7882 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
      "Epoch 342/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4392 - accuracy: 0.7882 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
      "Epoch 343/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4392 - accuracy: 0.7882 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
      "Epoch 344/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
      "Epoch 345/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4391 - accuracy: 0.7865 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
      "Epoch 346/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 347/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 348/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4390 - accuracy: 0.7882 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 349/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4390 - accuracy: 0.7882 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 350/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4390 - accuracy: 0.7882 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 351/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4389 - accuracy: 0.7882 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 352/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4388 - accuracy: 0.7882 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 353/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4388 - accuracy: 0.7882 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 354/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4387 - accuracy: 0.7882 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 355/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4387 - accuracy: 0.7882 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 356/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4387 - accuracy: 0.7882 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 357/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4386 - accuracy: 0.7882 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 358/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4386 - accuracy: 0.7882 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 359/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4386 - accuracy: 0.7882 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 360/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4385 - accuracy: 0.7882 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 361/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4385 - accuracy: 0.7882 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 362/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4384 - accuracy: 0.7882 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 363/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4384 - accuracy: 0.7882 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 364/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4383 - accuracy: 0.7882 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 365/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4383 - accuracy: 0.7882 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 366/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4383 - accuracy: 0.7882 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 367/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4382 - accuracy: 0.7882 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 368/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4382 - accuracy: 0.7882 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
      "Epoch 369/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4381 - accuracy: 0.7882 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
      "Epoch 370/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4381 - accuracy: 0.7882 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
      "Epoch 371/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4381 - accuracy: 0.7882 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
      "Epoch 372/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4380 - accuracy: 0.7882 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
      "Epoch 373/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4380 - accuracy: 0.7882 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
      "Epoch 374/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4379 - accuracy: 0.7882 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
      "Epoch 375/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4379 - accuracy: 0.7882 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
      "Epoch 376/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4378 - accuracy: 0.7882 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
      "Epoch 377/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4378 - accuracy: 0.7882 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
      "Epoch 378/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4378 - accuracy: 0.7882 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
      "Epoch 379/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4377 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7500\n",
      "Epoch 380/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4377 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7500\n",
      "Epoch 381/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4376 - accuracy: 0.7882 - val_loss: 0.5062 - val_accuracy: 0.7500\n",
      "Epoch 382/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4376 - accuracy: 0.7882 - val_loss: 0.5062 - val_accuracy: 0.7500\n",
      "Epoch 383/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4375 - accuracy: 0.7865 - val_loss: 0.5063 - val_accuracy: 0.7500\n",
      "Epoch 384/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4375 - accuracy: 0.7865 - val_loss: 0.5063 - val_accuracy: 0.7500\n",
      "Epoch 385/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4374 - accuracy: 0.7865 - val_loss: 0.5063 - val_accuracy: 0.7500\n",
      "Epoch 386/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4374 - accuracy: 0.7865 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
      "Epoch 387/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4374 - accuracy: 0.7865 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 388/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4373 - accuracy: 0.7865 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 389/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4372 - accuracy: 0.7865 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 390/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4372 - accuracy: 0.7865 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 391/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4372 - accuracy: 0.7865 - val_loss: 0.5065 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 392/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4371 - accuracy: 0.7865 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 393/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4371 - accuracy: 0.7865 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 394/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4370 - accuracy: 0.7865 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 395/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4370 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 396/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4369 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 397/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4369 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 398/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4368 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 399/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4368 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 400/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4368 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 401/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4367 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 402/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4367 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 403/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4366 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 404/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4366 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 405/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4366 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 406/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4365 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 407/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4364 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 408/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4364 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 409/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4364 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 410/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4363 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 411/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4363 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 412/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4362 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
      "Epoch 413/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4362 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
      "Epoch 414/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4361 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
      "Epoch 415/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4361 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
      "Epoch 416/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4361 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
      "Epoch 417/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4360 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
      "Epoch 418/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4360 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
      "Epoch 419/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4359 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
      "Epoch 420/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4359 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
      "Epoch 421/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4358 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
      "Epoch 422/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4358 - accuracy: 0.7899 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
      "Epoch 423/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4357 - accuracy: 0.7882 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
      "Epoch 424/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4357 - accuracy: 0.7882 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
      "Epoch 425/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4356 - accuracy: 0.7899 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
      "Epoch 426/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4356 - accuracy: 0.7899 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
      "Epoch 427/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4356 - accuracy: 0.7899 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
      "Epoch 428/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4355 - accuracy: 0.7882 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
      "Epoch 429/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4355 - accuracy: 0.7899 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
      "Epoch 430/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4354 - accuracy: 0.7882 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
      "Epoch 431/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4353 - accuracy: 0.7899 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
      "Epoch 432/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4353 - accuracy: 0.7899 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
      "Epoch 433/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4353 - accuracy: 0.7899 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
      "Epoch 434/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4353 - accuracy: 0.7882 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
      "Epoch 435/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4352 - accuracy: 0.7899 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
      "Epoch 436/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4352 - accuracy: 0.7899 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
      "Epoch 437/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4351 - accuracy: 0.7899 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
      "Epoch 438/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4351 - accuracy: 0.7899 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
      "Epoch 439/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4350 - accuracy: 0.7899 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
      "Epoch 440/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4350 - accuracy: 0.7899 - val_loss: 0.5075 - val_accuracy: 0.7448\n",
      "Epoch 441/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4350 - accuracy: 0.7899 - val_loss: 0.5075 - val_accuracy: 0.7448\n",
      "Epoch 442/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4349 - accuracy: 0.7899 - val_loss: 0.5075 - val_accuracy: 0.7448\n",
      "Epoch 443/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4349 - accuracy: 0.7882 - val_loss: 0.5075 - val_accuracy: 0.7448\n",
      "Epoch 444/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4348 - accuracy: 0.7899 - val_loss: 0.5075 - val_accuracy: 0.7448\n",
      "Epoch 445/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4348 - accuracy: 0.7899 - val_loss: 0.5075 - val_accuracy: 0.7448\n",
      "Epoch 446/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4348 - accuracy: 0.7899 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
      "Epoch 447/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4347 - accuracy: 0.7899 - val_loss: 0.5076 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4347 - accuracy: 0.7899 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
      "Epoch 449/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4346 - accuracy: 0.7899 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
      "Epoch 450/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4346 - accuracy: 0.7882 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
      "Epoch 451/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4346 - accuracy: 0.7899 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
      "Epoch 452/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4345 - accuracy: 0.7882 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
      "Epoch 453/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4345 - accuracy: 0.7899 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
      "Epoch 454/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4345 - accuracy: 0.7899 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
      "Epoch 455/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4344 - accuracy: 0.7899 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
      "Epoch 456/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4344 - accuracy: 0.7899 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
      "Epoch 457/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4343 - accuracy: 0.7899 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
      "Epoch 458/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4343 - accuracy: 0.7899 - val_loss: 0.5078 - val_accuracy: 0.7448\n",
      "Epoch 459/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4343 - accuracy: 0.7899 - val_loss: 0.5078 - val_accuracy: 0.7448\n",
      "Epoch 460/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4343 - accuracy: 0.7899 - val_loss: 0.5078 - val_accuracy: 0.7448\n",
      "Epoch 461/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4342 - accuracy: 0.7899 - val_loss: 0.5078 - val_accuracy: 0.7448\n",
      "Epoch 462/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4341 - accuracy: 0.7899 - val_loss: 0.5078 - val_accuracy: 0.7448\n",
      "Epoch 463/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4341 - accuracy: 0.7899 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
      "Epoch 464/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4341 - accuracy: 0.7882 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
      "Epoch 465/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4340 - accuracy: 0.7882 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
      "Epoch 466/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4340 - accuracy: 0.7899 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
      "Epoch 467/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4340 - accuracy: 0.7899 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
      "Epoch 468/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4339 - accuracy: 0.7899 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
      "Epoch 469/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4338 - accuracy: 0.7899 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
      "Epoch 470/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4338 - accuracy: 0.7899 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
      "Epoch 471/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4338 - accuracy: 0.7899 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
      "Epoch 472/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4338 - accuracy: 0.7899 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
      "Epoch 473/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4337 - accuracy: 0.7899 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
      "Epoch 474/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4337 - accuracy: 0.7899 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
      "Epoch 475/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4336 - accuracy: 0.7899 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
      "Epoch 476/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4336 - accuracy: 0.7899 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
      "Epoch 477/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4336 - accuracy: 0.7899 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
      "Epoch 478/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4335 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 479/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4335 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 480/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4335 - accuracy: 0.7899 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 481/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4334 - accuracy: 0.7899 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 482/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4334 - accuracy: 0.7899 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 483/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4334 - accuracy: 0.7899 - val_loss: 0.5083 - val_accuracy: 0.7448\n",
      "Epoch 484/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4333 - accuracy: 0.7899 - val_loss: 0.5083 - val_accuracy: 0.7448\n",
      "Epoch 485/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4333 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7448\n",
      "Epoch 486/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4333 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7448\n",
      "Epoch 487/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4332 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7448\n",
      "Epoch 488/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4332 - accuracy: 0.7899 - val_loss: 0.5084 - val_accuracy: 0.7448\n",
      "Epoch 489/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4332 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7448\n",
      "Epoch 490/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4331 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7448\n",
      "Epoch 491/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4331 - accuracy: 0.7899 - val_loss: 0.5084 - val_accuracy: 0.7448\n",
      "Epoch 492/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4331 - accuracy: 0.7899 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 493/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4330 - accuracy: 0.7917 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 494/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4330 - accuracy: 0.7899 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 495/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4330 - accuracy: 0.7899 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 496/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4329 - accuracy: 0.7917 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 497/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4329 - accuracy: 0.7917 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 498/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4329 - accuracy: 0.7899 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 499/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4329 - accuracy: 0.7899 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 500/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4328 - accuracy: 0.7917 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 501/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4328 - accuracy: 0.7882 - val_loss: 0.5087 - val_accuracy: 0.7448\n",
      "Epoch 502/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4327 - accuracy: 0.7899 - val_loss: 0.5087 - val_accuracy: 0.7448\n",
      "Epoch 503/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4327 - accuracy: 0.7899 - val_loss: 0.5087 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 504/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4327 - accuracy: 0.7899 - val_loss: 0.5087 - val_accuracy: 0.7448\n",
      "Epoch 505/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4327 - accuracy: 0.7899 - val_loss: 0.5087 - val_accuracy: 0.7448\n",
      "Epoch 506/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4326 - accuracy: 0.7882 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
      "Epoch 507/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4326 - accuracy: 0.7882 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
      "Epoch 508/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4326 - accuracy: 0.7899 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
      "Epoch 509/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4325 - accuracy: 0.7882 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
      "Epoch 510/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4325 - accuracy: 0.7899 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
      "Epoch 511/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4325 - accuracy: 0.7882 - val_loss: 0.5089 - val_accuracy: 0.7448\n",
      "Epoch 512/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4324 - accuracy: 0.7882 - val_loss: 0.5089 - val_accuracy: 0.7448\n",
      "Epoch 513/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4324 - accuracy: 0.7882 - val_loss: 0.5089 - val_accuracy: 0.7448\n",
      "Epoch 514/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4323 - accuracy: 0.7882 - val_loss: 0.5089 - val_accuracy: 0.7448\n",
      "Epoch 515/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4323 - accuracy: 0.7882 - val_loss: 0.5089 - val_accuracy: 0.7448\n",
      "Epoch 516/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4323 - accuracy: 0.7899 - val_loss: 0.5090 - val_accuracy: 0.7448\n",
      "Epoch 517/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4322 - accuracy: 0.7882 - val_loss: 0.5090 - val_accuracy: 0.7448\n",
      "Epoch 518/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4322 - accuracy: 0.7899 - val_loss: 0.5090 - val_accuracy: 0.7448\n",
      "Epoch 519/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4322 - accuracy: 0.7882 - val_loss: 0.5090 - val_accuracy: 0.7448\n",
      "Epoch 520/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4322 - accuracy: 0.7899 - val_loss: 0.5090 - val_accuracy: 0.7448\n",
      "Epoch 521/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4321 - accuracy: 0.7899 - val_loss: 0.5090 - val_accuracy: 0.7448\n",
      "Epoch 522/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4321 - accuracy: 0.7899 - val_loss: 0.5091 - val_accuracy: 0.7448\n",
      "Epoch 523/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4321 - accuracy: 0.7882 - val_loss: 0.5091 - val_accuracy: 0.7448\n",
      "Epoch 524/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4320 - accuracy: 0.7882 - val_loss: 0.5091 - val_accuracy: 0.7448\n",
      "Epoch 525/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4320 - accuracy: 0.7882 - val_loss: 0.5091 - val_accuracy: 0.7448\n",
      "Epoch 526/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4320 - accuracy: 0.7882 - val_loss: 0.5091 - val_accuracy: 0.7448\n",
      "Epoch 527/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4320 - accuracy: 0.7899 - val_loss: 0.5091 - val_accuracy: 0.7448\n",
      "Epoch 528/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4319 - accuracy: 0.7882 - val_loss: 0.5092 - val_accuracy: 0.7448\n",
      "Epoch 529/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4319 - accuracy: 0.7882 - val_loss: 0.5092 - val_accuracy: 0.7448\n",
      "Epoch 530/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4318 - accuracy: 0.7882 - val_loss: 0.5092 - val_accuracy: 0.7448\n",
      "Epoch 531/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4318 - accuracy: 0.7882 - val_loss: 0.5092 - val_accuracy: 0.7448\n",
      "Epoch 532/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4318 - accuracy: 0.7882 - val_loss: 0.5092 - val_accuracy: 0.7448\n",
      "Epoch 533/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4318 - accuracy: 0.7882 - val_loss: 0.5092 - val_accuracy: 0.7448\n",
      "Epoch 534/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4317 - accuracy: 0.7882 - val_loss: 0.5093 - val_accuracy: 0.7448\n",
      "Epoch 535/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4317 - accuracy: 0.7882 - val_loss: 0.5093 - val_accuracy: 0.7448\n",
      "Epoch 536/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4316 - accuracy: 0.7882 - val_loss: 0.5093 - val_accuracy: 0.7448\n",
      "Epoch 537/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4316 - accuracy: 0.7882 - val_loss: 0.5093 - val_accuracy: 0.7396\n",
      "Epoch 538/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4316 - accuracy: 0.7882 - val_loss: 0.5093 - val_accuracy: 0.7396\n",
      "Epoch 539/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4315 - accuracy: 0.7882 - val_loss: 0.5093 - val_accuracy: 0.7396\n",
      "Epoch 540/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4315 - accuracy: 0.7882 - val_loss: 0.5094 - val_accuracy: 0.7396\n",
      "Epoch 541/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4315 - accuracy: 0.7882 - val_loss: 0.5094 - val_accuracy: 0.7396\n",
      "Epoch 542/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4315 - accuracy: 0.7882 - val_loss: 0.5094 - val_accuracy: 0.7396\n",
      "Epoch 543/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4314 - accuracy: 0.7882 - val_loss: 0.5094 - val_accuracy: 0.7396\n",
      "Epoch 544/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4314 - accuracy: 0.7899 - val_loss: 0.5094 - val_accuracy: 0.7396\n",
      "Epoch 545/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4314 - accuracy: 0.7882 - val_loss: 0.5094 - val_accuracy: 0.7396\n",
      "Epoch 546/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4313 - accuracy: 0.7882 - val_loss: 0.5095 - val_accuracy: 0.7396\n",
      "Epoch 547/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4313 - accuracy: 0.7882 - val_loss: 0.5095 - val_accuracy: 0.7396\n",
      "Epoch 548/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4313 - accuracy: 0.7882 - val_loss: 0.5095 - val_accuracy: 0.7396\n",
      "Epoch 549/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4312 - accuracy: 0.7882 - val_loss: 0.5095 - val_accuracy: 0.7396\n",
      "Epoch 550/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4312 - accuracy: 0.7882 - val_loss: 0.5095 - val_accuracy: 0.7396\n",
      "Epoch 551/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4312 - accuracy: 0.7882 - val_loss: 0.5095 - val_accuracy: 0.7396\n",
      "Epoch 552/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4311 - accuracy: 0.7882 - val_loss: 0.5096 - val_accuracy: 0.7396\n",
      "Epoch 553/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4311 - accuracy: 0.7899 - val_loss: 0.5096 - val_accuracy: 0.7396\n",
      "Epoch 554/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4311 - accuracy: 0.7882 - val_loss: 0.5096 - val_accuracy: 0.7396\n",
      "Epoch 555/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4310 - accuracy: 0.7882 - val_loss: 0.5096 - val_accuracy: 0.7396\n",
      "Epoch 556/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4310 - accuracy: 0.7882 - val_loss: 0.5096 - val_accuracy: 0.7396\n",
      "Epoch 557/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4310 - accuracy: 0.7882 - val_loss: 0.5096 - val_accuracy: 0.7396\n",
      "Epoch 558/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4309 - accuracy: 0.7882 - val_loss: 0.5096 - val_accuracy: 0.7396\n",
      "Epoch 559/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4309 - accuracy: 0.7882 - val_loss: 0.5097 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 560/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4309 - accuracy: 0.7882 - val_loss: 0.5097 - val_accuracy: 0.7396\n",
      "Epoch 561/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4309 - accuracy: 0.7882 - val_loss: 0.5097 - val_accuracy: 0.7396\n",
      "Epoch 562/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4308 - accuracy: 0.7882 - val_loss: 0.5097 - val_accuracy: 0.7396\n",
      "Epoch 563/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4308 - accuracy: 0.7882 - val_loss: 0.5097 - val_accuracy: 0.7396\n",
      "Epoch 564/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4307 - accuracy: 0.7882 - val_loss: 0.5097 - val_accuracy: 0.7396\n",
      "Epoch 565/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4307 - accuracy: 0.7899 - val_loss: 0.5097 - val_accuracy: 0.7396\n",
      "Epoch 566/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4307 - accuracy: 0.7899 - val_loss: 0.5098 - val_accuracy: 0.7396\n",
      "Epoch 567/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4306 - accuracy: 0.7899 - val_loss: 0.5098 - val_accuracy: 0.7396\n",
      "Epoch 568/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4306 - accuracy: 0.7899 - val_loss: 0.5098 - val_accuracy: 0.7396\n",
      "Epoch 569/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4306 - accuracy: 0.7899 - val_loss: 0.5098 - val_accuracy: 0.7396\n",
      "Epoch 570/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4306 - accuracy: 0.7882 - val_loss: 0.5098 - val_accuracy: 0.7396\n",
      "Epoch 571/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4305 - accuracy: 0.7899 - val_loss: 0.5098 - val_accuracy: 0.7396\n",
      "Epoch 572/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4305 - accuracy: 0.7917 - val_loss: 0.5098 - val_accuracy: 0.7396\n",
      "Epoch 573/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4305 - accuracy: 0.7899 - val_loss: 0.5098 - val_accuracy: 0.7396\n",
      "Epoch 574/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4304 - accuracy: 0.7899 - val_loss: 0.5099 - val_accuracy: 0.7396\n",
      "Epoch 575/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4304 - accuracy: 0.7899 - val_loss: 0.5099 - val_accuracy: 0.7396\n",
      "Epoch 576/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4303 - accuracy: 0.7899 - val_loss: 0.5099 - val_accuracy: 0.7396\n",
      "Epoch 577/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4303 - accuracy: 0.7899 - val_loss: 0.5099 - val_accuracy: 0.7396\n",
      "Epoch 578/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4303 - accuracy: 0.7899 - val_loss: 0.5099 - val_accuracy: 0.7396\n",
      "Epoch 579/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4303 - accuracy: 0.7899 - val_loss: 0.5099 - val_accuracy: 0.7396\n",
      "Epoch 580/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4302 - accuracy: 0.7899 - val_loss: 0.5100 - val_accuracy: 0.7396\n",
      "Epoch 581/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4302 - accuracy: 0.7899 - val_loss: 0.5100 - val_accuracy: 0.7396\n",
      "Epoch 582/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4302 - accuracy: 0.7899 - val_loss: 0.5100 - val_accuracy: 0.7396\n",
      "Epoch 583/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4302 - accuracy: 0.7899 - val_loss: 0.5100 - val_accuracy: 0.7396\n",
      "Epoch 584/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4301 - accuracy: 0.7899 - val_loss: 0.5100 - val_accuracy: 0.7396\n",
      "Epoch 585/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4301 - accuracy: 0.7899 - val_loss: 0.5100 - val_accuracy: 0.7396\n",
      "Epoch 586/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4300 - accuracy: 0.7899 - val_loss: 0.5100 - val_accuracy: 0.7396\n",
      "Epoch 587/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4300 - accuracy: 0.7917 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
      "Epoch 588/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4300 - accuracy: 0.7899 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
      "Epoch 589/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4300 - accuracy: 0.7899 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
      "Epoch 590/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4299 - accuracy: 0.7899 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
      "Epoch 591/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4299 - accuracy: 0.7917 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
      "Epoch 592/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4298 - accuracy: 0.7899 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
      "Epoch 593/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4299 - accuracy: 0.7917 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
      "Epoch 594/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4298 - accuracy: 0.7899 - val_loss: 0.5102 - val_accuracy: 0.7396\n",
      "Epoch 595/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4298 - accuracy: 0.7899 - val_loss: 0.5102 - val_accuracy: 0.7396\n",
      "Epoch 596/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4297 - accuracy: 0.7899 - val_loss: 0.5102 - val_accuracy: 0.7396\n",
      "Epoch 597/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4297 - accuracy: 0.7899 - val_loss: 0.5102 - val_accuracy: 0.7396\n",
      "Epoch 598/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4297 - accuracy: 0.7899 - val_loss: 0.5102 - val_accuracy: 0.7396\n",
      "Epoch 599/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4296 - accuracy: 0.7899 - val_loss: 0.5102 - val_accuracy: 0.7396\n",
      "Epoch 600/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4296 - accuracy: 0.7899 - val_loss: 0.5103 - val_accuracy: 0.7396\n",
      "Epoch 601/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4295 - accuracy: 0.7899 - val_loss: 0.5103 - val_accuracy: 0.7396\n",
      "Epoch 602/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4296 - accuracy: 0.7899 - val_loss: 0.5103 - val_accuracy: 0.7396\n",
      "Epoch 603/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4295 - accuracy: 0.7899 - val_loss: 0.5103 - val_accuracy: 0.7396\n",
      "Epoch 604/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4295 - accuracy: 0.7917 - val_loss: 0.5103 - val_accuracy: 0.7396\n",
      "Epoch 605/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4294 - accuracy: 0.7899 - val_loss: 0.5103 - val_accuracy: 0.7396\n",
      "Epoch 606/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4294 - accuracy: 0.7899 - val_loss: 0.5104 - val_accuracy: 0.7396\n",
      "Epoch 607/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4294 - accuracy: 0.7899 - val_loss: 0.5104 - val_accuracy: 0.7396\n",
      "Epoch 608/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4293 - accuracy: 0.7899 - val_loss: 0.5104 - val_accuracy: 0.7396\n",
      "Epoch 609/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4293 - accuracy: 0.7899 - val_loss: 0.5104 - val_accuracy: 0.7396\n",
      "Epoch 610/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4293 - accuracy: 0.7899 - val_loss: 0.5104 - val_accuracy: 0.7396\n",
      "Epoch 611/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4292 - accuracy: 0.7899 - val_loss: 0.5105 - val_accuracy: 0.7396\n",
      "Epoch 612/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4292 - accuracy: 0.7899 - val_loss: 0.5105 - val_accuracy: 0.7396\n",
      "Epoch 613/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4292 - accuracy: 0.7899 - val_loss: 0.5105 - val_accuracy: 0.7396\n",
      "Epoch 614/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4292 - accuracy: 0.7899 - val_loss: 0.5105 - val_accuracy: 0.7396\n",
      "Epoch 615/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4291 - accuracy: 0.7899 - val_loss: 0.5105 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 616/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4291 - accuracy: 0.7899 - val_loss: 0.5105 - val_accuracy: 0.7396\n",
      "Epoch 617/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4290 - accuracy: 0.7899 - val_loss: 0.5106 - val_accuracy: 0.7396\n",
      "Epoch 618/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4290 - accuracy: 0.7899 - val_loss: 0.5106 - val_accuracy: 0.7396\n",
      "Epoch 619/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4290 - accuracy: 0.7899 - val_loss: 0.5106 - val_accuracy: 0.7396\n",
      "Epoch 620/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4290 - accuracy: 0.7899 - val_loss: 0.5106 - val_accuracy: 0.7396\n",
      "Epoch 621/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4289 - accuracy: 0.7899 - val_loss: 0.5106 - val_accuracy: 0.7396\n",
      "Epoch 622/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4289 - accuracy: 0.7899 - val_loss: 0.5106 - val_accuracy: 0.7396\n",
      "Epoch 623/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4289 - accuracy: 0.7899 - val_loss: 0.5107 - val_accuracy: 0.7396\n",
      "Epoch 624/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4288 - accuracy: 0.7899 - val_loss: 0.5107 - val_accuracy: 0.7396\n",
      "Epoch 625/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4288 - accuracy: 0.7899 - val_loss: 0.5107 - val_accuracy: 0.7396\n",
      "Epoch 626/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4288 - accuracy: 0.7899 - val_loss: 0.5107 - val_accuracy: 0.7396\n",
      "Epoch 627/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4287 - accuracy: 0.7899 - val_loss: 0.5107 - val_accuracy: 0.7396\n",
      "Epoch 628/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4287 - accuracy: 0.7899 - val_loss: 0.5108 - val_accuracy: 0.7396\n",
      "Epoch 629/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4287 - accuracy: 0.7899 - val_loss: 0.5108 - val_accuracy: 0.7396\n",
      "Epoch 630/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4286 - accuracy: 0.7899 - val_loss: 0.5108 - val_accuracy: 0.7396\n",
      "Epoch 631/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4286 - accuracy: 0.7899 - val_loss: 0.5108 - val_accuracy: 0.7396\n",
      "Epoch 632/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4286 - accuracy: 0.7899 - val_loss: 0.5108 - val_accuracy: 0.7396\n",
      "Epoch 633/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4285 - accuracy: 0.7899 - val_loss: 0.5108 - val_accuracy: 0.7396\n",
      "Epoch 634/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4285 - accuracy: 0.7899 - val_loss: 0.5109 - val_accuracy: 0.7396\n",
      "Epoch 635/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4285 - accuracy: 0.7899 - val_loss: 0.5109 - val_accuracy: 0.7396\n",
      "Epoch 636/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4284 - accuracy: 0.7899 - val_loss: 0.5109 - val_accuracy: 0.7396\n",
      "Epoch 637/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4284 - accuracy: 0.7899 - val_loss: 0.5109 - val_accuracy: 0.7396\n",
      "Epoch 638/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4284 - accuracy: 0.7899 - val_loss: 0.5109 - val_accuracy: 0.7396\n",
      "Epoch 639/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4283 - accuracy: 0.7899 - val_loss: 0.5110 - val_accuracy: 0.7396\n",
      "Epoch 640/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4283 - accuracy: 0.7917 - val_loss: 0.5110 - val_accuracy: 0.7396\n",
      "Epoch 641/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4283 - accuracy: 0.7899 - val_loss: 0.5110 - val_accuracy: 0.7396\n",
      "Epoch 642/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4282 - accuracy: 0.7899 - val_loss: 0.5110 - val_accuracy: 0.7396\n",
      "Epoch 643/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4282 - accuracy: 0.7899 - val_loss: 0.5110 - val_accuracy: 0.7396\n",
      "Epoch 644/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4282 - accuracy: 0.7899 - val_loss: 0.5110 - val_accuracy: 0.7396\n",
      "Epoch 645/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4281 - accuracy: 0.7899 - val_loss: 0.5111 - val_accuracy: 0.7396\n",
      "Epoch 646/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4281 - accuracy: 0.7899 - val_loss: 0.5111 - val_accuracy: 0.7396\n",
      "Epoch 647/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4280 - accuracy: 0.7899 - val_loss: 0.5111 - val_accuracy: 0.7396\n",
      "Epoch 648/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4280 - accuracy: 0.7899 - val_loss: 0.5111 - val_accuracy: 0.7396\n",
      "Epoch 649/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4280 - accuracy: 0.7899 - val_loss: 0.5111 - val_accuracy: 0.7396\n",
      "Epoch 650/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4279 - accuracy: 0.7899 - val_loss: 0.5112 - val_accuracy: 0.7396\n",
      "Epoch 651/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4279 - accuracy: 0.7899 - val_loss: 0.5112 - val_accuracy: 0.7396\n",
      "Epoch 652/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4279 - accuracy: 0.7899 - val_loss: 0.5112 - val_accuracy: 0.7396\n",
      "Epoch 653/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4278 - accuracy: 0.7899 - val_loss: 0.5112 - val_accuracy: 0.7396\n",
      "Epoch 654/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4278 - accuracy: 0.7899 - val_loss: 0.5112 - val_accuracy: 0.7396\n",
      "Epoch 655/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4278 - accuracy: 0.7899 - val_loss: 0.5112 - val_accuracy: 0.7396\n",
      "Epoch 656/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4277 - accuracy: 0.7899 - val_loss: 0.5113 - val_accuracy: 0.7396\n",
      "Epoch 657/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4277 - accuracy: 0.7899 - val_loss: 0.5113 - val_accuracy: 0.7396\n",
      "Epoch 658/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4277 - accuracy: 0.7899 - val_loss: 0.5113 - val_accuracy: 0.7396\n",
      "Epoch 659/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.5113 - val_accuracy: 0.7396\n",
      "Epoch 660/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.5113 - val_accuracy: 0.7396\n",
      "Epoch 661/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.5113 - val_accuracy: 0.7396\n",
      "Epoch 662/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4275 - accuracy: 0.7899 - val_loss: 0.5113 - val_accuracy: 0.7396\n",
      "Epoch 663/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4275 - accuracy: 0.7899 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
      "Epoch 664/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4274 - accuracy: 0.7899 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
      "Epoch 665/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4274 - accuracy: 0.7899 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
      "Epoch 666/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4274 - accuracy: 0.7899 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
      "Epoch 667/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4274 - accuracy: 0.7899 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
      "Epoch 668/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4273 - accuracy: 0.7899 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
      "Epoch 669/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4273 - accuracy: 0.7899 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
      "Epoch 670/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4273 - accuracy: 0.7899 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
      "Epoch 671/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4272 - accuracy: 0.7899 - val_loss: 0.5115 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 672/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4272 - accuracy: 0.7899 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
      "Epoch 673/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4271 - accuracy: 0.7899 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
      "Epoch 674/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4271 - accuracy: 0.7899 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
      "Epoch 675/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4271 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7396\n",
      "Epoch 676/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.5116 - val_accuracy: 0.7396\n",
      "Epoch 677/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4270 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7396\n",
      "Epoch 678/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4269 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7396\n",
      "Epoch 679/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4269 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7396\n",
      "Epoch 680/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4269 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7396\n",
      "Epoch 681/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4269 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7396\n",
      "Epoch 682/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4268 - accuracy: 0.7882 - val_loss: 0.5117 - val_accuracy: 0.7396\n",
      "Epoch 683/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4268 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7396\n",
      "Epoch 684/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4268 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7396\n",
      "Epoch 685/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4267 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7396\n",
      "Epoch 686/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4267 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7396\n",
      "Epoch 687/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4266 - accuracy: 0.7899 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
      "Epoch 688/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4266 - accuracy: 0.7882 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
      "Epoch 689/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4266 - accuracy: 0.7899 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
      "Epoch 690/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4265 - accuracy: 0.7882 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
      "Epoch 691/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4265 - accuracy: 0.7899 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
      "Epoch 692/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4265 - accuracy: 0.7899 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
      "Epoch 693/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4264 - accuracy: 0.7899 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
      "Epoch 694/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4264 - accuracy: 0.7899 - val_loss: 0.5119 - val_accuracy: 0.7396\n",
      "Epoch 695/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4264 - accuracy: 0.7899 - val_loss: 0.5119 - val_accuracy: 0.7396\n",
      "Epoch 696/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4263 - accuracy: 0.7899 - val_loss: 0.5119 - val_accuracy: 0.7396\n",
      "Epoch 697/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4263 - accuracy: 0.7882 - val_loss: 0.5119 - val_accuracy: 0.7396\n",
      "Epoch 698/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4262 - accuracy: 0.7882 - val_loss: 0.5119 - val_accuracy: 0.7396\n",
      "Epoch 699/1000\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5063 - accuracy: 0.71 - 0s 40us/step - loss: 0.4262 - accuracy: 0.7899 - val_loss: 0.5120 - val_accuracy: 0.7396\n",
      "Epoch 700/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4262 - accuracy: 0.7899 - val_loss: 0.5120 - val_accuracy: 0.7396\n",
      "Epoch 701/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4262 - accuracy: 0.7899 - val_loss: 0.5120 - val_accuracy: 0.7448\n",
      "Epoch 702/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4261 - accuracy: 0.7899 - val_loss: 0.5120 - val_accuracy: 0.7448\n",
      "Epoch 703/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4261 - accuracy: 0.7899 - val_loss: 0.5120 - val_accuracy: 0.7448\n",
      "Epoch 704/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4260 - accuracy: 0.7882 - val_loss: 0.5120 - val_accuracy: 0.7448\n",
      "Epoch 705/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4260 - accuracy: 0.7899 - val_loss: 0.5121 - val_accuracy: 0.7500\n",
      "Epoch 706/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4260 - accuracy: 0.7899 - val_loss: 0.5121 - val_accuracy: 0.7500\n",
      "Epoch 707/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4260 - accuracy: 0.7899 - val_loss: 0.5121 - val_accuracy: 0.7500\n",
      "Epoch 708/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4260 - accuracy: 0.7899 - val_loss: 0.5121 - val_accuracy: 0.7500\n",
      "Epoch 709/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4259 - accuracy: 0.7882 - val_loss: 0.5121 - val_accuracy: 0.7500\n",
      "Epoch 710/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4258 - accuracy: 0.7899 - val_loss: 0.5122 - val_accuracy: 0.7500\n",
      "Epoch 711/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4258 - accuracy: 0.7882 - val_loss: 0.5122 - val_accuracy: 0.7500\n",
      "Epoch 712/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4258 - accuracy: 0.7882 - val_loss: 0.5122 - val_accuracy: 0.7500\n",
      "Epoch 713/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4257 - accuracy: 0.7899 - val_loss: 0.5122 - val_accuracy: 0.7500\n",
      "Epoch 714/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4257 - accuracy: 0.7882 - val_loss: 0.5122 - val_accuracy: 0.7500\n",
      "Epoch 715/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4257 - accuracy: 0.7899 - val_loss: 0.5122 - val_accuracy: 0.7500\n",
      "Epoch 716/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4256 - accuracy: 0.7899 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
      "Epoch 717/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4256 - accuracy: 0.7882 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
      "Epoch 718/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4255 - accuracy: 0.7899 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
      "Epoch 719/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4255 - accuracy: 0.7882 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
      "Epoch 720/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4255 - accuracy: 0.7882 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
      "Epoch 721/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4255 - accuracy: 0.7882 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
      "Epoch 722/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4254 - accuracy: 0.7882 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
      "Epoch 723/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4254 - accuracy: 0.7899 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
      "Epoch 724/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4254 - accuracy: 0.7882 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
      "Epoch 725/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4253 - accuracy: 0.7882 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
      "Epoch 726/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4253 - accuracy: 0.7899 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
      "Epoch 727/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4253 - accuracy: 0.7882 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
      "Epoch 728/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4252 - accuracy: 0.7882 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
      "Epoch 729/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4252 - accuracy: 0.7899 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
      "Epoch 730/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4252 - accuracy: 0.7882 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
      "Epoch 731/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4251 - accuracy: 0.7882 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
      "Epoch 732/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4251 - accuracy: 0.7882 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
      "Epoch 733/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4251 - accuracy: 0.7882 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
      "Epoch 734/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4250 - accuracy: 0.7882 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
      "Epoch 735/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4250 - accuracy: 0.7882 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
      "Epoch 736/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4249 - accuracy: 0.7899 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
      "Epoch 737/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4249 - accuracy: 0.7899 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
      "Epoch 738/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4249 - accuracy: 0.7882 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
      "Epoch 739/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4249 - accuracy: 0.7882 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
      "Epoch 740/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4248 - accuracy: 0.7917 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 741/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4248 - accuracy: 0.7917 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 742/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4248 - accuracy: 0.7882 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 743/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 744/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 745/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
      "Epoch 746/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4247 - accuracy: 0.7917 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
      "Epoch 747/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
      "Epoch 748/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
      "Epoch 749/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
      "Epoch 750/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.5129 - val_accuracy: 0.7500\n",
      "Epoch 751/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.5129 - val_accuracy: 0.7500\n",
      "Epoch 752/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4244 - accuracy: 0.7934 - val_loss: 0.5129 - val_accuracy: 0.7500\n",
      "Epoch 753/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4244 - accuracy: 0.7899 - val_loss: 0.5129 - val_accuracy: 0.7500\n",
      "Epoch 754/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4244 - accuracy: 0.7899 - val_loss: 0.5129 - val_accuracy: 0.7500\n",
      "Epoch 755/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4244 - accuracy: 0.7899 - val_loss: 0.5130 - val_accuracy: 0.7500\n",
      "Epoch 756/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.5130 - val_accuracy: 0.7500\n",
      "Epoch 757/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.5130 - val_accuracy: 0.7500\n",
      "Epoch 758/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4242 - accuracy: 0.7917 - val_loss: 0.5130 - val_accuracy: 0.7500\n",
      "Epoch 759/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4242 - accuracy: 0.7899 - val_loss: 0.5131 - val_accuracy: 0.7500\n",
      "Epoch 760/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4242 - accuracy: 0.7917 - val_loss: 0.5131 - val_accuracy: 0.7500\n",
      "Epoch 761/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4242 - accuracy: 0.7899 - val_loss: 0.5131 - val_accuracy: 0.7500\n",
      "Epoch 762/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.5131 - val_accuracy: 0.7500\n",
      "Epoch 763/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.5131 - val_accuracy: 0.7500\n",
      "Epoch 764/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4241 - accuracy: 0.7917 - val_loss: 0.5132 - val_accuracy: 0.7500\n",
      "Epoch 765/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4240 - accuracy: 0.7899 - val_loss: 0.5132 - val_accuracy: 0.7500\n",
      "Epoch 766/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4240 - accuracy: 0.7917 - val_loss: 0.5132 - val_accuracy: 0.7500\n",
      "Epoch 767/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4239 - accuracy: 0.7917 - val_loss: 0.5132 - val_accuracy: 0.7500\n",
      "Epoch 768/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4239 - accuracy: 0.7899 - val_loss: 0.5133 - val_accuracy: 0.7500\n",
      "Epoch 769/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4239 - accuracy: 0.7899 - val_loss: 0.5133 - val_accuracy: 0.7500\n",
      "Epoch 770/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4238 - accuracy: 0.7917 - val_loss: 0.5133 - val_accuracy: 0.7500\n",
      "Epoch 771/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4238 - accuracy: 0.7917 - val_loss: 0.5133 - val_accuracy: 0.7500\n",
      "Epoch 772/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4238 - accuracy: 0.7899 - val_loss: 0.5134 - val_accuracy: 0.7500\n",
      "Epoch 773/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4237 - accuracy: 0.7917 - val_loss: 0.5134 - val_accuracy: 0.7500\n",
      "Epoch 774/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4237 - accuracy: 0.7934 - val_loss: 0.5134 - val_accuracy: 0.7500\n",
      "Epoch 775/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4237 - accuracy: 0.7917 - val_loss: 0.5134 - val_accuracy: 0.7500\n",
      "Epoch 776/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4236 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7500\n",
      "Epoch 777/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4236 - accuracy: 0.7934 - val_loss: 0.5135 - val_accuracy: 0.7500\n",
      "Epoch 778/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4236 - accuracy: 0.7934 - val_loss: 0.5135 - val_accuracy: 0.7500\n",
      "Epoch 779/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4236 - accuracy: 0.7934 - val_loss: 0.5135 - val_accuracy: 0.7500\n",
      "Epoch 780/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4235 - accuracy: 0.7917 - val_loss: 0.5135 - val_accuracy: 0.7500\n",
      "Epoch 781/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4235 - accuracy: 0.7934 - val_loss: 0.5136 - val_accuracy: 0.7500\n",
      "Epoch 782/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4235 - accuracy: 0.7934 - val_loss: 0.5136 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 783/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4234 - accuracy: 0.7934 - val_loss: 0.5136 - val_accuracy: 0.7500\n",
      "Epoch 784/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4234 - accuracy: 0.7934 - val_loss: 0.5136 - val_accuracy: 0.7500\n",
      "Epoch 785/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4234 - accuracy: 0.7951 - val_loss: 0.5137 - val_accuracy: 0.7500\n",
      "Epoch 786/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4234 - accuracy: 0.7951 - val_loss: 0.5137 - val_accuracy: 0.7500\n",
      "Epoch 787/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4233 - accuracy: 0.7934 - val_loss: 0.5137 - val_accuracy: 0.7500\n",
      "Epoch 788/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4233 - accuracy: 0.7951 - val_loss: 0.5137 - val_accuracy: 0.7500\n",
      "Epoch 789/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4232 - accuracy: 0.7934 - val_loss: 0.5138 - val_accuracy: 0.7500\n",
      "Epoch 790/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4232 - accuracy: 0.7951 - val_loss: 0.5138 - val_accuracy: 0.7500\n",
      "Epoch 791/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4232 - accuracy: 0.7951 - val_loss: 0.5138 - val_accuracy: 0.7500\n",
      "Epoch 792/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4231 - accuracy: 0.7951 - val_loss: 0.5138 - val_accuracy: 0.7500\n",
      "Epoch 793/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4231 - accuracy: 0.7951 - val_loss: 0.5138 - val_accuracy: 0.7500\n",
      "Epoch 794/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4231 - accuracy: 0.7934 - val_loss: 0.5139 - val_accuracy: 0.7500\n",
      "Epoch 795/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4230 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7500\n",
      "Epoch 796/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4230 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7500\n",
      "Epoch 797/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4230 - accuracy: 0.7934 - val_loss: 0.5139 - val_accuracy: 0.7500\n",
      "Epoch 798/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4229 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7500\n",
      "Epoch 799/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4230 - accuracy: 0.7934 - val_loss: 0.5140 - val_accuracy: 0.7500\n",
      "Epoch 800/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4229 - accuracy: 0.7951 - val_loss: 0.5140 - val_accuracy: 0.7500\n",
      "Epoch 801/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4229 - accuracy: 0.7951 - val_loss: 0.5140 - val_accuracy: 0.7500\n",
      "Epoch 802/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4228 - accuracy: 0.7951 - val_loss: 0.5140 - val_accuracy: 0.7500\n",
      "Epoch 803/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4228 - accuracy: 0.7951 - val_loss: 0.5140 - val_accuracy: 0.7500\n",
      "Epoch 804/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4228 - accuracy: 0.7951 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 805/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4228 - accuracy: 0.7951 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 806/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4227 - accuracy: 0.7951 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 807/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4227 - accuracy: 0.7951 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 808/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4227 - accuracy: 0.7951 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 809/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4227 - accuracy: 0.7951 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 810/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4227 - accuracy: 0.7951 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 811/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4226 - accuracy: 0.7951 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 812/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4226 - accuracy: 0.7951 - val_loss: 0.5143 - val_accuracy: 0.7500\n",
      "Epoch 813/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4225 - accuracy: 0.7951 - val_loss: 0.5143 - val_accuracy: 0.7500\n",
      "Epoch 814/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4225 - accuracy: 0.7951 - val_loss: 0.5143 - val_accuracy: 0.7500\n",
      "Epoch 815/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4225 - accuracy: 0.7951 - val_loss: 0.5143 - val_accuracy: 0.7500\n",
      "Epoch 816/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4224 - accuracy: 0.7951 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 817/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4224 - accuracy: 0.7951 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 818/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4224 - accuracy: 0.7951 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 819/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4224 - accuracy: 0.7951 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 820/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4224 - accuracy: 0.7951 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 821/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.5145 - val_accuracy: 0.7500\n",
      "Epoch 822/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.5145 - val_accuracy: 0.7500\n",
      "Epoch 823/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.5145 - val_accuracy: 0.7500\n",
      "Epoch 824/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.5145 - val_accuracy: 0.7500\n",
      "Epoch 825/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.5146 - val_accuracy: 0.7500\n",
      "Epoch 826/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4222 - accuracy: 0.7951 - val_loss: 0.5146 - val_accuracy: 0.7500\n",
      "Epoch 827/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4222 - accuracy: 0.7951 - val_loss: 0.5146 - val_accuracy: 0.7500\n",
      "Epoch 828/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4222 - accuracy: 0.7951 - val_loss: 0.5146 - val_accuracy: 0.7500\n",
      "Epoch 829/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4221 - accuracy: 0.7951 - val_loss: 0.5147 - val_accuracy: 0.7500\n",
      "Epoch 830/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4221 - accuracy: 0.7951 - val_loss: 0.5147 - val_accuracy: 0.7500\n",
      "Epoch 831/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4221 - accuracy: 0.7951 - val_loss: 0.5147 - val_accuracy: 0.7500\n",
      "Epoch 832/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4221 - accuracy: 0.7934 - val_loss: 0.5147 - val_accuracy: 0.7500\n",
      "Epoch 833/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.5148 - val_accuracy: 0.7500\n",
      "Epoch 834/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.5148 - val_accuracy: 0.7500\n",
      "Epoch 835/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.5148 - val_accuracy: 0.7500\n",
      "Epoch 836/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.5148 - val_accuracy: 0.7500\n",
      "Epoch 837/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4219 - accuracy: 0.7934 - val_loss: 0.5148 - val_accuracy: 0.7500\n",
      "Epoch 838/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.5149 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 839/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.5149 - val_accuracy: 0.7500\n",
      "Epoch 840/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.5149 - val_accuracy: 0.7500\n",
      "Epoch 841/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.5149 - val_accuracy: 0.7500\n",
      "Epoch 842/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.5149 - val_accuracy: 0.7500\n",
      "Epoch 843/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.5149 - val_accuracy: 0.7500\n",
      "Epoch 844/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.5150 - val_accuracy: 0.7500\n",
      "Epoch 845/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4217 - accuracy: 0.7951 - val_loss: 0.5150 - val_accuracy: 0.7500\n",
      "Epoch 846/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4217 - accuracy: 0.7969 - val_loss: 0.5150 - val_accuracy: 0.7500\n",
      "Epoch 847/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4217 - accuracy: 0.7951 - val_loss: 0.5150 - val_accuracy: 0.7500\n",
      "Epoch 848/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4216 - accuracy: 0.7951 - val_loss: 0.5150 - val_accuracy: 0.7500\n",
      "Epoch 849/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4216 - accuracy: 0.7951 - val_loss: 0.5150 - val_accuracy: 0.7500\n",
      "Epoch 850/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4216 - accuracy: 0.7951 - val_loss: 0.5151 - val_accuracy: 0.7500\n",
      "Epoch 851/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4216 - accuracy: 0.7951 - val_loss: 0.5151 - val_accuracy: 0.7500\n",
      "Epoch 852/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4216 - accuracy: 0.7934 - val_loss: 0.5151 - val_accuracy: 0.7500\n",
      "Epoch 853/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4215 - accuracy: 0.7951 - val_loss: 0.5151 - val_accuracy: 0.7500\n",
      "Epoch 854/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4215 - accuracy: 0.7951 - val_loss: 0.5151 - val_accuracy: 0.7500\n",
      "Epoch 855/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4215 - accuracy: 0.7951 - val_loss: 0.5152 - val_accuracy: 0.7500\n",
      "Epoch 856/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4215 - accuracy: 0.7951 - val_loss: 0.5152 - val_accuracy: 0.7500\n",
      "Epoch 857/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4215 - accuracy: 0.7951 - val_loss: 0.5152 - val_accuracy: 0.7500\n",
      "Epoch 858/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4214 - accuracy: 0.7951 - val_loss: 0.5152 - val_accuracy: 0.7500\n",
      "Epoch 859/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4214 - accuracy: 0.7951 - val_loss: 0.5152 - val_accuracy: 0.7500\n",
      "Epoch 860/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4214 - accuracy: 0.7951 - val_loss: 0.5152 - val_accuracy: 0.7500\n",
      "Epoch 861/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4213 - accuracy: 0.7951 - val_loss: 0.5153 - val_accuracy: 0.7500\n",
      "Epoch 862/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4213 - accuracy: 0.7969 - val_loss: 0.5153 - val_accuracy: 0.7500\n",
      "Epoch 863/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4213 - accuracy: 0.7951 - val_loss: 0.5153 - val_accuracy: 0.7500\n",
      "Epoch 864/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4213 - accuracy: 0.7951 - val_loss: 0.5153 - val_accuracy: 0.7500\n",
      "Epoch 865/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4213 - accuracy: 0.7951 - val_loss: 0.5153 - val_accuracy: 0.7500\n",
      "Epoch 866/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4213 - accuracy: 0.7951 - val_loss: 0.5153 - val_accuracy: 0.7500\n",
      "Epoch 867/1000\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3246 - accuracy: 0.87 - 0s 35us/step - loss: 0.4213 - accuracy: 0.7951 - val_loss: 0.5153 - val_accuracy: 0.7500\n",
      "Epoch 868/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4212 - accuracy: 0.7951 - val_loss: 0.5154 - val_accuracy: 0.7500\n",
      "Epoch 869/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4212 - accuracy: 0.7951 - val_loss: 0.5154 - val_accuracy: 0.7500\n",
      "Epoch 870/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4212 - accuracy: 0.7969 - val_loss: 0.5154 - val_accuracy: 0.7500\n",
      "Epoch 871/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4212 - accuracy: 0.7951 - val_loss: 0.5154 - val_accuracy: 0.7500\n",
      "Epoch 872/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4211 - accuracy: 0.7951 - val_loss: 0.5154 - val_accuracy: 0.7500\n",
      "Epoch 873/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4211 - accuracy: 0.7951 - val_loss: 0.5154 - val_accuracy: 0.7500\n",
      "Epoch 874/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4211 - accuracy: 0.7951 - val_loss: 0.5155 - val_accuracy: 0.7500\n",
      "Epoch 875/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4211 - accuracy: 0.7951 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 876/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4210 - accuracy: 0.7951 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 877/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4210 - accuracy: 0.7951 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 878/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4210 - accuracy: 0.7969 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 879/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4210 - accuracy: 0.7951 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 880/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4209 - accuracy: 0.7951 - val_loss: 0.5156 - val_accuracy: 0.7552\n",
      "Epoch 881/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4209 - accuracy: 0.7951 - val_loss: 0.5156 - val_accuracy: 0.7552\n",
      "Epoch 882/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4209 - accuracy: 0.7934 - val_loss: 0.5156 - val_accuracy: 0.7552\n",
      "Epoch 883/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4209 - accuracy: 0.7951 - val_loss: 0.5156 - val_accuracy: 0.7552\n",
      "Epoch 884/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4209 - accuracy: 0.7969 - val_loss: 0.5156 - val_accuracy: 0.7552\n",
      "Epoch 885/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4208 - accuracy: 0.7951 - val_loss: 0.5156 - val_accuracy: 0.7552\n",
      "Epoch 886/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4208 - accuracy: 0.7951 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
      "Epoch 887/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4208 - accuracy: 0.7951 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
      "Epoch 888/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4208 - accuracy: 0.7951 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
      "Epoch 889/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
      "Epoch 890/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4207 - accuracy: 0.7951 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
      "Epoch 891/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4207 - accuracy: 0.7951 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
      "Epoch 892/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4207 - accuracy: 0.7951 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
      "Epoch 893/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4206 - accuracy: 0.7951 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
      "Epoch 894/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4206 - accuracy: 0.7951 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
      "Epoch 895/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4206 - accuracy: 0.7951 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
      "Epoch 896/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4206 - accuracy: 0.7951 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
      "Epoch 897/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4205 - accuracy: 0.7951 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
      "Epoch 898/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4206 - accuracy: 0.7969 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
      "Epoch 899/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
      "Epoch 900/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.5159 - val_accuracy: 0.7552\n",
      "Epoch 901/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.5159 - val_accuracy: 0.7552\n",
      "Epoch 902/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.5159 - val_accuracy: 0.7552\n",
      "Epoch 903/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4204 - accuracy: 0.7951 - val_loss: 0.5159 - val_accuracy: 0.7552\n",
      "Epoch 904/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4204 - accuracy: 0.7951 - val_loss: 0.5159 - val_accuracy: 0.7552\n",
      "Epoch 905/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4204 - accuracy: 0.7951 - val_loss: 0.5159 - val_accuracy: 0.7552\n",
      "Epoch 906/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4203 - accuracy: 0.7951 - val_loss: 0.5159 - val_accuracy: 0.7552\n",
      "Epoch 907/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4203 - accuracy: 0.7969 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 908/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4203 - accuracy: 0.7969 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 909/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4203 - accuracy: 0.7951 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 910/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4203 - accuracy: 0.7969 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 911/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4202 - accuracy: 0.7951 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 912/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4202 - accuracy: 0.7951 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 913/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4202 - accuracy: 0.7951 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 914/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4202 - accuracy: 0.7951 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 915/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4201 - accuracy: 0.7951 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 916/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4201 - accuracy: 0.7951 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 917/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4201 - accuracy: 0.7951 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 918/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4201 - accuracy: 0.7969 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 919/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4201 - accuracy: 0.7951 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 920/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4201 - accuracy: 0.7969 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 921/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4200 - accuracy: 0.7969 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 922/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.5162 - val_accuracy: 0.7552\n",
      "Epoch 923/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.5162 - val_accuracy: 0.7552\n",
      "Epoch 924/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4200 - accuracy: 0.7969 - val_loss: 0.5162 - val_accuracy: 0.7552\n",
      "Epoch 925/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4199 - accuracy: 0.7969 - val_loss: 0.5162 - val_accuracy: 0.7552\n",
      "Epoch 926/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4199 - accuracy: 0.7951 - val_loss: 0.5162 - val_accuracy: 0.7552\n",
      "Epoch 927/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4199 - accuracy: 0.7951 - val_loss: 0.5162 - val_accuracy: 0.7552\n",
      "Epoch 928/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4199 - accuracy: 0.7951 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 929/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4199 - accuracy: 0.7969 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 930/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4198 - accuracy: 0.7969 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 931/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4198 - accuracy: 0.7951 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 932/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4198 - accuracy: 0.7951 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 933/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4198 - accuracy: 0.7951 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
      "Epoch 934/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4197 - accuracy: 0.7969 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
      "Epoch 935/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4197 - accuracy: 0.7951 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
      "Epoch 936/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4197 - accuracy: 0.7951 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
      "Epoch 937/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4197 - accuracy: 0.7951 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
      "Epoch 938/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4197 - accuracy: 0.7951 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
      "Epoch 939/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4196 - accuracy: 0.7969 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
      "Epoch 940/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4196 - accuracy: 0.7969 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
      "Epoch 941/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4196 - accuracy: 0.7951 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
      "Epoch 942/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4196 - accuracy: 0.7951 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
      "Epoch 943/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4196 - accuracy: 0.7969 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 944/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4195 - accuracy: 0.7951 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 945/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4195 - accuracy: 0.7951 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 946/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4195 - accuracy: 0.7969 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 947/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4195 - accuracy: 0.7951 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 948/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4194 - accuracy: 0.7969 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 949/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4194 - accuracy: 0.7951 - val_loss: 0.5167 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 950/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4194 - accuracy: 0.7969 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 951/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4194 - accuracy: 0.7969 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 952/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4194 - accuracy: 0.7951 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 953/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4193 - accuracy: 0.7951 - val_loss: 0.5168 - val_accuracy: 0.7500\n",
      "Epoch 954/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4193 - accuracy: 0.7951 - val_loss: 0.5168 - val_accuracy: 0.7500\n",
      "Epoch 955/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4193 - accuracy: 0.7951 - val_loss: 0.5168 - val_accuracy: 0.7500\n",
      "Epoch 956/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4193 - accuracy: 0.7969 - val_loss: 0.5168 - val_accuracy: 0.7500\n",
      "Epoch 957/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4193 - accuracy: 0.7951 - val_loss: 0.5168 - val_accuracy: 0.7500\n",
      "Epoch 958/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4192 - accuracy: 0.7951 - val_loss: 0.5169 - val_accuracy: 0.7500\n",
      "Epoch 959/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4192 - accuracy: 0.7951 - val_loss: 0.5169 - val_accuracy: 0.7500\n",
      "Epoch 960/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4192 - accuracy: 0.7951 - val_loss: 0.5169 - val_accuracy: 0.7500\n",
      "Epoch 961/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4192 - accuracy: 0.7934 - val_loss: 0.5169 - val_accuracy: 0.7500\n",
      "Epoch 962/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4192 - accuracy: 0.7951 - val_loss: 0.5169 - val_accuracy: 0.7500\n",
      "Epoch 963/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4191 - accuracy: 0.7934 - val_loss: 0.5170 - val_accuracy: 0.7500\n",
      "Epoch 964/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4191 - accuracy: 0.7951 - val_loss: 0.5170 - val_accuracy: 0.7500\n",
      "Epoch 965/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4191 - accuracy: 0.7951 - val_loss: 0.5170 - val_accuracy: 0.7500\n",
      "Epoch 966/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4191 - accuracy: 0.7951 - val_loss: 0.5170 - val_accuracy: 0.7500\n",
      "Epoch 967/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4190 - accuracy: 0.7969 - val_loss: 0.5170 - val_accuracy: 0.7500\n",
      "Epoch 968/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4190 - accuracy: 0.7969 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 969/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4190 - accuracy: 0.7951 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 970/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4190 - accuracy: 0.7969 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 971/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4190 - accuracy: 0.7951 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 972/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4190 - accuracy: 0.7951 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 973/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4189 - accuracy: 0.7951 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 974/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4189 - accuracy: 0.7951 - val_loss: 0.5172 - val_accuracy: 0.7500\n",
      "Epoch 975/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4189 - accuracy: 0.7951 - val_loss: 0.5172 - val_accuracy: 0.7500\n",
      "Epoch 976/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4188 - accuracy: 0.7969 - val_loss: 0.5172 - val_accuracy: 0.7500\n",
      "Epoch 977/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4188 - accuracy: 0.7969 - val_loss: 0.5172 - val_accuracy: 0.7500\n",
      "Epoch 978/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4188 - accuracy: 0.7969 - val_loss: 0.5172 - val_accuracy: 0.7500\n",
      "Epoch 979/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4188 - accuracy: 0.7969 - val_loss: 0.5173 - val_accuracy: 0.7500\n",
      "Epoch 980/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4188 - accuracy: 0.7951 - val_loss: 0.5173 - val_accuracy: 0.7500\n",
      "Epoch 981/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4187 - accuracy: 0.7969 - val_loss: 0.5173 - val_accuracy: 0.7500\n",
      "Epoch 982/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4187 - accuracy: 0.7951 - val_loss: 0.5174 - val_accuracy: 0.7500\n",
      "Epoch 983/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4187 - accuracy: 0.7951 - val_loss: 0.5174 - val_accuracy: 0.7500\n",
      "Epoch 984/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4187 - accuracy: 0.7951 - val_loss: 0.5174 - val_accuracy: 0.7500\n",
      "Epoch 985/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4187 - accuracy: 0.7969 - val_loss: 0.5174 - val_accuracy: 0.7500\n",
      "Epoch 986/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4187 - accuracy: 0.7969 - val_loss: 0.5174 - val_accuracy: 0.7500\n",
      "Epoch 987/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4186 - accuracy: 0.7951 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
      "Epoch 988/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4186 - accuracy: 0.7969 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
      "Epoch 989/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4186 - accuracy: 0.7969 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
      "Epoch 990/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4186 - accuracy: 0.7969 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
      "Epoch 991/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4186 - accuracy: 0.7986 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
      "Epoch 992/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4185 - accuracy: 0.7951 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
      "Epoch 993/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4185 - accuracy: 0.7969 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
      "Epoch 994/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4185 - accuracy: 0.7951 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
      "Epoch 995/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4185 - accuracy: 0.7986 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
      "Epoch 996/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4184 - accuracy: 0.7969 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
      "Epoch 997/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4184 - accuracy: 0.7986 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
      "Epoch 998/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4184 - accuracy: 0.7969 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
      "Epoch 999/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4184 - accuracy: 0.7951 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
      "Epoch 1000/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4184 - accuracy: 0.7986 - val_loss: 0.5177 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Compulsary Task 2\n",
    "Now it's your turn.  Do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here to with layer 1,2 having activation relu and layer 3 with activation sigmoid\n",
    "\n",
    "model_student = Sequential([\n",
    "    Dense(6, input_shape=(8,), activation=\"relu\"), # 8 input and 6 hidden nodes in first hidden layer\n",
    "    Dense(6, activation=\"relu\"), # 6 nodes of next hidden layer\n",
    "    Dense(1, activation=\"sigmoid\") # final node and output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 103\n",
      "Trainable params: 103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_student.summary() # getting a bit of oversight of how the params change in the new model\n",
    "# shows the params per layer level, which is the number of relationships from previous to next layers as well as counting the neurons in the layer receiving the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/1500\n",
      "576/576 [==============================] - 0s 268us/step - loss: 0.4066 - accuracy: 0.8125 - val_loss: 0.5202 - val_accuracy: 0.7604\n",
      "Epoch 2/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4066 - accuracy: 0.8142 - val_loss: 0.5203 - val_accuracy: 0.7604\n",
      "Epoch 3/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4066 - accuracy: 0.8177 - val_loss: 0.5202 - val_accuracy: 0.7604\n",
      "Epoch 4/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4066 - accuracy: 0.8108 - val_loss: 0.5203 - val_accuracy: 0.7604\n",
      "Epoch 5/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4067 - accuracy: 0.8125 - val_loss: 0.5203 - val_accuracy: 0.7604\n",
      "Epoch 6/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4066 - accuracy: 0.8125 - val_loss: 0.5203 - val_accuracy: 0.7604\n",
      "Epoch 7/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4067 - accuracy: 0.8090 - val_loss: 0.5203 - val_accuracy: 0.7604\n",
      "Epoch 8/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4067 - accuracy: 0.8125 - val_loss: 0.5203 - val_accuracy: 0.7604\n",
      "Epoch 9/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4067 - accuracy: 0.8142 - val_loss: 0.5203 - val_accuracy: 0.7604\n",
      "Epoch 10/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4065 - accuracy: 0.8090 - val_loss: 0.5203 - val_accuracy: 0.7604\n",
      "Epoch 11/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4066 - accuracy: 0.8108 - val_loss: 0.5203 - val_accuracy: 0.7604\n",
      "Epoch 12/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4067 - accuracy: 0.8142 - val_loss: 0.5204 - val_accuracy: 0.7604\n",
      "Epoch 13/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4065 - accuracy: 0.8142 - val_loss: 0.5204 - val_accuracy: 0.7604\n",
      "Epoch 14/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4067 - accuracy: 0.8125 - val_loss: 0.5204 - val_accuracy: 0.7604\n",
      "Epoch 15/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4066 - accuracy: 0.8108 - val_loss: 0.5204 - val_accuracy: 0.7604\n",
      "Epoch 16/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4065 - accuracy: 0.8125 - val_loss: 0.5204 - val_accuracy: 0.7604\n",
      "Epoch 17/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4065 - accuracy: 0.8108 - val_loss: 0.5204 - val_accuracy: 0.7604\n",
      "Epoch 18/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4066 - accuracy: 0.8125 - val_loss: 0.5204 - val_accuracy: 0.7604\n",
      "Epoch 19/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4065 - accuracy: 0.8125 - val_loss: 0.5204 - val_accuracy: 0.7604\n",
      "Epoch 20/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4065 - accuracy: 0.8125 - val_loss: 0.5204 - val_accuracy: 0.7604\n",
      "Epoch 21/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4065 - accuracy: 0.8125 - val_loss: 0.5205 - val_accuracy: 0.7604\n",
      "Epoch 22/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4065 - accuracy: 0.8142 - val_loss: 0.5205 - val_accuracy: 0.7604\n",
      "Epoch 23/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4065 - accuracy: 0.8125 - val_loss: 0.5205 - val_accuracy: 0.7604\n",
      "Epoch 24/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4065 - accuracy: 0.8108 - val_loss: 0.5205 - val_accuracy: 0.7604\n",
      "Epoch 25/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4065 - accuracy: 0.8125 - val_loss: 0.5205 - val_accuracy: 0.7604\n",
      "Epoch 26/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4066 - accuracy: 0.8090 - val_loss: 0.5206 - val_accuracy: 0.7604\n",
      "Epoch 27/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4065 - accuracy: 0.8108 - val_loss: 0.5205 - val_accuracy: 0.7604\n",
      "Epoch 28/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4065 - accuracy: 0.8090 - val_loss: 0.5206 - val_accuracy: 0.7604\n",
      "Epoch 29/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4065 - accuracy: 0.8125 - val_loss: 0.5206 - val_accuracy: 0.7604\n",
      "Epoch 30/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4065 - accuracy: 0.8108 - val_loss: 0.5206 - val_accuracy: 0.7604\n",
      "Epoch 31/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4064 - accuracy: 0.8108 - val_loss: 0.5206 - val_accuracy: 0.7604\n",
      "Epoch 32/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4065 - accuracy: 0.8108 - val_loss: 0.5206 - val_accuracy: 0.7604\n",
      "Epoch 33/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4065 - accuracy: 0.8142 - val_loss: 0.5206 - val_accuracy: 0.7604\n",
      "Epoch 34/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4064 - accuracy: 0.8108 - val_loss: 0.5207 - val_accuracy: 0.7604\n",
      "Epoch 35/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4064 - accuracy: 0.8125 - val_loss: 0.5207 - val_accuracy: 0.7552\n",
      "Epoch 36/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4064 - accuracy: 0.8108 - val_loss: 0.5207 - val_accuracy: 0.7604\n",
      "Epoch 37/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4064 - accuracy: 0.8142 - val_loss: 0.5207 - val_accuracy: 0.7604\n",
      "Epoch 38/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4065 - accuracy: 0.8108 - val_loss: 0.5207 - val_accuracy: 0.7604\n",
      "Epoch 39/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4064 - accuracy: 0.8125 - val_loss: 0.5207 - val_accuracy: 0.7604\n",
      "Epoch 40/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4064 - accuracy: 0.8142 - val_loss: 0.5208 - val_accuracy: 0.7604\n",
      "Epoch 41/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4065 - accuracy: 0.8108 - val_loss: 0.5208 - val_accuracy: 0.7604\n",
      "Epoch 42/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4063 - accuracy: 0.8108 - val_loss: 0.5208 - val_accuracy: 0.7604\n",
      "Epoch 43/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4063 - accuracy: 0.8108 - val_loss: 0.5208 - val_accuracy: 0.7604\n",
      "Epoch 44/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4064 - accuracy: 0.8142 - val_loss: 0.5208 - val_accuracy: 0.7604\n",
      "Epoch 45/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4064 - accuracy: 0.8108 - val_loss: 0.5208 - val_accuracy: 0.7604\n",
      "Epoch 46/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4063 - accuracy: 0.8125 - val_loss: 0.5208 - val_accuracy: 0.7604\n",
      "Epoch 47/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4064 - accuracy: 0.8125 - val_loss: 0.5208 - val_accuracy: 0.7604\n",
      "Epoch 48/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4063 - accuracy: 0.8108 - val_loss: 0.5208 - val_accuracy: 0.7604\n",
      "Epoch 49/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4064 - accuracy: 0.8108 - val_loss: 0.5209 - val_accuracy: 0.7604\n",
      "Epoch 50/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4063 - accuracy: 0.8142 - val_loss: 0.5209 - val_accuracy: 0.7552\n",
      "Epoch 51/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4063 - accuracy: 0.8125 - val_loss: 0.5209 - val_accuracy: 0.7552\n",
      "Epoch 52/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4063 - accuracy: 0.8125 - val_loss: 0.5209 - val_accuracy: 0.7552\n",
      "Epoch 53/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4063 - accuracy: 0.8125 - val_loss: 0.5209 - val_accuracy: 0.7604\n",
      "Epoch 54/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4063 - accuracy: 0.8142 - val_loss: 0.5210 - val_accuracy: 0.7604\n",
      "Epoch 55/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4063 - accuracy: 0.8125 - val_loss: 0.5210 - val_accuracy: 0.7552\n",
      "Epoch 56/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4063 - accuracy: 0.8108 - val_loss: 0.5210 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4063 - accuracy: 0.8108 - val_loss: 0.5210 - val_accuracy: 0.7604\n",
      "Epoch 58/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4063 - accuracy: 0.8125 - val_loss: 0.5210 - val_accuracy: 0.7552\n",
      "Epoch 59/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4063 - accuracy: 0.8108 - val_loss: 0.5211 - val_accuracy: 0.7552\n",
      "Epoch 60/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4063 - accuracy: 0.8160 - val_loss: 0.5210 - val_accuracy: 0.7552\n",
      "Epoch 61/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4063 - accuracy: 0.8108 - val_loss: 0.5211 - val_accuracy: 0.7552\n",
      "Epoch 62/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4062 - accuracy: 0.8125 - val_loss: 0.5211 - val_accuracy: 0.7552\n",
      "Epoch 63/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4063 - accuracy: 0.8142 - val_loss: 0.5211 - val_accuracy: 0.7552\n",
      "Epoch 64/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4063 - accuracy: 0.8108 - val_loss: 0.5211 - val_accuracy: 0.7552\n",
      "Epoch 65/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4062 - accuracy: 0.8108 - val_loss: 0.5211 - val_accuracy: 0.7552\n",
      "Epoch 66/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4063 - accuracy: 0.8125 - val_loss: 0.5211 - val_accuracy: 0.7604\n",
      "Epoch 67/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4063 - accuracy: 0.8125 - val_loss: 0.5211 - val_accuracy: 0.7552\n",
      "Epoch 68/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4062 - accuracy: 0.8108 - val_loss: 0.5212 - val_accuracy: 0.7552\n",
      "Epoch 69/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4062 - accuracy: 0.8125 - val_loss: 0.5212 - val_accuracy: 0.7604\n",
      "Epoch 70/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4062 - accuracy: 0.8108 - val_loss: 0.5212 - val_accuracy: 0.7552\n",
      "Epoch 71/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4062 - accuracy: 0.8108 - val_loss: 0.5212 - val_accuracy: 0.7552\n",
      "Epoch 72/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4062 - accuracy: 0.8142 - val_loss: 0.5212 - val_accuracy: 0.7552\n",
      "Epoch 73/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4062 - accuracy: 0.8125 - val_loss: 0.5212 - val_accuracy: 0.7604\n",
      "Epoch 74/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4062 - accuracy: 0.8142 - val_loss: 0.5212 - val_accuracy: 0.7604\n",
      "Epoch 75/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4062 - accuracy: 0.8142 - val_loss: 0.5213 - val_accuracy: 0.7552\n",
      "Epoch 76/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4062 - accuracy: 0.8125 - val_loss: 0.5213 - val_accuracy: 0.7552\n",
      "Epoch 77/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4061 - accuracy: 0.8108 - val_loss: 0.5213 - val_accuracy: 0.7552\n",
      "Epoch 78/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4062 - accuracy: 0.8125 - val_loss: 0.5213 - val_accuracy: 0.7552\n",
      "Epoch 79/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4061 - accuracy: 0.8108 - val_loss: 0.5214 - val_accuracy: 0.7552\n",
      "Epoch 80/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4062 - accuracy: 0.8108 - val_loss: 0.5214 - val_accuracy: 0.7552\n",
      "Epoch 81/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4061 - accuracy: 0.8160 - val_loss: 0.5214 - val_accuracy: 0.7552\n",
      "Epoch 82/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4062 - accuracy: 0.8125 - val_loss: 0.5214 - val_accuracy: 0.7552\n",
      "Epoch 83/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4061 - accuracy: 0.8125 - val_loss: 0.5214 - val_accuracy: 0.7604\n",
      "Epoch 84/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4062 - accuracy: 0.8142 - val_loss: 0.5214 - val_accuracy: 0.7552\n",
      "Epoch 85/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4061 - accuracy: 0.8125 - val_loss: 0.5214 - val_accuracy: 0.7552\n",
      "Epoch 86/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4061 - accuracy: 0.8125 - val_loss: 0.5214 - val_accuracy: 0.7552\n",
      "Epoch 87/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4061 - accuracy: 0.8125 - val_loss: 0.5214 - val_accuracy: 0.7604\n",
      "Epoch 88/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4061 - accuracy: 0.8108 - val_loss: 0.5215 - val_accuracy: 0.7604\n",
      "Epoch 89/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4061 - accuracy: 0.8125 - val_loss: 0.5215 - val_accuracy: 0.7604\n",
      "Epoch 90/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4060 - accuracy: 0.8125 - val_loss: 0.5215 - val_accuracy: 0.7552\n",
      "Epoch 91/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4061 - accuracy: 0.8108 - val_loss: 0.5215 - val_accuracy: 0.7552\n",
      "Epoch 92/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4061 - accuracy: 0.8125 - val_loss: 0.5215 - val_accuracy: 0.7552\n",
      "Epoch 93/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4061 - accuracy: 0.8125 - val_loss: 0.5215 - val_accuracy: 0.7552\n",
      "Epoch 94/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4061 - accuracy: 0.8125 - val_loss: 0.5216 - val_accuracy: 0.7552\n",
      "Epoch 95/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4060 - accuracy: 0.8125 - val_loss: 0.5216 - val_accuracy: 0.7552\n",
      "Epoch 96/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4060 - accuracy: 0.8125 - val_loss: 0.5216 - val_accuracy: 0.7552\n",
      "Epoch 97/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4061 - accuracy: 0.8125 - val_loss: 0.5216 - val_accuracy: 0.7552\n",
      "Epoch 98/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4060 - accuracy: 0.8108 - val_loss: 0.5216 - val_accuracy: 0.7552\n",
      "Epoch 99/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4060 - accuracy: 0.8108 - val_loss: 0.5216 - val_accuracy: 0.7552\n",
      "Epoch 100/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4060 - accuracy: 0.8125 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
      "Epoch 101/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4060 - accuracy: 0.8090 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
      "Epoch 102/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4060 - accuracy: 0.8125 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
      "Epoch 103/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4060 - accuracy: 0.8142 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
      "Epoch 104/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4060 - accuracy: 0.8108 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
      "Epoch 105/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4061 - accuracy: 0.8108 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
      "Epoch 106/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4060 - accuracy: 0.8125 - val_loss: 0.5218 - val_accuracy: 0.7552\n",
      "Epoch 107/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4060 - accuracy: 0.8108 - val_loss: 0.5218 - val_accuracy: 0.7552\n",
      "Epoch 108/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4060 - accuracy: 0.8125 - val_loss: 0.5218 - val_accuracy: 0.7552\n",
      "Epoch 109/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4059 - accuracy: 0.8090 - val_loss: 0.5218 - val_accuracy: 0.7552\n",
      "Epoch 110/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4060 - accuracy: 0.8125 - val_loss: 0.5218 - val_accuracy: 0.7552\n",
      "Epoch 111/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4060 - accuracy: 0.8125 - val_loss: 0.5219 - val_accuracy: 0.7552\n",
      "Epoch 112/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4059 - accuracy: 0.8090 - val_loss: 0.5219 - val_accuracy: 0.7552\n",
      "Epoch 113/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 35us/step - loss: 0.4059 - accuracy: 0.8108 - val_loss: 0.5219 - val_accuracy: 0.7552\n",
      "Epoch 114/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4059 - accuracy: 0.8142 - val_loss: 0.5219 - val_accuracy: 0.7552\n",
      "Epoch 115/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4059 - accuracy: 0.8142 - val_loss: 0.5219 - val_accuracy: 0.7552\n",
      "Epoch 116/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4059 - accuracy: 0.8125 - val_loss: 0.5219 - val_accuracy: 0.7552\n",
      "Epoch 117/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4059 - accuracy: 0.8108 - val_loss: 0.5219 - val_accuracy: 0.7552\n",
      "Epoch 118/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4059 - accuracy: 0.8125 - val_loss: 0.5219 - val_accuracy: 0.7552\n",
      "Epoch 119/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4059 - accuracy: 0.8142 - val_loss: 0.5219 - val_accuracy: 0.7552\n",
      "Epoch 120/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4059 - accuracy: 0.8108 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
      "Epoch 121/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4058 - accuracy: 0.8160 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
      "Epoch 122/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4058 - accuracy: 0.8142 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
      "Epoch 123/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4059 - accuracy: 0.8125 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
      "Epoch 124/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4058 - accuracy: 0.8125 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
      "Epoch 125/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4058 - accuracy: 0.8108 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
      "Epoch 126/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4058 - accuracy: 0.8142 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
      "Epoch 127/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4058 - accuracy: 0.8125 - val_loss: 0.5221 - val_accuracy: 0.7552\n",
      "Epoch 128/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4058 - accuracy: 0.8142 - val_loss: 0.5221 - val_accuracy: 0.7552\n",
      "Epoch 129/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4058 - accuracy: 0.8125 - val_loss: 0.5221 - val_accuracy: 0.7552\n",
      "Epoch 130/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4059 - accuracy: 0.8108 - val_loss: 0.5221 - val_accuracy: 0.7552\n",
      "Epoch 131/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4059 - accuracy: 0.8142 - val_loss: 0.5221 - val_accuracy: 0.7552\n",
      "Epoch 132/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4058 - accuracy: 0.8108 - val_loss: 0.5222 - val_accuracy: 0.7552\n",
      "Epoch 133/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4058 - accuracy: 0.8108 - val_loss: 0.5222 - val_accuracy: 0.7552\n",
      "Epoch 134/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4058 - accuracy: 0.8108 - val_loss: 0.5222 - val_accuracy: 0.7552\n",
      "Epoch 135/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4057 - accuracy: 0.8125 - val_loss: 0.5222 - val_accuracy: 0.7552\n",
      "Epoch 136/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4058 - accuracy: 0.8108 - val_loss: 0.5222 - val_accuracy: 0.7552\n",
      "Epoch 137/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4058 - accuracy: 0.8125 - val_loss: 0.5223 - val_accuracy: 0.7552\n",
      "Epoch 138/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4059 - accuracy: 0.8090 - val_loss: 0.5223 - val_accuracy: 0.7552\n",
      "Epoch 139/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4058 - accuracy: 0.8108 - val_loss: 0.5223 - val_accuracy: 0.7552\n",
      "Epoch 140/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4058 - accuracy: 0.8108 - val_loss: 0.5223 - val_accuracy: 0.7552\n",
      "Epoch 141/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4057 - accuracy: 0.8125 - val_loss: 0.5223 - val_accuracy: 0.7552\n",
      "Epoch 142/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4058 - accuracy: 0.8125 - val_loss: 0.5223 - val_accuracy: 0.7552\n",
      "Epoch 143/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4057 - accuracy: 0.8125 - val_loss: 0.5223 - val_accuracy: 0.7552\n",
      "Epoch 144/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4057 - accuracy: 0.8142 - val_loss: 0.5224 - val_accuracy: 0.7552\n",
      "Epoch 145/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4058 - accuracy: 0.8125 - val_loss: 0.5224 - val_accuracy: 0.7552\n",
      "Epoch 146/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4057 - accuracy: 0.8125 - val_loss: 0.5224 - val_accuracy: 0.7552\n",
      "Epoch 147/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4058 - accuracy: 0.8142 - val_loss: 0.5224 - val_accuracy: 0.7552\n",
      "Epoch 148/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4057 - accuracy: 0.8142 - val_loss: 0.5224 - val_accuracy: 0.7552\n",
      "Epoch 149/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4056 - accuracy: 0.8142 - val_loss: 0.5224 - val_accuracy: 0.7552\n",
      "Epoch 150/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4057 - accuracy: 0.8142 - val_loss: 0.5224 - val_accuracy: 0.7552\n",
      "Epoch 151/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4056 - accuracy: 0.8090 - val_loss: 0.5225 - val_accuracy: 0.7552\n",
      "Epoch 152/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4056 - accuracy: 0.8142 - val_loss: 0.5224 - val_accuracy: 0.7552\n",
      "Epoch 153/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4057 - accuracy: 0.8125 - val_loss: 0.5224 - val_accuracy: 0.7604\n",
      "Epoch 154/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4056 - accuracy: 0.8108 - val_loss: 0.5225 - val_accuracy: 0.7552\n",
      "Epoch 155/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4057 - accuracy: 0.8108 - val_loss: 0.5225 - val_accuracy: 0.7552\n",
      "Epoch 156/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4057 - accuracy: 0.8108 - val_loss: 0.5225 - val_accuracy: 0.7552\n",
      "Epoch 157/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4057 - accuracy: 0.8177 - val_loss: 0.5225 - val_accuracy: 0.7552\n",
      "Epoch 158/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4057 - accuracy: 0.8108 - val_loss: 0.5225 - val_accuracy: 0.7552\n",
      "Epoch 159/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4057 - accuracy: 0.8142 - val_loss: 0.5225 - val_accuracy: 0.7604\n",
      "Epoch 160/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4058 - accuracy: 0.8108 - val_loss: 0.5226 - val_accuracy: 0.7604\n",
      "Epoch 161/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4056 - accuracy: 0.8125 - val_loss: 0.5226 - val_accuracy: 0.7604\n",
      "Epoch 162/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4057 - accuracy: 0.8125 - val_loss: 0.5225 - val_accuracy: 0.7604\n",
      "Epoch 163/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4056 - accuracy: 0.8108 - val_loss: 0.5226 - val_accuracy: 0.7604\n",
      "Epoch 164/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4057 - accuracy: 0.8090 - val_loss: 0.5226 - val_accuracy: 0.7604\n",
      "Epoch 165/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4056 - accuracy: 0.8108 - val_loss: 0.5227 - val_accuracy: 0.7552\n",
      "Epoch 166/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4056 - accuracy: 0.8125 - val_loss: 0.5227 - val_accuracy: 0.7604\n",
      "Epoch 167/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4056 - accuracy: 0.8160 - val_loss: 0.5227 - val_accuracy: 0.7604\n",
      "Epoch 168/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4056 - accuracy: 0.8125 - val_loss: 0.5227 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4056 - accuracy: 0.8108 - val_loss: 0.5227 - val_accuracy: 0.7552\n",
      "Epoch 170/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4056 - accuracy: 0.8108 - val_loss: 0.5227 - val_accuracy: 0.7552\n",
      "Epoch 171/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4056 - accuracy: 0.8125 - val_loss: 0.5228 - val_accuracy: 0.7552\n",
      "Epoch 172/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4058 - accuracy: 0.8177 - val_loss: 0.5228 - val_accuracy: 0.7552\n",
      "Epoch 173/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4056 - accuracy: 0.8125 - val_loss: 0.5228 - val_accuracy: 0.7552\n",
      "Epoch 174/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4055 - accuracy: 0.8142 - val_loss: 0.5228 - val_accuracy: 0.7552\n",
      "Epoch 175/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4056 - accuracy: 0.8142 - val_loss: 0.5228 - val_accuracy: 0.7552\n",
      "Epoch 176/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4055 - accuracy: 0.8160 - val_loss: 0.5228 - val_accuracy: 0.7604\n",
      "Epoch 177/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4055 - accuracy: 0.8108 - val_loss: 0.5228 - val_accuracy: 0.7604\n",
      "Epoch 178/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4056 - accuracy: 0.8125 - val_loss: 0.5228 - val_accuracy: 0.7604\n",
      "Epoch 179/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4057 - accuracy: 0.8160 - val_loss: 0.5228 - val_accuracy: 0.7604\n",
      "Epoch 180/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4055 - accuracy: 0.8160 - val_loss: 0.5228 - val_accuracy: 0.7552\n",
      "Epoch 181/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4055 - accuracy: 0.8125 - val_loss: 0.5229 - val_accuracy: 0.7552\n",
      "Epoch 182/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4056 - accuracy: 0.8142 - val_loss: 0.5229 - val_accuracy: 0.7552\n",
      "Epoch 183/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4055 - accuracy: 0.8125 - val_loss: 0.5229 - val_accuracy: 0.7604\n",
      "Epoch 184/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4055 - accuracy: 0.8125 - val_loss: 0.5229 - val_accuracy: 0.7604\n",
      "Epoch 185/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4055 - accuracy: 0.8142 - val_loss: 0.5229 - val_accuracy: 0.7552\n",
      "Epoch 186/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4055 - accuracy: 0.8125 - val_loss: 0.5229 - val_accuracy: 0.7552\n",
      "Epoch 187/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4055 - accuracy: 0.8142 - val_loss: 0.5230 - val_accuracy: 0.7552\n",
      "Epoch 188/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4056 - accuracy: 0.8160 - val_loss: 0.5230 - val_accuracy: 0.7552\n",
      "Epoch 189/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4055 - accuracy: 0.8142 - val_loss: 0.5230 - val_accuracy: 0.7552\n",
      "Epoch 190/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4055 - accuracy: 0.8142 - val_loss: 0.5230 - val_accuracy: 0.7552\n",
      "Epoch 191/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4054 - accuracy: 0.8142 - val_loss: 0.5230 - val_accuracy: 0.7552\n",
      "Epoch 192/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4058 - accuracy: 0.8142 - val_loss: 0.5230 - val_accuracy: 0.7552\n",
      "Epoch 193/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4055 - accuracy: 0.8125 - val_loss: 0.5230 - val_accuracy: 0.7552\n",
      "Epoch 194/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4056 - accuracy: 0.8142 - val_loss: 0.5230 - val_accuracy: 0.7604\n",
      "Epoch 195/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4054 - accuracy: 0.8125 - val_loss: 0.5230 - val_accuracy: 0.7604\n",
      "Epoch 196/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4055 - accuracy: 0.8125 - val_loss: 0.5231 - val_accuracy: 0.7552\n",
      "Epoch 197/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4054 - accuracy: 0.8142 - val_loss: 0.5230 - val_accuracy: 0.7604\n",
      "Epoch 198/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4054 - accuracy: 0.8142 - val_loss: 0.5231 - val_accuracy: 0.7552\n",
      "Epoch 199/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4055 - accuracy: 0.8160 - val_loss: 0.5231 - val_accuracy: 0.7604\n",
      "Epoch 200/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4055 - accuracy: 0.8142 - val_loss: 0.5231 - val_accuracy: 0.7552\n",
      "Epoch 201/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4055 - accuracy: 0.8142 - val_loss: 0.5231 - val_accuracy: 0.7552\n",
      "Epoch 202/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4054 - accuracy: 0.8160 - val_loss: 0.5231 - val_accuracy: 0.7604\n",
      "Epoch 203/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4054 - accuracy: 0.8125 - val_loss: 0.5231 - val_accuracy: 0.7604\n",
      "Epoch 204/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4054 - accuracy: 0.8142 - val_loss: 0.5231 - val_accuracy: 0.7604\n",
      "Epoch 205/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4053 - accuracy: 0.8160 - val_loss: 0.5232 - val_accuracy: 0.7604\n",
      "Epoch 206/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4055 - accuracy: 0.8125 - val_loss: 0.5232 - val_accuracy: 0.7604\n",
      "Epoch 207/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4054 - accuracy: 0.8142 - val_loss: 0.5232 - val_accuracy: 0.7604\n",
      "Epoch 208/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4054 - accuracy: 0.8108 - val_loss: 0.5232 - val_accuracy: 0.7604\n",
      "Epoch 209/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4054 - accuracy: 0.8142 - val_loss: 0.5232 - val_accuracy: 0.7604\n",
      "Epoch 210/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4054 - accuracy: 0.8108 - val_loss: 0.5232 - val_accuracy: 0.7604\n",
      "Epoch 211/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4053 - accuracy: 0.8142 - val_loss: 0.5232 - val_accuracy: 0.7604\n",
      "Epoch 212/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4053 - accuracy: 0.8125 - val_loss: 0.5232 - val_accuracy: 0.7604\n",
      "Epoch 213/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4054 - accuracy: 0.8125 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
      "Epoch 214/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4054 - accuracy: 0.8142 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
      "Epoch 215/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4054 - accuracy: 0.8108 - val_loss: 0.5233 - val_accuracy: 0.7604\n",
      "Epoch 216/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4053 - accuracy: 0.8125 - val_loss: 0.5233 - val_accuracy: 0.7604\n",
      "Epoch 217/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4053 - accuracy: 0.8108 - val_loss: 0.5233 - val_accuracy: 0.7604\n",
      "Epoch 218/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4053 - accuracy: 0.8108 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
      "Epoch 219/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4053 - accuracy: 0.8125 - val_loss: 0.5233 - val_accuracy: 0.7604\n",
      "Epoch 220/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4053 - accuracy: 0.8125 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
      "Epoch 221/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4053 - accuracy: 0.8125 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
      "Epoch 222/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4052 - accuracy: 0.8125 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
      "Epoch 223/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4053 - accuracy: 0.8142 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
      "Epoch 224/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4052 - accuracy: 0.8142 - val_loss: 0.5234 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4053 - accuracy: 0.8142 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
      "Epoch 226/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4053 - accuracy: 0.8125 - val_loss: 0.5234 - val_accuracy: 0.7552\n",
      "Epoch 227/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4053 - accuracy: 0.8108 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
      "Epoch 228/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4053 - accuracy: 0.8125 - val_loss: 0.5235 - val_accuracy: 0.7604\n",
      "Epoch 229/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4052 - accuracy: 0.8108 - val_loss: 0.5235 - val_accuracy: 0.7604\n",
      "Epoch 230/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4053 - accuracy: 0.8125 - val_loss: 0.5235 - val_accuracy: 0.7604\n",
      "Epoch 231/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4052 - accuracy: 0.8125 - val_loss: 0.5235 - val_accuracy: 0.7604\n",
      "Epoch 232/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4053 - accuracy: 0.8142 - val_loss: 0.5235 - val_accuracy: 0.7604\n",
      "Epoch 233/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4053 - accuracy: 0.8142 - val_loss: 0.5235 - val_accuracy: 0.7552\n",
      "Epoch 234/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4052 - accuracy: 0.8125 - val_loss: 0.5235 - val_accuracy: 0.7552\n",
      "Epoch 235/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4053 - accuracy: 0.8142 - val_loss: 0.5235 - val_accuracy: 0.7552\n",
      "Epoch 236/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4053 - accuracy: 0.8142 - val_loss: 0.5235 - val_accuracy: 0.7604\n",
      "Epoch 237/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4052 - accuracy: 0.8108 - val_loss: 0.5236 - val_accuracy: 0.7604\n",
      "Epoch 238/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4053 - accuracy: 0.8125 - val_loss: 0.5236 - val_accuracy: 0.7604\n",
      "Epoch 239/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4052 - accuracy: 0.8142 - val_loss: 0.5236 - val_accuracy: 0.7604\n",
      "Epoch 240/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4052 - accuracy: 0.8160 - val_loss: 0.5237 - val_accuracy: 0.7604\n",
      "Epoch 241/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4052 - accuracy: 0.8125 - val_loss: 0.5237 - val_accuracy: 0.7604\n",
      "Epoch 242/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4052 - accuracy: 0.8125 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
      "Epoch 243/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4053 - accuracy: 0.8142 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
      "Epoch 244/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4052 - accuracy: 0.8125 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
      "Epoch 245/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4054 - accuracy: 0.8142 - val_loss: 0.5237 - val_accuracy: 0.7604\n",
      "Epoch 246/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4052 - accuracy: 0.8125 - val_loss: 0.5237 - val_accuracy: 0.7604\n",
      "Epoch 247/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4052 - accuracy: 0.8142 - val_loss: 0.5237 - val_accuracy: 0.7604\n",
      "Epoch 248/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4052 - accuracy: 0.8160 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
      "Epoch 249/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4051 - accuracy: 0.8142 - val_loss: 0.5238 - val_accuracy: 0.7552\n",
      "Epoch 250/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4051 - accuracy: 0.8160 - val_loss: 0.5238 - val_accuracy: 0.7604\n",
      "Epoch 251/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4052 - accuracy: 0.8125 - val_loss: 0.5238 - val_accuracy: 0.7604\n",
      "Epoch 252/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4052 - accuracy: 0.8142 - val_loss: 0.5238 - val_accuracy: 0.7604\n",
      "Epoch 253/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4052 - accuracy: 0.8142 - val_loss: 0.5238 - val_accuracy: 0.7604\n",
      "Epoch 254/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4052 - accuracy: 0.8125 - val_loss: 0.5238 - val_accuracy: 0.7604\n",
      "Epoch 255/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4052 - accuracy: 0.8125 - val_loss: 0.5238 - val_accuracy: 0.7604\n",
      "Epoch 256/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4051 - accuracy: 0.8125 - val_loss: 0.5238 - val_accuracy: 0.7604\n",
      "Epoch 257/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4051 - accuracy: 0.8142 - val_loss: 0.5238 - val_accuracy: 0.7604\n",
      "Epoch 258/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4051 - accuracy: 0.8125 - val_loss: 0.5239 - val_accuracy: 0.7604\n",
      "Epoch 259/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4051 - accuracy: 0.8142 - val_loss: 0.5239 - val_accuracy: 0.7604\n",
      "Epoch 260/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4052 - accuracy: 0.8125 - val_loss: 0.5239 - val_accuracy: 0.7552\n",
      "Epoch 261/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4051 - accuracy: 0.8142 - val_loss: 0.5239 - val_accuracy: 0.7552\n",
      "Epoch 262/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4051 - accuracy: 0.8125 - val_loss: 0.5239 - val_accuracy: 0.7604\n",
      "Epoch 263/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4051 - accuracy: 0.8142 - val_loss: 0.5239 - val_accuracy: 0.7604\n",
      "Epoch 264/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4051 - accuracy: 0.8108 - val_loss: 0.5239 - val_accuracy: 0.7604\n",
      "Epoch 265/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4050 - accuracy: 0.8142 - val_loss: 0.5239 - val_accuracy: 0.7552\n",
      "Epoch 266/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4051 - accuracy: 0.8125 - val_loss: 0.5239 - val_accuracy: 0.7552\n",
      "Epoch 267/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4051 - accuracy: 0.8142 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
      "Epoch 268/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4050 - accuracy: 0.8142 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
      "Epoch 269/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4050 - accuracy: 0.8125 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
      "Epoch 270/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4051 - accuracy: 0.8125 - val_loss: 0.5240 - val_accuracy: 0.7604\n",
      "Epoch 271/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4050 - accuracy: 0.8142 - val_loss: 0.5240 - val_accuracy: 0.7604\n",
      "Epoch 272/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4050 - accuracy: 0.8142 - val_loss: 0.5241 - val_accuracy: 0.7604\n",
      "Epoch 273/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4051 - accuracy: 0.8142 - val_loss: 0.5241 - val_accuracy: 0.7604\n",
      "Epoch 274/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4050 - accuracy: 0.8142 - val_loss: 0.5241 - val_accuracy: 0.7552\n",
      "Epoch 275/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4050 - accuracy: 0.8160 - val_loss: 0.5241 - val_accuracy: 0.7604\n",
      "Epoch 276/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4052 - accuracy: 0.8108 - val_loss: 0.5241 - val_accuracy: 0.7552\n",
      "Epoch 277/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4049 - accuracy: 0.8125 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 278/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4050 - accuracy: 0.8108 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 279/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4051 - accuracy: 0.8125 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 280/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4050 - accuracy: 0.8142 - val_loss: 0.5242 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4051 - accuracy: 0.8160 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 282/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4050 - accuracy: 0.8125 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 283/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4049 - accuracy: 0.8142 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 284/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4050 - accuracy: 0.8090 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 285/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4050 - accuracy: 0.8108 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 286/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4049 - accuracy: 0.8160 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 287/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4051 - accuracy: 0.8142 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
      "Epoch 288/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4050 - accuracy: 0.8108 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
      "Epoch 289/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4049 - accuracy: 0.8142 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
      "Epoch 290/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4050 - accuracy: 0.8108 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
      "Epoch 291/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4049 - accuracy: 0.8108 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 292/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4049 - accuracy: 0.8142 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
      "Epoch 293/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4050 - accuracy: 0.8160 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
      "Epoch 294/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4049 - accuracy: 0.8108 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
      "Epoch 295/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4050 - accuracy: 0.8125 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 296/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4049 - accuracy: 0.8108 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 297/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4050 - accuracy: 0.8142 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 298/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4049 - accuracy: 0.8142 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 299/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4049 - accuracy: 0.8142 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 300/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4049 - accuracy: 0.8108 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 301/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4049 - accuracy: 0.8160 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 302/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4049 - accuracy: 0.8142 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 303/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4048 - accuracy: 0.8125 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 304/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4049 - accuracy: 0.8108 - val_loss: 0.5245 - val_accuracy: 0.7500\n",
      "Epoch 305/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4048 - accuracy: 0.8108 - val_loss: 0.5245 - val_accuracy: 0.7552\n",
      "Epoch 306/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4049 - accuracy: 0.8125 - val_loss: 0.5245 - val_accuracy: 0.7552\n",
      "Epoch 307/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4048 - accuracy: 0.8108 - val_loss: 0.5245 - val_accuracy: 0.7552\n",
      "Epoch 308/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4048 - accuracy: 0.8142 - val_loss: 0.5245 - val_accuracy: 0.7552\n",
      "Epoch 309/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4048 - accuracy: 0.8108 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
      "Epoch 310/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4049 - accuracy: 0.8142 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
      "Epoch 311/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4049 - accuracy: 0.8108 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
      "Epoch 312/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4048 - accuracy: 0.8142 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
      "Epoch 313/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4048 - accuracy: 0.8125 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
      "Epoch 314/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4050 - accuracy: 0.8142 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
      "Epoch 315/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4048 - accuracy: 0.8125 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
      "Epoch 316/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4047 - accuracy: 0.8160 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
      "Epoch 317/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4047 - accuracy: 0.8108 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
      "Epoch 318/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4048 - accuracy: 0.8142 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
      "Epoch 319/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4048 - accuracy: 0.8160 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
      "Epoch 320/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4047 - accuracy: 0.8125 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
      "Epoch 321/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4048 - accuracy: 0.8142 - val_loss: 0.5246 - val_accuracy: 0.7500\n",
      "Epoch 322/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4048 - accuracy: 0.8108 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
      "Epoch 323/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4047 - accuracy: 0.8090 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
      "Epoch 324/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4048 - accuracy: 0.8108 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
      "Epoch 325/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4048 - accuracy: 0.8142 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
      "Epoch 326/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4048 - accuracy: 0.8160 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
      "Epoch 327/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4047 - accuracy: 0.8142 - val_loss: 0.5247 - val_accuracy: 0.7500\n",
      "Epoch 328/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4047 - accuracy: 0.8142 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
      "Epoch 329/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4048 - accuracy: 0.8142 - val_loss: 0.5247 - val_accuracy: 0.7500\n",
      "Epoch 330/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4047 - accuracy: 0.8108 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
      "Epoch 331/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4046 - accuracy: 0.8108 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
      "Epoch 332/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4046 - accuracy: 0.8142 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
      "Epoch 333/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4047 - accuracy: 0.8108 - val_loss: 0.5248 - val_accuracy: 0.7552\n",
      "Epoch 334/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4047 - accuracy: 0.8108 - val_loss: 0.5248 - val_accuracy: 0.7552\n",
      "Epoch 335/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4046 - accuracy: 0.8125 - val_loss: 0.5248 - val_accuracy: 0.7552\n",
      "Epoch 336/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4049 - accuracy: 0.8142 - val_loss: 0.5248 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4047 - accuracy: 0.8160 - val_loss: 0.5248 - val_accuracy: 0.7552\n",
      "Epoch 338/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4047 - accuracy: 0.8125 - val_loss: 0.5248 - val_accuracy: 0.7552\n",
      "Epoch 339/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4047 - accuracy: 0.8125 - val_loss: 0.5248 - val_accuracy: 0.7552\n",
      "Epoch 340/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4046 - accuracy: 0.8125 - val_loss: 0.5248 - val_accuracy: 0.7552\n",
      "Epoch 341/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4048 - accuracy: 0.8125 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
      "Epoch 342/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4047 - accuracy: 0.8108 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
      "Epoch 343/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4046 - accuracy: 0.8125 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
      "Epoch 344/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4046 - accuracy: 0.8160 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
      "Epoch 345/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4046 - accuracy: 0.8142 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
      "Epoch 346/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4046 - accuracy: 0.8073 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
      "Epoch 347/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4048 - accuracy: 0.8142 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
      "Epoch 348/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4046 - accuracy: 0.8108 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
      "Epoch 349/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4046 - accuracy: 0.8142 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
      "Epoch 350/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4046 - accuracy: 0.8125 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
      "Epoch 351/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4047 - accuracy: 0.8142 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
      "Epoch 352/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4047 - accuracy: 0.8090 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
      "Epoch 353/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4046 - accuracy: 0.8125 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
      "Epoch 354/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4046 - accuracy: 0.8108 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
      "Epoch 355/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4045 - accuracy: 0.8090 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
      "Epoch 356/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4046 - accuracy: 0.8125 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
      "Epoch 357/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4046 - accuracy: 0.8125 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
      "Epoch 358/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4047 - accuracy: 0.8108 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
      "Epoch 359/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4046 - accuracy: 0.8125 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
      "Epoch 360/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4047 - accuracy: 0.8125 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
      "Epoch 361/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4045 - accuracy: 0.8142 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
      "Epoch 362/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4045 - accuracy: 0.8108 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
      "Epoch 363/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4046 - accuracy: 0.8090 - val_loss: 0.5252 - val_accuracy: 0.7552\n",
      "Epoch 364/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4046 - accuracy: 0.8108 - val_loss: 0.5252 - val_accuracy: 0.7552\n",
      "Epoch 365/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4046 - accuracy: 0.8108 - val_loss: 0.5252 - val_accuracy: 0.7552\n",
      "Epoch 366/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4046 - accuracy: 0.8090 - val_loss: 0.5252 - val_accuracy: 0.7552\n",
      "Epoch 367/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4045 - accuracy: 0.8125 - val_loss: 0.5252 - val_accuracy: 0.7552\n",
      "Epoch 368/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4046 - accuracy: 0.8125 - val_loss: 0.5252 - val_accuracy: 0.7552\n",
      "Epoch 369/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4045 - accuracy: 0.8108 - val_loss: 0.5252 - val_accuracy: 0.7552\n",
      "Epoch 370/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4046 - accuracy: 0.8108 - val_loss: 0.5252 - val_accuracy: 0.7552\n",
      "Epoch 371/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4045 - accuracy: 0.8160 - val_loss: 0.5252 - val_accuracy: 0.7552\n",
      "Epoch 372/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4046 - accuracy: 0.8090 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
      "Epoch 373/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4046 - accuracy: 0.8108 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
      "Epoch 374/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4045 - accuracy: 0.8125 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
      "Epoch 375/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4045 - accuracy: 0.8125 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
      "Epoch 376/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4045 - accuracy: 0.8125 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
      "Epoch 377/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4045 - accuracy: 0.8108 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
      "Epoch 378/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4044 - accuracy: 0.8108 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
      "Epoch 379/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4045 - accuracy: 0.8090 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
      "Epoch 380/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4045 - accuracy: 0.8108 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
      "Epoch 381/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4044 - accuracy: 0.8090 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
      "Epoch 382/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4044 - accuracy: 0.8125 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
      "Epoch 383/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4044 - accuracy: 0.8125 - val_loss: 0.5254 - val_accuracy: 0.7552\n",
      "Epoch 384/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4044 - accuracy: 0.8108 - val_loss: 0.5254 - val_accuracy: 0.7552\n",
      "Epoch 385/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4045 - accuracy: 0.8125 - val_loss: 0.5254 - val_accuracy: 0.7552\n",
      "Epoch 386/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4045 - accuracy: 0.8090 - val_loss: 0.5254 - val_accuracy: 0.7552\n",
      "Epoch 387/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4044 - accuracy: 0.8108 - val_loss: 0.5255 - val_accuracy: 0.7552\n",
      "Epoch 388/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4044 - accuracy: 0.8125 - val_loss: 0.5255 - val_accuracy: 0.7552\n",
      "Epoch 389/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4044 - accuracy: 0.8090 - val_loss: 0.5255 - val_accuracy: 0.7552\n",
      "Epoch 390/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4044 - accuracy: 0.8142 - val_loss: 0.5255 - val_accuracy: 0.7552\n",
      "Epoch 391/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4045 - accuracy: 0.8108 - val_loss: 0.5255 - val_accuracy: 0.7552\n",
      "Epoch 392/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4044 - accuracy: 0.8125 - val_loss: 0.5255 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4045 - accuracy: 0.8090 - val_loss: 0.5255 - val_accuracy: 0.7552\n",
      "Epoch 394/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4044 - accuracy: 0.8125 - val_loss: 0.5255 - val_accuracy: 0.7552\n",
      "Epoch 395/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4043 - accuracy: 0.8125 - val_loss: 0.5255 - val_accuracy: 0.7552\n",
      "Epoch 396/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4044 - accuracy: 0.8090 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
      "Epoch 397/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4044 - accuracy: 0.8108 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
      "Epoch 398/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4044 - accuracy: 0.8125 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
      "Epoch 399/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4044 - accuracy: 0.8108 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
      "Epoch 400/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4043 - accuracy: 0.8108 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
      "Epoch 401/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4043 - accuracy: 0.8108 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
      "Epoch 402/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4043 - accuracy: 0.8108 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
      "Epoch 403/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4044 - accuracy: 0.8108 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
      "Epoch 404/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4044 - accuracy: 0.8125 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
      "Epoch 405/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4044 - accuracy: 0.8108 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
      "Epoch 406/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4043 - accuracy: 0.8108 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
      "Epoch 407/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4043 - accuracy: 0.8108 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
      "Epoch 408/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4044 - accuracy: 0.8108 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
      "Epoch 409/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4043 - accuracy: 0.8125 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
      "Epoch 410/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4043 - accuracy: 0.8090 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
      "Epoch 411/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4043 - accuracy: 0.8090 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
      "Epoch 412/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4043 - accuracy: 0.8108 - val_loss: 0.5258 - val_accuracy: 0.7552\n",
      "Epoch 413/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4043 - accuracy: 0.8142 - val_loss: 0.5258 - val_accuracy: 0.7552\n",
      "Epoch 414/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4043 - accuracy: 0.8125 - val_loss: 0.5258 - val_accuracy: 0.7552\n",
      "Epoch 415/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4043 - accuracy: 0.8142 - val_loss: 0.5258 - val_accuracy: 0.7552\n",
      "Epoch 416/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4043 - accuracy: 0.8108 - val_loss: 0.5258 - val_accuracy: 0.7552\n",
      "Epoch 417/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4042 - accuracy: 0.8125 - val_loss: 0.5258 - val_accuracy: 0.7552\n",
      "Epoch 418/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4042 - accuracy: 0.8125 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
      "Epoch 419/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4042 - accuracy: 0.8108 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
      "Epoch 420/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4043 - accuracy: 0.8108 - val_loss: 0.5258 - val_accuracy: 0.7552\n",
      "Epoch 421/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4043 - accuracy: 0.8125 - val_loss: 0.5259 - val_accuracy: 0.7552\n",
      "Epoch 422/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4043 - accuracy: 0.8090 - val_loss: 0.5259 - val_accuracy: 0.7552\n",
      "Epoch 423/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4042 - accuracy: 0.8108 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
      "Epoch 424/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4042 - accuracy: 0.8125 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
      "Epoch 425/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4043 - accuracy: 0.8073 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
      "Epoch 426/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4042 - accuracy: 0.8142 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
      "Epoch 427/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4042 - accuracy: 0.8090 - val_loss: 0.5259 - val_accuracy: 0.7552\n",
      "Epoch 428/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4042 - accuracy: 0.8108 - val_loss: 0.5259 - val_accuracy: 0.7552\n",
      "Epoch 429/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4042 - accuracy: 0.8090 - val_loss: 0.5260 - val_accuracy: 0.7552\n",
      "Epoch 430/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4041 - accuracy: 0.8125 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
      "Epoch 431/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4041 - accuracy: 0.8090 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
      "Epoch 432/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4042 - accuracy: 0.8108 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
      "Epoch 433/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4042 - accuracy: 0.8090 - val_loss: 0.5260 - val_accuracy: 0.7552\n",
      "Epoch 434/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4041 - accuracy: 0.8090 - val_loss: 0.5260 - val_accuracy: 0.7552\n",
      "Epoch 435/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4041 - accuracy: 0.8108 - val_loss: 0.5260 - val_accuracy: 0.7552\n",
      "Epoch 436/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4042 - accuracy: 0.8108 - val_loss: 0.5260 - val_accuracy: 0.7552\n",
      "Epoch 437/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4042 - accuracy: 0.8108 - val_loss: 0.5260 - val_accuracy: 0.7552\n",
      "Epoch 438/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4042 - accuracy: 0.8108 - val_loss: 0.5260 - val_accuracy: 0.7552\n",
      "Epoch 439/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4041 - accuracy: 0.8125 - val_loss: 0.5260 - val_accuracy: 0.7500\n",
      "Epoch 440/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4042 - accuracy: 0.8108 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
      "Epoch 441/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4041 - accuracy: 0.8125 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
      "Epoch 442/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4040 - accuracy: 0.8125 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
      "Epoch 443/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4041 - accuracy: 0.8090 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
      "Epoch 444/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4041 - accuracy: 0.8073 - val_loss: 0.5261 - val_accuracy: 0.7552\n",
      "Epoch 445/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4041 - accuracy: 0.8108 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
      "Epoch 446/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4041 - accuracy: 0.8108 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
      "Epoch 447/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4041 - accuracy: 0.8108 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
      "Epoch 448/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4041 - accuracy: 0.8125 - val_loss: 0.5261 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4041 - accuracy: 0.8090 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
      "Epoch 450/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4041 - accuracy: 0.8108 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
      "Epoch 451/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4041 - accuracy: 0.8090 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
      "Epoch 452/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4041 - accuracy: 0.8125 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
      "Epoch 453/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4041 - accuracy: 0.8125 - val_loss: 0.5262 - val_accuracy: 0.7500\n",
      "Epoch 454/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4041 - accuracy: 0.8073 - val_loss: 0.5262 - val_accuracy: 0.7500\n",
      "Epoch 455/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4040 - accuracy: 0.8108 - val_loss: 0.5262 - val_accuracy: 0.7500\n",
      "Epoch 456/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4041 - accuracy: 0.8108 - val_loss: 0.5262 - val_accuracy: 0.7500\n",
      "Epoch 457/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4040 - accuracy: 0.8090 - val_loss: 0.5262 - val_accuracy: 0.7500\n",
      "Epoch 458/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4041 - accuracy: 0.8108 - val_loss: 0.5262 - val_accuracy: 0.7500\n",
      "Epoch 459/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4041 - accuracy: 0.8090 - val_loss: 0.5263 - val_accuracy: 0.7500\n",
      "Epoch 460/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4040 - accuracy: 0.8090 - val_loss: 0.5263 - val_accuracy: 0.7500\n",
      "Epoch 461/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4039 - accuracy: 0.8090 - val_loss: 0.5263 - val_accuracy: 0.7500\n",
      "Epoch 462/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4041 - accuracy: 0.8073 - val_loss: 0.5263 - val_accuracy: 0.7552\n",
      "Epoch 463/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4040 - accuracy: 0.8108 - val_loss: 0.5263 - val_accuracy: 0.7552\n",
      "Epoch 464/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4040 - accuracy: 0.8108 - val_loss: 0.5263 - val_accuracy: 0.7500\n",
      "Epoch 465/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4040 - accuracy: 0.8125 - val_loss: 0.5263 - val_accuracy: 0.7500\n",
      "Epoch 466/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4041 - accuracy: 0.8073 - val_loss: 0.5264 - val_accuracy: 0.7552\n",
      "Epoch 467/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4040 - accuracy: 0.8090 - val_loss: 0.5264 - val_accuracy: 0.7552\n",
      "Epoch 468/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4040 - accuracy: 0.8090 - val_loss: 0.5264 - val_accuracy: 0.7552\n",
      "Epoch 469/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4040 - accuracy: 0.8090 - val_loss: 0.5263 - val_accuracy: 0.7500\n",
      "Epoch 470/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4039 - accuracy: 0.8125 - val_loss: 0.5263 - val_accuracy: 0.7500\n",
      "Epoch 471/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4040 - accuracy: 0.8090 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
      "Epoch 472/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4040 - accuracy: 0.8090 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
      "Epoch 473/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4040 - accuracy: 0.8108 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
      "Epoch 474/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4040 - accuracy: 0.8142 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
      "Epoch 475/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4040 - accuracy: 0.8108 - val_loss: 0.5263 - val_accuracy: 0.7500\n",
      "Epoch 476/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4039 - accuracy: 0.8108 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
      "Epoch 477/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4039 - accuracy: 0.8108 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
      "Epoch 478/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4039 - accuracy: 0.8090 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
      "Epoch 479/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4039 - accuracy: 0.8090 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
      "Epoch 480/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4039 - accuracy: 0.8108 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
      "Epoch 481/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4040 - accuracy: 0.8073 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 482/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4039 - accuracy: 0.8125 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
      "Epoch 483/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4039 - accuracy: 0.8090 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
      "Epoch 484/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4039 - accuracy: 0.8108 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
      "Epoch 485/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4039 - accuracy: 0.8108 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
      "Epoch 486/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4038 - accuracy: 0.8090 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
      "Epoch 487/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4039 - accuracy: 0.8090 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
      "Epoch 488/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4039 - accuracy: 0.8090 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
      "Epoch 489/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4038 - accuracy: 0.8108 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
      "Epoch 490/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4039 - accuracy: 0.8108 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
      "Epoch 491/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4038 - accuracy: 0.8090 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
      "Epoch 492/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4039 - accuracy: 0.8090 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
      "Epoch 493/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4038 - accuracy: 0.8108 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
      "Epoch 494/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4039 - accuracy: 0.8108 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
      "Epoch 495/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4039 - accuracy: 0.8090 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
      "Epoch 496/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4038 - accuracy: 0.8090 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
      "Epoch 497/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4038 - accuracy: 0.8108 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
      "Epoch 498/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4038 - accuracy: 0.8090 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
      "Epoch 499/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4039 - accuracy: 0.8090 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
      "Epoch 500/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4038 - accuracy: 0.8108 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
      "Epoch 501/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4038 - accuracy: 0.8108 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
      "Epoch 502/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4038 - accuracy: 0.8108 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
      "Epoch 503/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4039 - accuracy: 0.8108 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
      "Epoch 504/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4038 - accuracy: 0.8108 - val_loss: 0.5268 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4038 - accuracy: 0.8108 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
      "Epoch 506/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4038 - accuracy: 0.8090 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
      "Epoch 507/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4038 - accuracy: 0.8125 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
      "Epoch 508/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4038 - accuracy: 0.8125 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
      "Epoch 509/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4038 - accuracy: 0.8108 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
      "Epoch 510/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4038 - accuracy: 0.8125 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
      "Epoch 511/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4038 - accuracy: 0.8090 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
      "Epoch 512/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4038 - accuracy: 0.8090 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
      "Epoch 513/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4038 - accuracy: 0.8090 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
      "Epoch 514/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4037 - accuracy: 0.8073 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
      "Epoch 515/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4037 - accuracy: 0.8108 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
      "Epoch 516/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4038 - accuracy: 0.8090 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
      "Epoch 517/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4037 - accuracy: 0.8090 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
      "Epoch 518/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4038 - accuracy: 0.8090 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
      "Epoch 519/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4038 - accuracy: 0.8125 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
      "Epoch 520/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4037 - accuracy: 0.8108 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
      "Epoch 521/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4037 - accuracy: 0.8108 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
      "Epoch 522/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4036 - accuracy: 0.8125 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
      "Epoch 523/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4037 - accuracy: 0.8090 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
      "Epoch 524/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4037 - accuracy: 0.8108 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
      "Epoch 525/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4037 - accuracy: 0.8125 - val_loss: 0.5269 - val_accuracy: 0.7448\n",
      "Epoch 526/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4037 - accuracy: 0.8090 - val_loss: 0.5269 - val_accuracy: 0.7448\n",
      "Epoch 527/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4037 - accuracy: 0.8090 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
      "Epoch 528/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4037 - accuracy: 0.8090 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
      "Epoch 529/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4037 - accuracy: 0.8108 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
      "Epoch 530/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4037 - accuracy: 0.8090 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
      "Epoch 531/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4036 - accuracy: 0.8090 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
      "Epoch 532/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4037 - accuracy: 0.8090 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
      "Epoch 533/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4037 - accuracy: 0.8108 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
      "Epoch 534/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4036 - accuracy: 0.8108 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
      "Epoch 535/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4036 - accuracy: 0.8090 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
      "Epoch 536/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4037 - accuracy: 0.8090 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
      "Epoch 537/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4036 - accuracy: 0.8108 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
      "Epoch 538/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4035 - accuracy: 0.8090 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
      "Epoch 539/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4036 - accuracy: 0.8108 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
      "Epoch 540/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4036 - accuracy: 0.8108 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
      "Epoch 541/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4037 - accuracy: 0.8142 - val_loss: 0.5271 - val_accuracy: 0.7448\n",
      "Epoch 542/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4036 - accuracy: 0.8090 - val_loss: 0.5271 - val_accuracy: 0.7448\n",
      "Epoch 543/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4037 - accuracy: 0.8090 - val_loss: 0.5271 - val_accuracy: 0.7448\n",
      "Epoch 544/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4036 - accuracy: 0.8090 - val_loss: 0.5271 - val_accuracy: 0.7448\n",
      "Epoch 545/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4037 - accuracy: 0.8108 - val_loss: 0.5272 - val_accuracy: 0.7448\n",
      "Epoch 546/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4036 - accuracy: 0.8090 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
      "Epoch 547/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4035 - accuracy: 0.8108 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
      "Epoch 548/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4036 - accuracy: 0.8090 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
      "Epoch 549/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4035 - accuracy: 0.8108 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
      "Epoch 550/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4035 - accuracy: 0.8090 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
      "Epoch 551/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4035 - accuracy: 0.8108 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
      "Epoch 552/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4035 - accuracy: 0.8090 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
      "Epoch 553/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4036 - accuracy: 0.8108 - val_loss: 0.5273 - val_accuracy: 0.7500\n",
      "Epoch 554/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4035 - accuracy: 0.8108 - val_loss: 0.5273 - val_accuracy: 0.7500\n",
      "Epoch 555/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4036 - accuracy: 0.8090 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
      "Epoch 556/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4035 - accuracy: 0.8090 - val_loss: 0.5272 - val_accuracy: 0.7448\n",
      "Epoch 557/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4035 - accuracy: 0.8108 - val_loss: 0.5272 - val_accuracy: 0.7448\n",
      "Epoch 558/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4035 - accuracy: 0.8108 - val_loss: 0.5273 - val_accuracy: 0.7448\n",
      "Epoch 559/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4035 - accuracy: 0.8108 - val_loss: 0.5273 - val_accuracy: 0.7448\n",
      "Epoch 560/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4035 - accuracy: 0.8090 - val_loss: 0.5273 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 561/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4035 - accuracy: 0.8125 - val_loss: 0.5273 - val_accuracy: 0.7448\n",
      "Epoch 562/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4035 - accuracy: 0.8108 - val_loss: 0.5273 - val_accuracy: 0.7448\n",
      "Epoch 563/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4035 - accuracy: 0.8108 - val_loss: 0.5273 - val_accuracy: 0.7448\n",
      "Epoch 564/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4035 - accuracy: 0.8108 - val_loss: 0.5273 - val_accuracy: 0.7448\n",
      "Epoch 565/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4035 - accuracy: 0.8090 - val_loss: 0.5273 - val_accuracy: 0.7448\n",
      "Epoch 566/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4036 - accuracy: 0.8108 - val_loss: 0.5274 - val_accuracy: 0.7448\n",
      "Epoch 567/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4036 - accuracy: 0.8090 - val_loss: 0.5273 - val_accuracy: 0.7448\n",
      "Epoch 568/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4035 - accuracy: 0.8090 - val_loss: 0.5274 - val_accuracy: 0.7448\n",
      "Epoch 569/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4035 - accuracy: 0.8090 - val_loss: 0.5274 - val_accuracy: 0.7448\n",
      "Epoch 570/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4034 - accuracy: 0.8108 - val_loss: 0.5274 - val_accuracy: 0.7448\n",
      "Epoch 571/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4034 - accuracy: 0.8090 - val_loss: 0.5274 - val_accuracy: 0.7448\n",
      "Epoch 572/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4035 - accuracy: 0.8090 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
      "Epoch 573/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4035 - accuracy: 0.8108 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
      "Epoch 574/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4034 - accuracy: 0.8090 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
      "Epoch 575/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4035 - accuracy: 0.8108 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
      "Epoch 576/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4034 - accuracy: 0.8090 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
      "Epoch 577/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4034 - accuracy: 0.8090 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
      "Epoch 578/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4034 - accuracy: 0.8090 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
      "Epoch 579/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4035 - accuracy: 0.8090 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
      "Epoch 580/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4035 - accuracy: 0.8090 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
      "Epoch 581/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4034 - accuracy: 0.8090 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
      "Epoch 582/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4034 - accuracy: 0.8090 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
      "Epoch 583/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4034 - accuracy: 0.8090 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
      "Epoch 584/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4033 - accuracy: 0.8090 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
      "Epoch 585/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4035 - accuracy: 0.8090 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
      "Epoch 586/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4033 - accuracy: 0.8090 - val_loss: 0.5277 - val_accuracy: 0.7448\n",
      "Epoch 587/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4033 - accuracy: 0.8108 - val_loss: 0.5277 - val_accuracy: 0.7448\n",
      "Epoch 588/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4033 - accuracy: 0.8108 - val_loss: 0.5277 - val_accuracy: 0.7448\n",
      "Epoch 589/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4033 - accuracy: 0.8090 - val_loss: 0.5277 - val_accuracy: 0.7448\n",
      "Epoch 590/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4034 - accuracy: 0.8108 - val_loss: 0.5277 - val_accuracy: 0.7448\n",
      "Epoch 591/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4033 - accuracy: 0.8090 - val_loss: 0.5277 - val_accuracy: 0.7448\n",
      "Epoch 592/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4033 - accuracy: 0.8090 - val_loss: 0.5277 - val_accuracy: 0.7448\n",
      "Epoch 593/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4032 - accuracy: 0.8125 - val_loss: 0.5277 - val_accuracy: 0.7448\n",
      "Epoch 594/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4033 - accuracy: 0.8090 - val_loss: 0.5277 - val_accuracy: 0.7448\n",
      "Epoch 595/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4033 - accuracy: 0.8090 - val_loss: 0.5277 - val_accuracy: 0.7448\n",
      "Epoch 596/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4033 - accuracy: 0.8108 - val_loss: 0.5277 - val_accuracy: 0.7448\n",
      "Epoch 597/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4034 - accuracy: 0.8090 - val_loss: 0.5277 - val_accuracy: 0.7448\n",
      "Epoch 598/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4033 - accuracy: 0.8108 - val_loss: 0.5278 - val_accuracy: 0.7448\n",
      "Epoch 599/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4033 - accuracy: 0.8090 - val_loss: 0.5278 - val_accuracy: 0.7448\n",
      "Epoch 600/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4033 - accuracy: 0.8090 - val_loss: 0.5278 - val_accuracy: 0.7448\n",
      "Epoch 601/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4032 - accuracy: 0.8090 - val_loss: 0.5278 - val_accuracy: 0.7448\n",
      "Epoch 602/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4033 - accuracy: 0.8090 - val_loss: 0.5278 - val_accuracy: 0.7448\n",
      "Epoch 603/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4033 - accuracy: 0.8125 - val_loss: 0.5278 - val_accuracy: 0.7448\n",
      "Epoch 604/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4032 - accuracy: 0.8108 - val_loss: 0.5278 - val_accuracy: 0.7448\n",
      "Epoch 605/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4032 - accuracy: 0.8108 - val_loss: 0.5278 - val_accuracy: 0.7448\n",
      "Epoch 606/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4034 - accuracy: 0.8108 - val_loss: 0.5278 - val_accuracy: 0.7448\n",
      "Epoch 607/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4033 - accuracy: 0.8108 - val_loss: 0.5279 - val_accuracy: 0.7448\n",
      "Epoch 608/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4032 - accuracy: 0.8090 - val_loss: 0.5279 - val_accuracy: 0.7448\n",
      "Epoch 609/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4032 - accuracy: 0.8090 - val_loss: 0.5279 - val_accuracy: 0.7448\n",
      "Epoch 610/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4031 - accuracy: 0.8090 - val_loss: 0.5279 - val_accuracy: 0.7448\n",
      "Epoch 611/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4033 - accuracy: 0.8108 - val_loss: 0.5279 - val_accuracy: 0.7448\n",
      "Epoch 612/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4031 - accuracy: 0.8108 - val_loss: 0.5279 - val_accuracy: 0.7448\n",
      "Epoch 613/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4033 - accuracy: 0.8090 - val_loss: 0.5279 - val_accuracy: 0.7448\n",
      "Epoch 614/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4032 - accuracy: 0.8108 - val_loss: 0.5280 - val_accuracy: 0.7448\n",
      "Epoch 615/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4032 - accuracy: 0.8090 - val_loss: 0.5280 - val_accuracy: 0.7448\n",
      "Epoch 616/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4032 - accuracy: 0.8090 - val_loss: 0.5280 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 617/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4031 - accuracy: 0.8090 - val_loss: 0.5280 - val_accuracy: 0.7448\n",
      "Epoch 618/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4032 - accuracy: 0.8090 - val_loss: 0.5280 - val_accuracy: 0.7448\n",
      "Epoch 619/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4032 - accuracy: 0.8090 - val_loss: 0.5280 - val_accuracy: 0.7448\n",
      "Epoch 620/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4031 - accuracy: 0.8090 - val_loss: 0.5280 - val_accuracy: 0.7448\n",
      "Epoch 621/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4032 - accuracy: 0.8090 - val_loss: 0.5280 - val_accuracy: 0.7448\n",
      "Epoch 622/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4031 - accuracy: 0.8090 - val_loss: 0.5280 - val_accuracy: 0.7448\n",
      "Epoch 623/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4031 - accuracy: 0.8090 - val_loss: 0.5280 - val_accuracy: 0.7448\n",
      "Epoch 624/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4032 - accuracy: 0.8090 - val_loss: 0.5281 - val_accuracy: 0.7448\n",
      "Epoch 625/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4032 - accuracy: 0.8090 - val_loss: 0.5281 - val_accuracy: 0.7448\n",
      "Epoch 626/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4032 - accuracy: 0.8090 - val_loss: 0.5281 - val_accuracy: 0.7448\n",
      "Epoch 627/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4032 - accuracy: 0.8108 - val_loss: 0.5281 - val_accuracy: 0.7448\n",
      "Epoch 628/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4032 - accuracy: 0.8108 - val_loss: 0.5281 - val_accuracy: 0.7448\n",
      "Epoch 629/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4032 - accuracy: 0.8108 - val_loss: 0.5281 - val_accuracy: 0.7448\n",
      "Epoch 630/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4032 - accuracy: 0.8090 - val_loss: 0.5281 - val_accuracy: 0.7448\n",
      "Epoch 631/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4032 - accuracy: 0.8090 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
      "Epoch 632/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4031 - accuracy: 0.8090 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
      "Epoch 633/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4031 - accuracy: 0.8090 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
      "Epoch 634/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4032 - accuracy: 0.8090 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
      "Epoch 635/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4032 - accuracy: 0.8090 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
      "Epoch 636/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4031 - accuracy: 0.8090 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
      "Epoch 637/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4031 - accuracy: 0.8090 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
      "Epoch 638/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4030 - accuracy: 0.8108 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
      "Epoch 639/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4030 - accuracy: 0.8090 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
      "Epoch 640/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4032 - accuracy: 0.8090 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
      "Epoch 641/1500\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4030 - accuracy: 0.8090 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
      "Epoch 642/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4030 - accuracy: 0.8090 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
      "Epoch 643/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4030 - accuracy: 0.8090 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
      "Epoch 644/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4032 - accuracy: 0.8090 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
      "Epoch 645/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4030 - accuracy: 0.8090 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
      "Epoch 646/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4030 - accuracy: 0.8090 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
      "Epoch 647/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4030 - accuracy: 0.8090 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
      "Epoch 648/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4031 - accuracy: 0.8090 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
      "Epoch 649/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4030 - accuracy: 0.8090 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
      "Epoch 650/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4031 - accuracy: 0.8108 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
      "Epoch 651/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4030 - accuracy: 0.8090 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
      "Epoch 652/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4030 - accuracy: 0.8108 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
      "Epoch 653/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4030 - accuracy: 0.8090 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
      "Epoch 654/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4030 - accuracy: 0.8090 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
      "Epoch 655/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4029 - accuracy: 0.8090 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
      "Epoch 656/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4030 - accuracy: 0.8090 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
      "Epoch 657/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4030 - accuracy: 0.8090 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
      "Epoch 658/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4029 - accuracy: 0.8090 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
      "Epoch 659/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4030 - accuracy: 0.8108 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
      "Epoch 660/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4029 - accuracy: 0.8090 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
      "Epoch 661/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4028 - accuracy: 0.8090 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
      "Epoch 662/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4029 - accuracy: 0.8090 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
      "Epoch 663/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4029 - accuracy: 0.8090 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
      "Epoch 664/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4029 - accuracy: 0.8108 - val_loss: 0.5284 - val_accuracy: 0.7448\n",
      "Epoch 665/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4029 - accuracy: 0.8108 - val_loss: 0.5284 - val_accuracy: 0.7448\n",
      "Epoch 666/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4029 - accuracy: 0.8090 - val_loss: 0.5284 - val_accuracy: 0.7448\n",
      "Epoch 667/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4029 - accuracy: 0.8090 - val_loss: 0.5284 - val_accuracy: 0.7448\n",
      "Epoch 668/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4029 - accuracy: 0.8090 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
      "Epoch 669/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4029 - accuracy: 0.8108 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
      "Epoch 670/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4028 - accuracy: 0.8090 - val_loss: 0.5284 - val_accuracy: 0.7448\n",
      "Epoch 671/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4030 - accuracy: 0.8090 - val_loss: 0.5284 - val_accuracy: 0.7448\n",
      "Epoch 672/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4030 - accuracy: 0.8090 - val_loss: 0.5284 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 673/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4029 - accuracy: 0.8090 - val_loss: 0.5284 - val_accuracy: 0.7448\n",
      "Epoch 674/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4028 - accuracy: 0.8090 - val_loss: 0.5284 - val_accuracy: 0.7448\n",
      "Epoch 675/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4029 - accuracy: 0.8090 - val_loss: 0.5284 - val_accuracy: 0.7448\n",
      "Epoch 676/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4028 - accuracy: 0.8090 - val_loss: 0.5284 - val_accuracy: 0.7448\n",
      "Epoch 677/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4028 - accuracy: 0.8108 - val_loss: 0.5284 - val_accuracy: 0.7448\n",
      "Epoch 678/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4028 - accuracy: 0.8090 - val_loss: 0.5284 - val_accuracy: 0.7448\n",
      "Epoch 679/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4029 - accuracy: 0.8090 - val_loss: 0.5284 - val_accuracy: 0.7448\n",
      "Epoch 680/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4029 - accuracy: 0.8090 - val_loss: 0.5284 - val_accuracy: 0.7448\n",
      "Epoch 681/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4028 - accuracy: 0.8090 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 682/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4028 - accuracy: 0.8090 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 683/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4027 - accuracy: 0.8090 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 684/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4027 - accuracy: 0.8090 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 685/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4027 - accuracy: 0.8090 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 686/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4027 - accuracy: 0.8090 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 687/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4028 - accuracy: 0.8090 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 688/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4028 - accuracy: 0.8090 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 689/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4028 - accuracy: 0.8125 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 690/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4027 - accuracy: 0.8090 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 691/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4028 - accuracy: 0.8108 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 692/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4027 - accuracy: 0.8090 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 693/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4028 - accuracy: 0.8090 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 694/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4027 - accuracy: 0.8090 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 695/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4027 - accuracy: 0.8090 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 696/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4028 - accuracy: 0.8090 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 697/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4026 - accuracy: 0.8090 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 698/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4027 - accuracy: 0.8090 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 699/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4027 - accuracy: 0.8090 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 700/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4027 - accuracy: 0.8090 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 701/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4027 - accuracy: 0.8090 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 702/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4027 - accuracy: 0.8090 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 703/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4026 - accuracy: 0.8090 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 704/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4027 - accuracy: 0.8090 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 705/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4026 - accuracy: 0.8090 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 706/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4026 - accuracy: 0.8090 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 707/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4027 - accuracy: 0.8090 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 708/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4027 - accuracy: 0.8090 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 709/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4026 - accuracy: 0.8090 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 710/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4026 - accuracy: 0.8090 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 711/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4026 - accuracy: 0.8090 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 712/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4027 - accuracy: 0.8090 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 713/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4026 - accuracy: 0.8090 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 714/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4027 - accuracy: 0.8090 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 715/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4026 - accuracy: 0.8090 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 716/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4026 - accuracy: 0.8090 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 717/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4026 - accuracy: 0.8090 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 718/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4026 - accuracy: 0.8090 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 719/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4025 - accuracy: 0.8090 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 720/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4026 - accuracy: 0.8108 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 721/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4026 - accuracy: 0.8090 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 722/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4025 - accuracy: 0.8090 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 723/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4025 - accuracy: 0.8108 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 724/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4026 - accuracy: 0.8108 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 725/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4026 - accuracy: 0.8108 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 726/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4026 - accuracy: 0.8090 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 727/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4025 - accuracy: 0.8090 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 728/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4025 - accuracy: 0.8090 - val_loss: 0.5288 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 729/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4025 - accuracy: 0.8090 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 730/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4025 - accuracy: 0.8090 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 731/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4026 - accuracy: 0.8090 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 732/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4026 - accuracy: 0.8090 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 733/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4025 - accuracy: 0.8090 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 734/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4025 - accuracy: 0.8108 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 735/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4025 - accuracy: 0.8073 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 736/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4025 - accuracy: 0.8108 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 737/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4025 - accuracy: 0.8090 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 738/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4024 - accuracy: 0.8090 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 739/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4025 - accuracy: 0.8090 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 740/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4025 - accuracy: 0.8108 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 741/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4024 - accuracy: 0.8090 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 742/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4025 - accuracy: 0.8073 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
      "Epoch 743/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4024 - accuracy: 0.8073 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
      "Epoch 744/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4025 - accuracy: 0.8073 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
      "Epoch 745/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4025 - accuracy: 0.8090 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
      "Epoch 746/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4023 - accuracy: 0.8090 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
      "Epoch 747/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4023 - accuracy: 0.8090 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
      "Epoch 748/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4024 - accuracy: 0.8090 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
      "Epoch 749/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4024 - accuracy: 0.8090 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
      "Epoch 750/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4024 - accuracy: 0.8090 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
      "Epoch 751/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4025 - accuracy: 0.8090 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
      "Epoch 752/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4024 - accuracy: 0.8073 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
      "Epoch 753/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4023 - accuracy: 0.8090 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
      "Epoch 754/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4025 - accuracy: 0.8056 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
      "Epoch 755/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4023 - accuracy: 0.8090 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
      "Epoch 756/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4024 - accuracy: 0.8090 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
      "Epoch 757/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4023 - accuracy: 0.8090 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
      "Epoch 758/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4023 - accuracy: 0.8090 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
      "Epoch 759/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4023 - accuracy: 0.8073 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
      "Epoch 760/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4023 - accuracy: 0.8090 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
      "Epoch 761/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4023 - accuracy: 0.8073 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
      "Epoch 762/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4023 - accuracy: 0.8090 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
      "Epoch 763/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4024 - accuracy: 0.8108 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
      "Epoch 764/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4024 - accuracy: 0.8090 - val_loss: 0.5290 - val_accuracy: 0.7448\n",
      "Epoch 765/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4023 - accuracy: 0.8073 - val_loss: 0.5290 - val_accuracy: 0.7448\n",
      "Epoch 766/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4022 - accuracy: 0.8090 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
      "Epoch 767/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4022 - accuracy: 0.8073 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
      "Epoch 768/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4024 - accuracy: 0.8108 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
      "Epoch 769/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4023 - accuracy: 0.8073 - val_loss: 0.5290 - val_accuracy: 0.7448\n",
      "Epoch 770/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4022 - accuracy: 0.8073 - val_loss: 0.5290 - val_accuracy: 0.7448\n",
      "Epoch 771/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4023 - accuracy: 0.8073 - val_loss: 0.5290 - val_accuracy: 0.7448\n",
      "Epoch 772/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4023 - accuracy: 0.8073 - val_loss: 0.5290 - val_accuracy: 0.7448\n",
      "Epoch 773/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4022 - accuracy: 0.8090 - val_loss: 0.5290 - val_accuracy: 0.7448\n",
      "Epoch 774/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4023 - accuracy: 0.8108 - val_loss: 0.5291 - val_accuracy: 0.7448\n",
      "Epoch 775/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4022 - accuracy: 0.8073 - val_loss: 0.5291 - val_accuracy: 0.7448\n",
      "Epoch 776/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4022 - accuracy: 0.8073 - val_loss: 0.5291 - val_accuracy: 0.7448\n",
      "Epoch 777/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4022 - accuracy: 0.8073 - val_loss: 0.5291 - val_accuracy: 0.7448\n",
      "Epoch 778/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4022 - accuracy: 0.8073 - val_loss: 0.5290 - val_accuracy: 0.7448\n",
      "Epoch 779/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4023 - accuracy: 0.8090 - val_loss: 0.5291 - val_accuracy: 0.7448\n",
      "Epoch 780/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4022 - accuracy: 0.8090 - val_loss: 0.5291 - val_accuracy: 0.7448\n",
      "Epoch 781/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4022 - accuracy: 0.8073 - val_loss: 0.5291 - val_accuracy: 0.7448\n",
      "Epoch 782/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4022 - accuracy: 0.8073 - val_loss: 0.5291 - val_accuracy: 0.7448\n",
      "Epoch 783/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4022 - accuracy: 0.8073 - val_loss: 0.5291 - val_accuracy: 0.7448\n",
      "Epoch 784/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4022 - accuracy: 0.8090 - val_loss: 0.5291 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 785/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4022 - accuracy: 0.8073 - val_loss: 0.5291 - val_accuracy: 0.7448\n",
      "Epoch 786/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4022 - accuracy: 0.8073 - val_loss: 0.5291 - val_accuracy: 0.7448\n",
      "Epoch 787/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4022 - accuracy: 0.8073 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
      "Epoch 788/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4021 - accuracy: 0.8073 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
      "Epoch 789/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4021 - accuracy: 0.8073 - val_loss: 0.5291 - val_accuracy: 0.7448\n",
      "Epoch 790/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4021 - accuracy: 0.8073 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
      "Epoch 791/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4022 - accuracy: 0.8073 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
      "Epoch 792/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4022 - accuracy: 0.8073 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
      "Epoch 793/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4021 - accuracy: 0.8073 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
      "Epoch 794/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4021 - accuracy: 0.8073 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
      "Epoch 795/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4021 - accuracy: 0.8073 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
      "Epoch 796/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4021 - accuracy: 0.8073 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
      "Epoch 797/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4022 - accuracy: 0.8073 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
      "Epoch 798/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4021 - accuracy: 0.8073 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
      "Epoch 799/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4022 - accuracy: 0.8090 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
      "Epoch 800/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4021 - accuracy: 0.8090 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
      "Epoch 801/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4021 - accuracy: 0.8090 - val_loss: 0.5293 - val_accuracy: 0.7448\n",
      "Epoch 802/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4021 - accuracy: 0.8073 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
      "Epoch 803/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4020 - accuracy: 0.8073 - val_loss: 0.5293 - val_accuracy: 0.7448\n",
      "Epoch 804/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4020 - accuracy: 0.8073 - val_loss: 0.5293 - val_accuracy: 0.7448\n",
      "Epoch 805/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4020 - accuracy: 0.8090 - val_loss: 0.5293 - val_accuracy: 0.7448\n",
      "Epoch 806/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4020 - accuracy: 0.8073 - val_loss: 0.5293 - val_accuracy: 0.7448\n",
      "Epoch 807/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4019 - accuracy: 0.8090 - val_loss: 0.5293 - val_accuracy: 0.7448\n",
      "Epoch 808/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4021 - accuracy: 0.8090 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 809/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4020 - accuracy: 0.8090 - val_loss: 0.5293 - val_accuracy: 0.7448\n",
      "Epoch 810/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4020 - accuracy: 0.8090 - val_loss: 0.5293 - val_accuracy: 0.7448\n",
      "Epoch 811/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4019 - accuracy: 0.8073 - val_loss: 0.5293 - val_accuracy: 0.7448\n",
      "Epoch 812/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4020 - accuracy: 0.8073 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 813/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4020 - accuracy: 0.8090 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 814/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4020 - accuracy: 0.8073 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 815/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4019 - accuracy: 0.8073 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 816/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4020 - accuracy: 0.8073 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 817/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4019 - accuracy: 0.8073 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 818/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4019 - accuracy: 0.8073 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 819/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4019 - accuracy: 0.8073 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 820/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4019 - accuracy: 0.8073 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 821/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4018 - accuracy: 0.8090 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 822/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4020 - accuracy: 0.8090 - val_loss: 0.5295 - val_accuracy: 0.7448\n",
      "Epoch 823/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4020 - accuracy: 0.8073 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 824/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4019 - accuracy: 0.8073 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 825/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4019 - accuracy: 0.8073 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 826/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4018 - accuracy: 0.8090 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 827/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4018 - accuracy: 0.8073 - val_loss: 0.5295 - val_accuracy: 0.7448\n",
      "Epoch 828/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4019 - accuracy: 0.8090 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 829/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4019 - accuracy: 0.8073 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 830/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4019 - accuracy: 0.8090 - val_loss: 0.5295 - val_accuracy: 0.7448\n",
      "Epoch 831/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4018 - accuracy: 0.8073 - val_loss: 0.5295 - val_accuracy: 0.7448\n",
      "Epoch 832/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4019 - accuracy: 0.8090 - val_loss: 0.5295 - val_accuracy: 0.7448\n",
      "Epoch 833/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4018 - accuracy: 0.8090 - val_loss: 0.5295 - val_accuracy: 0.7448\n",
      "Epoch 834/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4018 - accuracy: 0.8090 - val_loss: 0.5295 - val_accuracy: 0.7448\n",
      "Epoch 835/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4018 - accuracy: 0.8090 - val_loss: 0.5295 - val_accuracy: 0.7448\n",
      "Epoch 836/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4019 - accuracy: 0.8090 - val_loss: 0.5296 - val_accuracy: 0.7448\n",
      "Epoch 837/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4019 - accuracy: 0.8073 - val_loss: 0.5296 - val_accuracy: 0.7448\n",
      "Epoch 838/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4018 - accuracy: 0.8090 - val_loss: 0.5296 - val_accuracy: 0.7448\n",
      "Epoch 839/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4018 - accuracy: 0.8073 - val_loss: 0.5295 - val_accuracy: 0.7448\n",
      "Epoch 840/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4018 - accuracy: 0.8073 - val_loss: 0.5296 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 841/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4017 - accuracy: 0.8073 - val_loss: 0.5296 - val_accuracy: 0.7448\n",
      "Epoch 842/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4018 - accuracy: 0.8073 - val_loss: 0.5296 - val_accuracy: 0.7448\n",
      "Epoch 843/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4018 - accuracy: 0.8073 - val_loss: 0.5295 - val_accuracy: 0.7448\n",
      "Epoch 844/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4017 - accuracy: 0.8073 - val_loss: 0.5295 - val_accuracy: 0.7448\n",
      "Epoch 845/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4018 - accuracy: 0.8073 - val_loss: 0.5295 - val_accuracy: 0.7448\n",
      "Epoch 846/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4017 - accuracy: 0.8090 - val_loss: 0.5296 - val_accuracy: 0.7448\n",
      "Epoch 847/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4018 - accuracy: 0.8090 - val_loss: 0.5296 - val_accuracy: 0.7448\n",
      "Epoch 848/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4017 - accuracy: 0.8090 - val_loss: 0.5295 - val_accuracy: 0.7448\n",
      "Epoch 849/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4017 - accuracy: 0.8090 - val_loss: 0.5296 - val_accuracy: 0.7448\n",
      "Epoch 850/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4017 - accuracy: 0.8090 - val_loss: 0.5296 - val_accuracy: 0.7448\n",
      "Epoch 851/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4018 - accuracy: 0.8125 - val_loss: 0.5296 - val_accuracy: 0.7448\n",
      "Epoch 852/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4017 - accuracy: 0.8090 - val_loss: 0.5296 - val_accuracy: 0.7448\n",
      "Epoch 853/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4017 - accuracy: 0.8090 - val_loss: 0.5296 - val_accuracy: 0.7448\n",
      "Epoch 854/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4017 - accuracy: 0.8073 - val_loss: 0.5296 - val_accuracy: 0.7448\n",
      "Epoch 855/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4017 - accuracy: 0.8073 - val_loss: 0.5296 - val_accuracy: 0.7448\n",
      "Epoch 856/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4017 - accuracy: 0.8090 - val_loss: 0.5297 - val_accuracy: 0.7448\n",
      "Epoch 857/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4018 - accuracy: 0.8073 - val_loss: 0.5296 - val_accuracy: 0.7448\n",
      "Epoch 858/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4016 - accuracy: 0.8090 - val_loss: 0.5297 - val_accuracy: 0.7448\n",
      "Epoch 859/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4017 - accuracy: 0.8090 - val_loss: 0.5296 - val_accuracy: 0.7448\n",
      "Epoch 860/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4016 - accuracy: 0.8073 - val_loss: 0.5296 - val_accuracy: 0.7448\n",
      "Epoch 861/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4017 - accuracy: 0.8073 - val_loss: 0.5296 - val_accuracy: 0.7448\n",
      "Epoch 862/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4017 - accuracy: 0.8108 - val_loss: 0.5297 - val_accuracy: 0.7448\n",
      "Epoch 863/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4016 - accuracy: 0.8073 - val_loss: 0.5297 - val_accuracy: 0.7448\n",
      "Epoch 864/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4016 - accuracy: 0.8090 - val_loss: 0.5297 - val_accuracy: 0.7448\n",
      "Epoch 865/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4016 - accuracy: 0.8073 - val_loss: 0.5296 - val_accuracy: 0.7448\n",
      "Epoch 866/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4017 - accuracy: 0.8073 - val_loss: 0.5297 - val_accuracy: 0.7448\n",
      "Epoch 867/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4016 - accuracy: 0.8073 - val_loss: 0.5297 - val_accuracy: 0.7448\n",
      "Epoch 868/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4016 - accuracy: 0.8090 - val_loss: 0.5297 - val_accuracy: 0.7448\n",
      "Epoch 869/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4016 - accuracy: 0.8073 - val_loss: 0.5297 - val_accuracy: 0.7448\n",
      "Epoch 870/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4017 - accuracy: 0.8073 - val_loss: 0.5297 - val_accuracy: 0.7448\n",
      "Epoch 871/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4016 - accuracy: 0.8108 - val_loss: 0.5298 - val_accuracy: 0.7448\n",
      "Epoch 872/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4016 - accuracy: 0.8090 - val_loss: 0.5298 - val_accuracy: 0.7448\n",
      "Epoch 873/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4016 - accuracy: 0.8090 - val_loss: 0.5297 - val_accuracy: 0.7448\n",
      "Epoch 874/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4016 - accuracy: 0.8073 - val_loss: 0.5297 - val_accuracy: 0.7448\n",
      "Epoch 875/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4015 - accuracy: 0.8090 - val_loss: 0.5297 - val_accuracy: 0.7448\n",
      "Epoch 876/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4015 - accuracy: 0.8090 - val_loss: 0.5298 - val_accuracy: 0.7448\n",
      "Epoch 877/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4017 - accuracy: 0.8073 - val_loss: 0.5298 - val_accuracy: 0.7448\n",
      "Epoch 878/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4015 - accuracy: 0.8108 - val_loss: 0.5298 - val_accuracy: 0.7448\n",
      "Epoch 879/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4015 - accuracy: 0.8108 - val_loss: 0.5298 - val_accuracy: 0.7448\n",
      "Epoch 880/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4015 - accuracy: 0.8073 - val_loss: 0.5298 - val_accuracy: 0.7448\n",
      "Epoch 881/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4015 - accuracy: 0.8073 - val_loss: 0.5298 - val_accuracy: 0.7448\n",
      "Epoch 882/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4016 - accuracy: 0.8090 - val_loss: 0.5298 - val_accuracy: 0.7448\n",
      "Epoch 883/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4015 - accuracy: 0.8073 - val_loss: 0.5298 - val_accuracy: 0.7448\n",
      "Epoch 884/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4016 - accuracy: 0.8108 - val_loss: 0.5298 - val_accuracy: 0.7448\n",
      "Epoch 885/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4015 - accuracy: 0.8090 - val_loss: 0.5298 - val_accuracy: 0.7448\n",
      "Epoch 886/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4015 - accuracy: 0.8090 - val_loss: 0.5298 - val_accuracy: 0.7448\n",
      "Epoch 887/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4016 - accuracy: 0.8073 - val_loss: 0.5298 - val_accuracy: 0.7448\n",
      "Epoch 888/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4014 - accuracy: 0.8108 - val_loss: 0.5298 - val_accuracy: 0.7448\n",
      "Epoch 889/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4016 - accuracy: 0.8090 - val_loss: 0.5298 - val_accuracy: 0.7448\n",
      "Epoch 890/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4015 - accuracy: 0.8090 - val_loss: 0.5299 - val_accuracy: 0.7448\n",
      "Epoch 891/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4016 - accuracy: 0.8108 - val_loss: 0.5299 - val_accuracy: 0.7448\n",
      "Epoch 892/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4014 - accuracy: 0.8073 - val_loss: 0.5299 - val_accuracy: 0.7448\n",
      "Epoch 893/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4014 - accuracy: 0.8073 - val_loss: 0.5299 - val_accuracy: 0.7448\n",
      "Epoch 894/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4015 - accuracy: 0.8108 - val_loss: 0.5299 - val_accuracy: 0.7448\n",
      "Epoch 895/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4014 - accuracy: 0.8090 - val_loss: 0.5299 - val_accuracy: 0.7448\n",
      "Epoch 896/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4015 - accuracy: 0.8090 - val_loss: 0.5299 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 897/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4015 - accuracy: 0.8125 - val_loss: 0.5299 - val_accuracy: 0.7448\n",
      "Epoch 898/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4015 - accuracy: 0.8090 - val_loss: 0.5299 - val_accuracy: 0.7448\n",
      "Epoch 899/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4015 - accuracy: 0.8090 - val_loss: 0.5299 - val_accuracy: 0.7448\n",
      "Epoch 900/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4015 - accuracy: 0.8073 - val_loss: 0.5299 - val_accuracy: 0.7448\n",
      "Epoch 901/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4014 - accuracy: 0.8090 - val_loss: 0.5299 - val_accuracy: 0.7448\n",
      "Epoch 902/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4015 - accuracy: 0.8090 - val_loss: 0.5299 - val_accuracy: 0.7448\n",
      "Epoch 903/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4015 - accuracy: 0.8090 - val_loss: 0.5299 - val_accuracy: 0.7448\n",
      "Epoch 904/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4014 - accuracy: 0.8073 - val_loss: 0.5299 - val_accuracy: 0.7448\n",
      "Epoch 905/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4015 - accuracy: 0.8090 - val_loss: 0.5299 - val_accuracy: 0.7448\n",
      "Epoch 906/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4015 - accuracy: 0.8108 - val_loss: 0.5299 - val_accuracy: 0.7448\n",
      "Epoch 907/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4015 - accuracy: 0.8090 - val_loss: 0.5299 - val_accuracy: 0.7448\n",
      "Epoch 908/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4014 - accuracy: 0.8073 - val_loss: 0.5299 - val_accuracy: 0.7448\n",
      "Epoch 909/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4014 - accuracy: 0.8090 - val_loss: 0.5299 - val_accuracy: 0.7448\n",
      "Epoch 910/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4013 - accuracy: 0.8090 - val_loss: 0.5299 - val_accuracy: 0.7448\n",
      "Epoch 911/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4015 - accuracy: 0.8108 - val_loss: 0.5299 - val_accuracy: 0.7448\n",
      "Epoch 912/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4014 - accuracy: 0.8108 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
      "Epoch 913/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4014 - accuracy: 0.8090 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
      "Epoch 914/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4014 - accuracy: 0.8090 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
      "Epoch 915/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4013 - accuracy: 0.8108 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
      "Epoch 916/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4014 - accuracy: 0.8090 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
      "Epoch 917/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4014 - accuracy: 0.8090 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
      "Epoch 918/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4014 - accuracy: 0.8073 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
      "Epoch 919/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4015 - accuracy: 0.8108 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
      "Epoch 920/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4015 - accuracy: 0.8090 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
      "Epoch 921/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4014 - accuracy: 0.8108 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
      "Epoch 922/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4013 - accuracy: 0.8108 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
      "Epoch 923/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4013 - accuracy: 0.8073 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
      "Epoch 924/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4015 - accuracy: 0.8108 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
      "Epoch 925/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4013 - accuracy: 0.8108 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
      "Epoch 926/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4013 - accuracy: 0.8056 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
      "Epoch 927/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4013 - accuracy: 0.8125 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
      "Epoch 928/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4014 - accuracy: 0.8108 - val_loss: 0.5301 - val_accuracy: 0.7448\n",
      "Epoch 929/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4013 - accuracy: 0.8073 - val_loss: 0.5301 - val_accuracy: 0.7448\n",
      "Epoch 930/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4013 - accuracy: 0.8108 - val_loss: 0.5301 - val_accuracy: 0.7448\n",
      "Epoch 931/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4012 - accuracy: 0.8090 - val_loss: 0.5301 - val_accuracy: 0.7448\n",
      "Epoch 932/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4013 - accuracy: 0.8090 - val_loss: 0.5301 - val_accuracy: 0.7448\n",
      "Epoch 933/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4013 - accuracy: 0.8108 - val_loss: 0.5301 - val_accuracy: 0.7448\n",
      "Epoch 934/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4013 - accuracy: 0.8108 - val_loss: 0.5301 - val_accuracy: 0.7448\n",
      "Epoch 935/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4014 - accuracy: 0.8108 - val_loss: 0.5301 - val_accuracy: 0.7448\n",
      "Epoch 936/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4011 - accuracy: 0.8108 - val_loss: 0.5301 - val_accuracy: 0.7448\n",
      "Epoch 937/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4013 - accuracy: 0.8108 - val_loss: 0.5301 - val_accuracy: 0.7448\n",
      "Epoch 938/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4013 - accuracy: 0.8090 - val_loss: 0.5301 - val_accuracy: 0.7448\n",
      "Epoch 939/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4012 - accuracy: 0.8090 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
      "Epoch 940/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4013 - accuracy: 0.8108 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
      "Epoch 941/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4012 - accuracy: 0.8090 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
      "Epoch 942/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4013 - accuracy: 0.8108 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
      "Epoch 943/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4012 - accuracy: 0.8090 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
      "Epoch 944/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4013 - accuracy: 0.8108 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
      "Epoch 945/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4012 - accuracy: 0.8108 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
      "Epoch 946/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4012 - accuracy: 0.8108 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
      "Epoch 947/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4012 - accuracy: 0.8125 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
      "Epoch 948/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4012 - accuracy: 0.8090 - val_loss: 0.5303 - val_accuracy: 0.7448\n",
      "Epoch 949/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4013 - accuracy: 0.8125 - val_loss: 0.5303 - val_accuracy: 0.7448\n",
      "Epoch 950/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4013 - accuracy: 0.8090 - val_loss: 0.5303 - val_accuracy: 0.7448\n",
      "Epoch 951/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4012 - accuracy: 0.8108 - val_loss: 0.5303 - val_accuracy: 0.7448\n",
      "Epoch 952/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4012 - accuracy: 0.8090 - val_loss: 0.5303 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 953/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4012 - accuracy: 0.8125 - val_loss: 0.5303 - val_accuracy: 0.7448\n",
      "Epoch 954/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4013 - accuracy: 0.8125 - val_loss: 0.5303 - val_accuracy: 0.7448\n",
      "Epoch 955/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4012 - accuracy: 0.8108 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
      "Epoch 956/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4011 - accuracy: 0.8090 - val_loss: 0.5303 - val_accuracy: 0.7448\n",
      "Epoch 957/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4013 - accuracy: 0.8125 - val_loss: 0.5303 - val_accuracy: 0.7448\n",
      "Epoch 958/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4012 - accuracy: 0.8090 - val_loss: 0.5303 - val_accuracy: 0.7448\n",
      "Epoch 959/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4012 - accuracy: 0.8073 - val_loss: 0.5303 - val_accuracy: 0.7448\n",
      "Epoch 960/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4011 - accuracy: 0.8125 - val_loss: 0.5303 - val_accuracy: 0.7448\n",
      "Epoch 961/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4012 - accuracy: 0.8108 - val_loss: 0.5304 - val_accuracy: 0.7448\n",
      "Epoch 962/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4011 - accuracy: 0.8090 - val_loss: 0.5304 - val_accuracy: 0.7448\n",
      "Epoch 963/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4011 - accuracy: 0.8090 - val_loss: 0.5304 - val_accuracy: 0.7448\n",
      "Epoch 964/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4012 - accuracy: 0.8090 - val_loss: 0.5304 - val_accuracy: 0.7448\n",
      "Epoch 965/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4012 - accuracy: 0.8090 - val_loss: 0.5304 - val_accuracy: 0.7448\n",
      "Epoch 966/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4011 - accuracy: 0.8090 - val_loss: 0.5304 - val_accuracy: 0.7448\n",
      "Epoch 967/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4010 - accuracy: 0.8108 - val_loss: 0.5304 - val_accuracy: 0.7448\n",
      "Epoch 968/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4011 - accuracy: 0.8090 - val_loss: 0.5304 - val_accuracy: 0.7448\n",
      "Epoch 969/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4011 - accuracy: 0.8108 - val_loss: 0.5304 - val_accuracy: 0.7448\n",
      "Epoch 970/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4011 - accuracy: 0.8108 - val_loss: 0.5304 - val_accuracy: 0.7448\n",
      "Epoch 971/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4011 - accuracy: 0.8108 - val_loss: 0.5304 - val_accuracy: 0.7448\n",
      "Epoch 972/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4011 - accuracy: 0.8090 - val_loss: 0.5304 - val_accuracy: 0.7448\n",
      "Epoch 973/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4011 - accuracy: 0.8108 - val_loss: 0.5305 - val_accuracy: 0.7448\n",
      "Epoch 974/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4011 - accuracy: 0.8108 - val_loss: 0.5304 - val_accuracy: 0.7448\n",
      "Epoch 975/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4011 - accuracy: 0.8090 - val_loss: 0.5304 - val_accuracy: 0.7448\n",
      "Epoch 976/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4011 - accuracy: 0.8125 - val_loss: 0.5304 - val_accuracy: 0.7448\n",
      "Epoch 977/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4011 - accuracy: 0.8108 - val_loss: 0.5304 - val_accuracy: 0.7448\n",
      "Epoch 978/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4010 - accuracy: 0.8108 - val_loss: 0.5305 - val_accuracy: 0.7448\n",
      "Epoch 979/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4011 - accuracy: 0.8125 - val_loss: 0.5305 - val_accuracy: 0.7448\n",
      "Epoch 980/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4010 - accuracy: 0.8108 - val_loss: 0.5305 - val_accuracy: 0.7448\n",
      "Epoch 981/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4010 - accuracy: 0.8108 - val_loss: 0.5305 - val_accuracy: 0.7448\n",
      "Epoch 982/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4010 - accuracy: 0.8108 - val_loss: 0.5305 - val_accuracy: 0.7448\n",
      "Epoch 983/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4010 - accuracy: 0.8108 - val_loss: 0.5305 - val_accuracy: 0.7448\n",
      "Epoch 984/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4010 - accuracy: 0.8108 - val_loss: 0.5305 - val_accuracy: 0.7448\n",
      "Epoch 985/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4010 - accuracy: 0.8108 - val_loss: 0.5306 - val_accuracy: 0.7448\n",
      "Epoch 986/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4010 - accuracy: 0.8125 - val_loss: 0.5306 - val_accuracy: 0.7448\n",
      "Epoch 987/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4011 - accuracy: 0.8090 - val_loss: 0.5306 - val_accuracy: 0.7448\n",
      "Epoch 988/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4010 - accuracy: 0.8108 - val_loss: 0.5306 - val_accuracy: 0.7448\n",
      "Epoch 989/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4010 - accuracy: 0.8108 - val_loss: 0.5306 - val_accuracy: 0.7448\n",
      "Epoch 990/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4010 - accuracy: 0.8090 - val_loss: 0.5306 - val_accuracy: 0.7448\n",
      "Epoch 991/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4010 - accuracy: 0.8108 - val_loss: 0.5306 - val_accuracy: 0.7448\n",
      "Epoch 992/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4010 - accuracy: 0.8108 - val_loss: 0.5306 - val_accuracy: 0.7448\n",
      "Epoch 993/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4009 - accuracy: 0.8090 - val_loss: 0.5306 - val_accuracy: 0.7448\n",
      "Epoch 994/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4010 - accuracy: 0.8142 - val_loss: 0.5307 - val_accuracy: 0.7448\n",
      "Epoch 995/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4010 - accuracy: 0.8108 - val_loss: 0.5307 - val_accuracy: 0.7448\n",
      "Epoch 996/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4009 - accuracy: 0.8108 - val_loss: 0.5307 - val_accuracy: 0.7448\n",
      "Epoch 997/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4009 - accuracy: 0.8073 - val_loss: 0.5307 - val_accuracy: 0.7448\n",
      "Epoch 998/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4010 - accuracy: 0.8108 - val_loss: 0.5307 - val_accuracy: 0.7448\n",
      "Epoch 999/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4009 - accuracy: 0.8108 - val_loss: 0.5307 - val_accuracy: 0.7448\n",
      "Epoch 1000/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4009 - accuracy: 0.8108 - val_loss: 0.5307 - val_accuracy: 0.7448\n",
      "Epoch 1001/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4010 - accuracy: 0.8108 - val_loss: 0.5307 - val_accuracy: 0.7448\n",
      "Epoch 1002/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4009 - accuracy: 0.8108 - val_loss: 0.5307 - val_accuracy: 0.7448\n",
      "Epoch 1003/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4010 - accuracy: 0.8142 - val_loss: 0.5307 - val_accuracy: 0.7448\n",
      "Epoch 1004/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4010 - accuracy: 0.8108 - val_loss: 0.5308 - val_accuracy: 0.7448\n",
      "Epoch 1005/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4010 - accuracy: 0.8090 - val_loss: 0.5308 - val_accuracy: 0.7448\n",
      "Epoch 1006/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4009 - accuracy: 0.8090 - val_loss: 0.5308 - val_accuracy: 0.7448\n",
      "Epoch 1007/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4009 - accuracy: 0.8125 - val_loss: 0.5307 - val_accuracy: 0.7448\n",
      "Epoch 1008/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4009 - accuracy: 0.8108 - val_loss: 0.5308 - val_accuracy: 0.7448\n",
      "Epoch 1009/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4009 - accuracy: 0.8108 - val_loss: 0.5308 - val_accuracy: 0.7448\n",
      "Epoch 1010/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4009 - accuracy: 0.8125 - val_loss: 0.5308 - val_accuracy: 0.7448\n",
      "Epoch 1011/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4008 - accuracy: 0.8090 - val_loss: 0.5308 - val_accuracy: 0.7448\n",
      "Epoch 1012/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4009 - accuracy: 0.8108 - val_loss: 0.5308 - val_accuracy: 0.7448\n",
      "Epoch 1013/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4008 - accuracy: 0.8125 - val_loss: 0.5308 - val_accuracy: 0.7448\n",
      "Epoch 1014/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4009 - accuracy: 0.8125 - val_loss: 0.5309 - val_accuracy: 0.7448\n",
      "Epoch 1015/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4010 - accuracy: 0.8108 - val_loss: 0.5308 - val_accuracy: 0.7448\n",
      "Epoch 1016/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4009 - accuracy: 0.8108 - val_loss: 0.5309 - val_accuracy: 0.7448\n",
      "Epoch 1017/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4008 - accuracy: 0.8108 - val_loss: 0.5309 - val_accuracy: 0.7448\n",
      "Epoch 1018/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4009 - accuracy: 0.8108 - val_loss: 0.5309 - val_accuracy: 0.7448\n",
      "Epoch 1019/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4008 - accuracy: 0.8125 - val_loss: 0.5309 - val_accuracy: 0.7448\n",
      "Epoch 1020/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4008 - accuracy: 0.8108 - val_loss: 0.5309 - val_accuracy: 0.7448\n",
      "Epoch 1021/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4009 - accuracy: 0.8142 - val_loss: 0.5309 - val_accuracy: 0.7448\n",
      "Epoch 1022/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4008 - accuracy: 0.8125 - val_loss: 0.5309 - val_accuracy: 0.7448\n",
      "Epoch 1023/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4008 - accuracy: 0.8090 - val_loss: 0.5309 - val_accuracy: 0.7448\n",
      "Epoch 1024/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4008 - accuracy: 0.8142 - val_loss: 0.5309 - val_accuracy: 0.7448\n",
      "Epoch 1025/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4008 - accuracy: 0.8125 - val_loss: 0.5309 - val_accuracy: 0.7448\n",
      "Epoch 1026/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4008 - accuracy: 0.8125 - val_loss: 0.5310 - val_accuracy: 0.7448\n",
      "Epoch 1027/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4009 - accuracy: 0.8125 - val_loss: 0.5310 - val_accuracy: 0.7448\n",
      "Epoch 1028/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4008 - accuracy: 0.8142 - val_loss: 0.5310 - val_accuracy: 0.7448\n",
      "Epoch 1029/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4008 - accuracy: 0.8125 - val_loss: 0.5310 - val_accuracy: 0.7448\n",
      "Epoch 1030/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4008 - accuracy: 0.8142 - val_loss: 0.5310 - val_accuracy: 0.7448\n",
      "Epoch 1031/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4009 - accuracy: 0.8125 - val_loss: 0.5310 - val_accuracy: 0.7448\n",
      "Epoch 1032/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4008 - accuracy: 0.8108 - val_loss: 0.5310 - val_accuracy: 0.7448\n",
      "Epoch 1033/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4008 - accuracy: 0.8108 - val_loss: 0.5310 - val_accuracy: 0.7448\n",
      "Epoch 1034/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4007 - accuracy: 0.8108 - val_loss: 0.5310 - val_accuracy: 0.7448\n",
      "Epoch 1035/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4007 - accuracy: 0.8108 - val_loss: 0.5310 - val_accuracy: 0.7448\n",
      "Epoch 1036/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4008 - accuracy: 0.8125 - val_loss: 0.5310 - val_accuracy: 0.7448\n",
      "Epoch 1037/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4008 - accuracy: 0.8125 - val_loss: 0.5310 - val_accuracy: 0.7448\n",
      "Epoch 1038/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4007 - accuracy: 0.8125 - val_loss: 0.5310 - val_accuracy: 0.7448\n",
      "Epoch 1039/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4008 - accuracy: 0.8108 - val_loss: 0.5310 - val_accuracy: 0.7448\n",
      "Epoch 1040/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4007 - accuracy: 0.8125 - val_loss: 0.5310 - val_accuracy: 0.7448\n",
      "Epoch 1041/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4008 - accuracy: 0.8108 - val_loss: 0.5310 - val_accuracy: 0.7448\n",
      "Epoch 1042/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4007 - accuracy: 0.8125 - val_loss: 0.5310 - val_accuracy: 0.7448\n",
      "Epoch 1043/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4007 - accuracy: 0.8125 - val_loss: 0.5311 - val_accuracy: 0.7448\n",
      "Epoch 1044/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4007 - accuracy: 0.8108 - val_loss: 0.5311 - val_accuracy: 0.7448\n",
      "Epoch 1045/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4008 - accuracy: 0.8125 - val_loss: 0.5311 - val_accuracy: 0.7448\n",
      "Epoch 1046/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4007 - accuracy: 0.8125 - val_loss: 0.5311 - val_accuracy: 0.7448\n",
      "Epoch 1047/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4007 - accuracy: 0.8108 - val_loss: 0.5311 - val_accuracy: 0.7448\n",
      "Epoch 1048/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4006 - accuracy: 0.8108 - val_loss: 0.5311 - val_accuracy: 0.7448\n",
      "Epoch 1049/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4007 - accuracy: 0.8125 - val_loss: 0.5311 - val_accuracy: 0.7448\n",
      "Epoch 1050/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4007 - accuracy: 0.8125 - val_loss: 0.5311 - val_accuracy: 0.7448\n",
      "Epoch 1051/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4007 - accuracy: 0.8108 - val_loss: 0.5311 - val_accuracy: 0.7448\n",
      "Epoch 1052/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4007 - accuracy: 0.8108 - val_loss: 0.5311 - val_accuracy: 0.7448\n",
      "Epoch 1053/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4007 - accuracy: 0.8125 - val_loss: 0.5311 - val_accuracy: 0.7448\n",
      "Epoch 1054/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4007 - accuracy: 0.8142 - val_loss: 0.5311 - val_accuracy: 0.7448\n",
      "Epoch 1055/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4007 - accuracy: 0.8125 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
      "Epoch 1056/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4006 - accuracy: 0.8108 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
      "Epoch 1057/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4006 - accuracy: 0.8090 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
      "Epoch 1058/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4006 - accuracy: 0.8125 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
      "Epoch 1059/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4006 - accuracy: 0.8142 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
      "Epoch 1060/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4006 - accuracy: 0.8108 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
      "Epoch 1061/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4007 - accuracy: 0.8142 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
      "Epoch 1062/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4006 - accuracy: 0.8108 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 1063/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 36us/step - loss: 0.4006 - accuracy: 0.8125 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
      "Epoch 1064/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4006 - accuracy: 0.8108 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
      "Epoch 1065/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4005 - accuracy: 0.8108 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
      "Epoch 1066/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4006 - accuracy: 0.8108 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 1067/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4006 - accuracy: 0.8108 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
      "Epoch 1068/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4005 - accuracy: 0.8108 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
      "Epoch 1069/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4006 - accuracy: 0.8108 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
      "Epoch 1070/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4005 - accuracy: 0.8125 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
      "Epoch 1071/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4006 - accuracy: 0.8108 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 1072/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4006 - accuracy: 0.8125 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 1073/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4007 - accuracy: 0.8125 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 1074/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4005 - accuracy: 0.8125 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 1075/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4005 - accuracy: 0.8125 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 1076/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4005 - accuracy: 0.8142 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 1077/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4005 - accuracy: 0.8108 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 1078/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4005 - accuracy: 0.8125 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 1079/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4005 - accuracy: 0.8142 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 1080/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4006 - accuracy: 0.8125 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 1081/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4006 - accuracy: 0.8142 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 1082/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4005 - accuracy: 0.8125 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 1083/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4005 - accuracy: 0.8125 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 1084/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4005 - accuracy: 0.8125 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 1085/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4005 - accuracy: 0.8125 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 1086/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4005 - accuracy: 0.8108 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 1087/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4005 - accuracy: 0.8125 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 1088/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4005 - accuracy: 0.8125 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 1089/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4005 - accuracy: 0.8125 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1090/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4005 - accuracy: 0.8108 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1091/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4005 - accuracy: 0.8125 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 1092/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4004 - accuracy: 0.8108 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 1093/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4005 - accuracy: 0.8108 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1094/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4004 - accuracy: 0.8108 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1095/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4004 - accuracy: 0.8125 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1096/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4004 - accuracy: 0.8125 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1097/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4005 - accuracy: 0.8125 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1098/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4005 - accuracy: 0.8108 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1099/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4005 - accuracy: 0.8142 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1100/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4005 - accuracy: 0.8125 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1101/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4005 - accuracy: 0.8108 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1102/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4004 - accuracy: 0.8125 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1103/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4004 - accuracy: 0.8125 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1104/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4004 - accuracy: 0.8108 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1105/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4004 - accuracy: 0.8125 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1106/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4005 - accuracy: 0.8125 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1107/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4004 - accuracy: 0.8108 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1108/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4004 - accuracy: 0.8125 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1109/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4004 - accuracy: 0.8125 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1110/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4003 - accuracy: 0.8108 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1111/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4004 - accuracy: 0.8108 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1112/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4004 - accuracy: 0.8108 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1113/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4005 - accuracy: 0.8125 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 1114/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4004 - accuracy: 0.8125 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 1115/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4003 - accuracy: 0.8125 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 1116/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4003 - accuracy: 0.8125 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 1117/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4003 - accuracy: 0.8108 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 1118/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4003 - accuracy: 0.8125 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 1119/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4003 - accuracy: 0.8125 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 1120/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4003 - accuracy: 0.8125 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 1121/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4003 - accuracy: 0.8125 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 1122/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4003 - accuracy: 0.8108 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 1123/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4003 - accuracy: 0.8125 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 1124/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4004 - accuracy: 0.8125 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 1125/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4002 - accuracy: 0.8142 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 1126/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4004 - accuracy: 0.8125 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 1127/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4003 - accuracy: 0.8125 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 1128/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4003 - accuracy: 0.8125 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 1129/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4003 - accuracy: 0.8125 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 1130/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4003 - accuracy: 0.8125 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 1131/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4001 - accuracy: 0.8125 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 1132/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4002 - accuracy: 0.8125 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 1133/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4003 - accuracy: 0.8125 - val_loss: 0.5316 - val_accuracy: 0.7448\n",
      "Epoch 1134/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4002 - accuracy: 0.8125 - val_loss: 0.5316 - val_accuracy: 0.7448\n",
      "Epoch 1135/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4002 - accuracy: 0.8125 - val_loss: 0.5316 - val_accuracy: 0.7448\n",
      "Epoch 1136/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4002 - accuracy: 0.8142 - val_loss: 0.5316 - val_accuracy: 0.7448\n",
      "Epoch 1137/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4003 - accuracy: 0.8125 - val_loss: 0.5316 - val_accuracy: 0.7448\n",
      "Epoch 1138/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4002 - accuracy: 0.8125 - val_loss: 0.5316 - val_accuracy: 0.7448\n",
      "Epoch 1139/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4003 - accuracy: 0.8125 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 1140/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4002 - accuracy: 0.8108 - val_loss: 0.5316 - val_accuracy: 0.7448\n",
      "Epoch 1141/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4002 - accuracy: 0.8125 - val_loss: 0.5316 - val_accuracy: 0.7448\n",
      "Epoch 1142/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4002 - accuracy: 0.8125 - val_loss: 0.5316 - val_accuracy: 0.7448\n",
      "Epoch 1143/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4002 - accuracy: 0.8125 - val_loss: 0.5316 - val_accuracy: 0.7448\n",
      "Epoch 1144/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4002 - accuracy: 0.8142 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 1145/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4002 - accuracy: 0.8125 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 1146/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4002 - accuracy: 0.8125 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 1147/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4002 - accuracy: 0.8125 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 1148/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4002 - accuracy: 0.8142 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 1149/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4002 - accuracy: 0.8108 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 1150/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4002 - accuracy: 0.8125 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 1151/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4001 - accuracy: 0.8142 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 1152/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4002 - accuracy: 0.8125 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 1153/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4002 - accuracy: 0.8125 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 1154/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4001 - accuracy: 0.8125 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 1155/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4001 - accuracy: 0.8125 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 1156/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4001 - accuracy: 0.8125 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 1157/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4001 - accuracy: 0.8125 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 1158/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4002 - accuracy: 0.8142 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 1159/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4002 - accuracy: 0.8125 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 1160/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4001 - accuracy: 0.8125 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 1161/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 1162/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4000 - accuracy: 0.8142 - val_loss: 0.5318 - val_accuracy: 0.7448\n",
      "Epoch 1163/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5318 - val_accuracy: 0.7448\n",
      "Epoch 1164/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4001 - accuracy: 0.8125 - val_loss: 0.5318 - val_accuracy: 0.7448\n",
      "Epoch 1165/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4001 - accuracy: 0.8125 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 1166/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4000 - accuracy: 0.8142 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 1167/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4001 - accuracy: 0.8125 - val_loss: 0.5318 - val_accuracy: 0.7448\n",
      "Epoch 1168/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4002 - accuracy: 0.8125 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 1169/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5318 - val_accuracy: 0.7448\n",
      "Epoch 1170/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4001 - accuracy: 0.8125 - val_loss: 0.5318 - val_accuracy: 0.7448\n",
      "Epoch 1171/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4001 - accuracy: 0.8108 - val_loss: 0.5318 - val_accuracy: 0.7448\n",
      "Epoch 1172/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4001 - accuracy: 0.8125 - val_loss: 0.5318 - val_accuracy: 0.7448\n",
      "Epoch 1173/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 36us/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5318 - val_accuracy: 0.7448\n",
      "Epoch 1174/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4000 - accuracy: 0.8142 - val_loss: 0.5318 - val_accuracy: 0.7448\n",
      "Epoch 1175/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4001 - accuracy: 0.8142 - val_loss: 0.5318 - val_accuracy: 0.7448\n",
      "Epoch 1176/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4000 - accuracy: 0.8108 - val_loss: 0.5318 - val_accuracy: 0.7448\n",
      "Epoch 1177/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5318 - val_accuracy: 0.7448\n",
      "Epoch 1178/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5319 - val_accuracy: 0.7448\n",
      "Epoch 1179/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5319 - val_accuracy: 0.7448\n",
      "Epoch 1180/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5319 - val_accuracy: 0.7448\n",
      "Epoch 1181/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5319 - val_accuracy: 0.7448\n",
      "Epoch 1182/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3999 - accuracy: 0.8125 - val_loss: 0.5319 - val_accuracy: 0.7448\n",
      "Epoch 1183/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5319 - val_accuracy: 0.7448\n",
      "Epoch 1184/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5319 - val_accuracy: 0.7448\n",
      "Epoch 1185/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1186/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1187/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4001 - accuracy: 0.8125 - val_loss: 0.5319 - val_accuracy: 0.7448\n",
      "Epoch 1188/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3999 - accuracy: 0.8125 - val_loss: 0.5319 - val_accuracy: 0.7448\n",
      "Epoch 1189/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5319 - val_accuracy: 0.7448\n",
      "Epoch 1190/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5319 - val_accuracy: 0.7448\n",
      "Epoch 1191/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5319 - val_accuracy: 0.7448\n",
      "Epoch 1192/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3999 - accuracy: 0.8125 - val_loss: 0.5319 - val_accuracy: 0.7448\n",
      "Epoch 1193/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1194/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3999 - accuracy: 0.8125 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1195/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1196/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3999 - accuracy: 0.8125 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1197/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4000 - accuracy: 0.8108 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1198/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3999 - accuracy: 0.8142 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1199/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3999 - accuracy: 0.8125 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1200/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3999 - accuracy: 0.8125 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1201/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5319 - val_accuracy: 0.7448\n",
      "Epoch 1202/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4000 - accuracy: 0.8142 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1203/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3999 - accuracy: 0.8125 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1204/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3999 - accuracy: 0.8142 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1205/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1206/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3998 - accuracy: 0.8142 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1207/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3999 - accuracy: 0.8125 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1208/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1209/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3998 - accuracy: 0.8125 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1210/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3999 - accuracy: 0.8108 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1211/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3998 - accuracy: 0.8125 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1212/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3999 - accuracy: 0.8125 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1213/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3999 - accuracy: 0.8125 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1214/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3999 - accuracy: 0.8142 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1215/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3999 - accuracy: 0.8125 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1216/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3998 - accuracy: 0.8125 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1217/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3997 - accuracy: 0.8125 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1218/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3998 - accuracy: 0.8125 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1219/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3998 - accuracy: 0.8108 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1220/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3998 - accuracy: 0.8125 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1221/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3999 - accuracy: 0.8125 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1222/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3998 - accuracy: 0.8125 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1223/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3998 - accuracy: 0.8142 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1224/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3998 - accuracy: 0.8125 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1225/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3997 - accuracy: 0.8125 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 1226/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3998 - accuracy: 0.8125 - val_loss: 0.5321 - val_accuracy: 0.7448\n",
      "Epoch 1227/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3998 - accuracy: 0.8125 - val_loss: 0.5321 - val_accuracy: 0.7448\n",
      "Epoch 1228/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3998 - accuracy: 0.8125 - val_loss: 0.5321 - val_accuracy: 0.7448\n",
      "Epoch 1229/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3998 - accuracy: 0.8125 - val_loss: 0.5321 - val_accuracy: 0.7448\n",
      "Epoch 1230/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3997 - accuracy: 0.8125 - val_loss: 0.5321 - val_accuracy: 0.7448\n",
      "Epoch 1231/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3997 - accuracy: 0.8125 - val_loss: 0.5321 - val_accuracy: 0.7448\n",
      "Epoch 1232/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3997 - accuracy: 0.8125 - val_loss: 0.5321 - val_accuracy: 0.7448\n",
      "Epoch 1233/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3998 - accuracy: 0.8125 - val_loss: 0.5321 - val_accuracy: 0.7448\n",
      "Epoch 1234/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3996 - accuracy: 0.8142 - val_loss: 0.5321 - val_accuracy: 0.7448\n",
      "Epoch 1235/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3997 - accuracy: 0.8125 - val_loss: 0.5321 - val_accuracy: 0.7448\n",
      "Epoch 1236/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3997 - accuracy: 0.8142 - val_loss: 0.5321 - val_accuracy: 0.7448\n",
      "Epoch 1237/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3997 - accuracy: 0.8125 - val_loss: 0.5321 - val_accuracy: 0.7448\n",
      "Epoch 1238/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3997 - accuracy: 0.8125 - val_loss: 0.5321 - val_accuracy: 0.7448\n",
      "Epoch 1239/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3997 - accuracy: 0.8125 - val_loss: 0.5321 - val_accuracy: 0.7448\n",
      "Epoch 1240/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3997 - accuracy: 0.8125 - val_loss: 0.5322 - val_accuracy: 0.7448\n",
      "Epoch 1241/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3997 - accuracy: 0.8125 - val_loss: 0.5321 - val_accuracy: 0.7448\n",
      "Epoch 1242/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3999 - accuracy: 0.8125 - val_loss: 0.5322 - val_accuracy: 0.7448\n",
      "Epoch 1243/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3997 - accuracy: 0.8125 - val_loss: 0.5322 - val_accuracy: 0.7448\n",
      "Epoch 1244/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3997 - accuracy: 0.8125 - val_loss: 0.5322 - val_accuracy: 0.7448\n",
      "Epoch 1245/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3997 - accuracy: 0.8142 - val_loss: 0.5322 - val_accuracy: 0.7448\n",
      "Epoch 1246/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3996 - accuracy: 0.8142 - val_loss: 0.5322 - val_accuracy: 0.7448\n",
      "Epoch 1247/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3996 - accuracy: 0.8125 - val_loss: 0.5322 - val_accuracy: 0.7448\n",
      "Epoch 1248/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3996 - accuracy: 0.8125 - val_loss: 0.5323 - val_accuracy: 0.7448\n",
      "Epoch 1249/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3998 - accuracy: 0.8125 - val_loss: 0.5323 - val_accuracy: 0.7448\n",
      "Epoch 1250/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3996 - accuracy: 0.8125 - val_loss: 0.5323 - val_accuracy: 0.7448\n",
      "Epoch 1251/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3997 - accuracy: 0.8142 - val_loss: 0.5323 - val_accuracy: 0.7448\n",
      "Epoch 1252/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3996 - accuracy: 0.8125 - val_loss: 0.5324 - val_accuracy: 0.7448\n",
      "Epoch 1253/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3996 - accuracy: 0.8142 - val_loss: 0.5324 - val_accuracy: 0.7448\n",
      "Epoch 1254/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3996 - accuracy: 0.8125 - val_loss: 0.5324 - val_accuracy: 0.7448\n",
      "Epoch 1255/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3997 - accuracy: 0.8125 - val_loss: 0.5324 - val_accuracy: 0.7448\n",
      "Epoch 1256/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3997 - accuracy: 0.8142 - val_loss: 0.5324 - val_accuracy: 0.7448\n",
      "Epoch 1257/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3996 - accuracy: 0.8125 - val_loss: 0.5324 - val_accuracy: 0.7448\n",
      "Epoch 1258/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3996 - accuracy: 0.8142 - val_loss: 0.5324 - val_accuracy: 0.7448\n",
      "Epoch 1259/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3996 - accuracy: 0.8142 - val_loss: 0.5324 - val_accuracy: 0.7448\n",
      "Epoch 1260/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3995 - accuracy: 0.8142 - val_loss: 0.5325 - val_accuracy: 0.7448\n",
      "Epoch 1261/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3996 - accuracy: 0.8125 - val_loss: 0.5324 - val_accuracy: 0.7448\n",
      "Epoch 1262/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3995 - accuracy: 0.8125 - val_loss: 0.5324 - val_accuracy: 0.7448\n",
      "Epoch 1263/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3996 - accuracy: 0.8142 - val_loss: 0.5325 - val_accuracy: 0.7448\n",
      "Epoch 1264/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3995 - accuracy: 0.8142 - val_loss: 0.5325 - val_accuracy: 0.7448\n",
      "Epoch 1265/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3996 - accuracy: 0.8142 - val_loss: 0.5325 - val_accuracy: 0.7448\n",
      "Epoch 1266/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3996 - accuracy: 0.8125 - val_loss: 0.5325 - val_accuracy: 0.7448\n",
      "Epoch 1267/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3997 - accuracy: 0.8125 - val_loss: 0.5325 - val_accuracy: 0.7448\n",
      "Epoch 1268/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3995 - accuracy: 0.8125 - val_loss: 0.5325 - val_accuracy: 0.7448\n",
      "Epoch 1269/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3996 - accuracy: 0.8125 - val_loss: 0.5325 - val_accuracy: 0.7448\n",
      "Epoch 1270/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3995 - accuracy: 0.8142 - val_loss: 0.5325 - val_accuracy: 0.7448\n",
      "Epoch 1271/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3995 - accuracy: 0.8142 - val_loss: 0.5325 - val_accuracy: 0.7448\n",
      "Epoch 1272/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3995 - accuracy: 0.8125 - val_loss: 0.5325 - val_accuracy: 0.7448\n",
      "Epoch 1273/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3995 - accuracy: 0.8160 - val_loss: 0.5326 - val_accuracy: 0.7448\n",
      "Epoch 1274/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3995 - accuracy: 0.8142 - val_loss: 0.5326 - val_accuracy: 0.7448\n",
      "Epoch 1275/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3994 - accuracy: 0.8142 - val_loss: 0.5326 - val_accuracy: 0.7448\n",
      "Epoch 1276/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3995 - accuracy: 0.8142 - val_loss: 0.5326 - val_accuracy: 0.7448\n",
      "Epoch 1277/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3995 - accuracy: 0.8160 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
      "Epoch 1278/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3995 - accuracy: 0.8125 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
      "Epoch 1279/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3994 - accuracy: 0.8125 - val_loss: 0.5326 - val_accuracy: 0.7448\n",
      "Epoch 1280/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3995 - accuracy: 0.8142 - val_loss: 0.5326 - val_accuracy: 0.7448\n",
      "Epoch 1281/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3995 - accuracy: 0.8142 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
      "Epoch 1282/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3995 - accuracy: 0.8142 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
      "Epoch 1283/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 33us/step - loss: 0.3995 - accuracy: 0.8142 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
      "Epoch 1284/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3995 - accuracy: 0.8125 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
      "Epoch 1285/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3994 - accuracy: 0.8125 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
      "Epoch 1286/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3994 - accuracy: 0.8160 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
      "Epoch 1287/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3994 - accuracy: 0.8142 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
      "Epoch 1288/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3993 - accuracy: 0.8125 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
      "Epoch 1289/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3995 - accuracy: 0.8160 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
      "Epoch 1290/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3994 - accuracy: 0.8142 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
      "Epoch 1291/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3994 - accuracy: 0.8142 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
      "Epoch 1292/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3995 - accuracy: 0.8160 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
      "Epoch 1293/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3994 - accuracy: 0.8142 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
      "Epoch 1294/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3994 - accuracy: 0.8160 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
      "Epoch 1295/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3994 - accuracy: 0.8125 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
      "Epoch 1296/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3994 - accuracy: 0.8160 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
      "Epoch 1297/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3994 - accuracy: 0.8142 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
      "Epoch 1298/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3994 - accuracy: 0.8160 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
      "Epoch 1299/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3993 - accuracy: 0.8160 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
      "Epoch 1300/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3994 - accuracy: 0.8160 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
      "Epoch 1301/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3994 - accuracy: 0.8160 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
      "Epoch 1302/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3994 - accuracy: 0.8160 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
      "Epoch 1303/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3993 - accuracy: 0.8160 - val_loss: 0.5329 - val_accuracy: 0.7448\n",
      "Epoch 1304/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3994 - accuracy: 0.8160 - val_loss: 0.5329 - val_accuracy: 0.7448\n",
      "Epoch 1305/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3993 - accuracy: 0.8160 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
      "Epoch 1306/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3993 - accuracy: 0.8160 - val_loss: 0.5329 - val_accuracy: 0.7448\n",
      "Epoch 1307/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3993 - accuracy: 0.8160 - val_loss: 0.5329 - val_accuracy: 0.7448\n",
      "Epoch 1308/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3993 - accuracy: 0.8160 - val_loss: 0.5329 - val_accuracy: 0.7448\n",
      "Epoch 1309/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3993 - accuracy: 0.8160 - val_loss: 0.5329 - val_accuracy: 0.7448\n",
      "Epoch 1310/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3993 - accuracy: 0.8160 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
      "Epoch 1311/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3993 - accuracy: 0.8160 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
      "Epoch 1312/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3992 - accuracy: 0.8160 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
      "Epoch 1313/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3992 - accuracy: 0.8142 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
      "Epoch 1314/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3992 - accuracy: 0.8160 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
      "Epoch 1315/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3993 - accuracy: 0.8160 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
      "Epoch 1316/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3993 - accuracy: 0.8160 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
      "Epoch 1317/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3992 - accuracy: 0.8160 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
      "Epoch 1318/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3992 - accuracy: 0.8160 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
      "Epoch 1319/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3991 - accuracy: 0.8160 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
      "Epoch 1320/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3992 - accuracy: 0.8160 - val_loss: 0.5331 - val_accuracy: 0.7448\n",
      "Epoch 1321/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3993 - accuracy: 0.8160 - val_loss: 0.5331 - val_accuracy: 0.7448\n",
      "Epoch 1322/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3992 - accuracy: 0.8160 - val_loss: 0.5331 - val_accuracy: 0.7448\n",
      "Epoch 1323/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3992 - accuracy: 0.8160 - val_loss: 0.5331 - val_accuracy: 0.7448\n",
      "Epoch 1324/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3991 - accuracy: 0.8160 - val_loss: 0.5331 - val_accuracy: 0.7448\n",
      "Epoch 1325/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3992 - accuracy: 0.8160 - val_loss: 0.5331 - val_accuracy: 0.7448\n",
      "Epoch 1326/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3992 - accuracy: 0.8160 - val_loss: 0.5332 - val_accuracy: 0.7448\n",
      "Epoch 1327/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3991 - accuracy: 0.8160 - val_loss: 0.5332 - val_accuracy: 0.7448\n",
      "Epoch 1328/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3992 - accuracy: 0.8160 - val_loss: 0.5332 - val_accuracy: 0.7448\n",
      "Epoch 1329/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3991 - accuracy: 0.8160 - val_loss: 0.5332 - val_accuracy: 0.7448\n",
      "Epoch 1330/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3991 - accuracy: 0.8160 - val_loss: 0.5333 - val_accuracy: 0.7448\n",
      "Epoch 1331/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3990 - accuracy: 0.8160 - val_loss: 0.5333 - val_accuracy: 0.7448\n",
      "Epoch 1332/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3991 - accuracy: 0.8160 - val_loss: 0.5333 - val_accuracy: 0.7448\n",
      "Epoch 1333/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3991 - accuracy: 0.8160 - val_loss: 0.5333 - val_accuracy: 0.7448\n",
      "Epoch 1334/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3991 - accuracy: 0.8160 - val_loss: 0.5333 - val_accuracy: 0.7448\n",
      "Epoch 1335/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3991 - accuracy: 0.8142 - val_loss: 0.5333 - val_accuracy: 0.7448\n",
      "Epoch 1336/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3991 - accuracy: 0.8160 - val_loss: 0.5333 - val_accuracy: 0.7448\n",
      "Epoch 1337/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3991 - accuracy: 0.8160 - val_loss: 0.5333 - val_accuracy: 0.7448\n",
      "Epoch 1338/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3990 - accuracy: 0.8160 - val_loss: 0.5333 - val_accuracy: 0.7448\n",
      "Epoch 1339/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3990 - accuracy: 0.8160 - val_loss: 0.5333 - val_accuracy: 0.7448\n",
      "Epoch 1340/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3991 - accuracy: 0.8160 - val_loss: 0.5334 - val_accuracy: 0.7448\n",
      "Epoch 1341/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3990 - accuracy: 0.8160 - val_loss: 0.5334 - val_accuracy: 0.7448\n",
      "Epoch 1342/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3991 - accuracy: 0.8160 - val_loss: 0.5334 - val_accuracy: 0.7448\n",
      "Epoch 1343/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3990 - accuracy: 0.8160 - val_loss: 0.5334 - val_accuracy: 0.7448\n",
      "Epoch 1344/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3990 - accuracy: 0.8160 - val_loss: 0.5334 - val_accuracy: 0.7448\n",
      "Epoch 1345/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3990 - accuracy: 0.8160 - val_loss: 0.5334 - val_accuracy: 0.7448\n",
      "Epoch 1346/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3990 - accuracy: 0.8160 - val_loss: 0.5335 - val_accuracy: 0.7448\n",
      "Epoch 1347/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3991 - accuracy: 0.8160 - val_loss: 0.5335 - val_accuracy: 0.7448\n",
      "Epoch 1348/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3990 - accuracy: 0.8160 - val_loss: 0.5335 - val_accuracy: 0.7448\n",
      "Epoch 1349/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3989 - accuracy: 0.8160 - val_loss: 0.5335 - val_accuracy: 0.7448\n",
      "Epoch 1350/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3989 - accuracy: 0.8160 - val_loss: 0.5335 - val_accuracy: 0.7448\n",
      "Epoch 1351/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3990 - accuracy: 0.8160 - val_loss: 0.5335 - val_accuracy: 0.7448\n",
      "Epoch 1352/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3991 - accuracy: 0.8160 - val_loss: 0.5335 - val_accuracy: 0.7448\n",
      "Epoch 1353/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3989 - accuracy: 0.8160 - val_loss: 0.5335 - val_accuracy: 0.7448\n",
      "Epoch 1354/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3990 - accuracy: 0.8160 - val_loss: 0.5335 - val_accuracy: 0.7448\n",
      "Epoch 1355/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3990 - accuracy: 0.8160 - val_loss: 0.5336 - val_accuracy: 0.7448\n",
      "Epoch 1356/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3989 - accuracy: 0.8160 - val_loss: 0.5336 - val_accuracy: 0.7448\n",
      "Epoch 1357/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3990 - accuracy: 0.8160 - val_loss: 0.5336 - val_accuracy: 0.7448\n",
      "Epoch 1358/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3990 - accuracy: 0.8160 - val_loss: 0.5337 - val_accuracy: 0.7448\n",
      "Epoch 1359/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3989 - accuracy: 0.8160 - val_loss: 0.5337 - val_accuracy: 0.7448\n",
      "Epoch 1360/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3989 - accuracy: 0.8142 - val_loss: 0.5336 - val_accuracy: 0.7448\n",
      "Epoch 1361/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3989 - accuracy: 0.8160 - val_loss: 0.5337 - val_accuracy: 0.7448\n",
      "Epoch 1362/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3988 - accuracy: 0.8160 - val_loss: 0.5336 - val_accuracy: 0.7448\n",
      "Epoch 1363/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3989 - accuracy: 0.8142 - val_loss: 0.5337 - val_accuracy: 0.7448\n",
      "Epoch 1364/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3989 - accuracy: 0.8160 - val_loss: 0.5337 - val_accuracy: 0.7448\n",
      "Epoch 1365/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3988 - accuracy: 0.8160 - val_loss: 0.5337 - val_accuracy: 0.7448\n",
      "Epoch 1366/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3988 - accuracy: 0.8160 - val_loss: 0.5337 - val_accuracy: 0.7448\n",
      "Epoch 1367/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3989 - accuracy: 0.8160 - val_loss: 0.5337 - val_accuracy: 0.7448\n",
      "Epoch 1368/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3989 - accuracy: 0.8160 - val_loss: 0.5338 - val_accuracy: 0.7448\n",
      "Epoch 1369/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3988 - accuracy: 0.8177 - val_loss: 0.5338 - val_accuracy: 0.7448\n",
      "Epoch 1370/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3988 - accuracy: 0.8177 - val_loss: 0.5338 - val_accuracy: 0.7448\n",
      "Epoch 1371/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3988 - accuracy: 0.8160 - val_loss: 0.5338 - val_accuracy: 0.7448\n",
      "Epoch 1372/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3987 - accuracy: 0.8160 - val_loss: 0.5338 - val_accuracy: 0.7448\n",
      "Epoch 1373/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3987 - accuracy: 0.8177 - val_loss: 0.5339 - val_accuracy: 0.7500\n",
      "Epoch 1374/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3987 - accuracy: 0.8160 - val_loss: 0.5339 - val_accuracy: 0.7448\n",
      "Epoch 1375/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3987 - accuracy: 0.8177 - val_loss: 0.5339 - val_accuracy: 0.7448\n",
      "Epoch 1376/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3988 - accuracy: 0.8160 - val_loss: 0.5339 - val_accuracy: 0.7448\n",
      "Epoch 1377/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3986 - accuracy: 0.8177 - val_loss: 0.5339 - val_accuracy: 0.7448\n",
      "Epoch 1378/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3988 - accuracy: 0.8177 - val_loss: 0.5339 - val_accuracy: 0.7448\n",
      "Epoch 1379/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3987 - accuracy: 0.8160 - val_loss: 0.5339 - val_accuracy: 0.7448\n",
      "Epoch 1380/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3987 - accuracy: 0.8160 - val_loss: 0.5340 - val_accuracy: 0.7500\n",
      "Epoch 1381/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3986 - accuracy: 0.8177 - val_loss: 0.5339 - val_accuracy: 0.7448\n",
      "Epoch 1382/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3986 - accuracy: 0.8177 - val_loss: 0.5340 - val_accuracy: 0.7500\n",
      "Epoch 1383/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3986 - accuracy: 0.8177 - val_loss: 0.5340 - val_accuracy: 0.7500\n",
      "Epoch 1384/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3987 - accuracy: 0.8160 - val_loss: 0.5340 - val_accuracy: 0.7500\n",
      "Epoch 1385/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3986 - accuracy: 0.8177 - val_loss: 0.5340 - val_accuracy: 0.7448\n",
      "Epoch 1386/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3986 - accuracy: 0.8160 - val_loss: 0.5340 - val_accuracy: 0.7500\n",
      "Epoch 1387/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3986 - accuracy: 0.8160 - val_loss: 0.5340 - val_accuracy: 0.7500\n",
      "Epoch 1388/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3987 - accuracy: 0.8177 - val_loss: 0.5341 - val_accuracy: 0.7500\n",
      "Epoch 1389/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3986 - accuracy: 0.8177 - val_loss: 0.5341 - val_accuracy: 0.7500\n",
      "Epoch 1390/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3985 - accuracy: 0.8160 - val_loss: 0.5341 - val_accuracy: 0.7500\n",
      "Epoch 1391/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3985 - accuracy: 0.8177 - val_loss: 0.5342 - val_accuracy: 0.7500\n",
      "Epoch 1392/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3985 - accuracy: 0.8177 - val_loss: 0.5342 - val_accuracy: 0.7500\n",
      "Epoch 1393/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 35us/step - loss: 0.3986 - accuracy: 0.8160 - val_loss: 0.5342 - val_accuracy: 0.7500\n",
      "Epoch 1394/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3986 - accuracy: 0.8177 - val_loss: 0.5342 - val_accuracy: 0.7500\n",
      "Epoch 1395/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3985 - accuracy: 0.8160 - val_loss: 0.5342 - val_accuracy: 0.7500\n",
      "Epoch 1396/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3985 - accuracy: 0.8177 - val_loss: 0.5342 - val_accuracy: 0.7500\n",
      "Epoch 1397/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3985 - accuracy: 0.8177 - val_loss: 0.5343 - val_accuracy: 0.7500\n",
      "Epoch 1398/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3986 - accuracy: 0.8160 - val_loss: 0.5343 - val_accuracy: 0.7500\n",
      "Epoch 1399/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3985 - accuracy: 0.8160 - val_loss: 0.5343 - val_accuracy: 0.7500\n",
      "Epoch 1400/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3985 - accuracy: 0.8194 - val_loss: 0.5343 - val_accuracy: 0.7500\n",
      "Epoch 1401/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3984 - accuracy: 0.8160 - val_loss: 0.5343 - val_accuracy: 0.7500\n",
      "Epoch 1402/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3984 - accuracy: 0.8160 - val_loss: 0.5343 - val_accuracy: 0.7500\n",
      "Epoch 1403/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3984 - accuracy: 0.8160 - val_loss: 0.5344 - val_accuracy: 0.7500\n",
      "Epoch 1404/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3983 - accuracy: 0.8160 - val_loss: 0.5344 - val_accuracy: 0.7500\n",
      "Epoch 1405/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3984 - accuracy: 0.8160 - val_loss: 0.5344 - val_accuracy: 0.7500\n",
      "Epoch 1406/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3984 - accuracy: 0.8160 - val_loss: 0.5344 - val_accuracy: 0.7500\n",
      "Epoch 1407/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3983 - accuracy: 0.8177 - val_loss: 0.5344 - val_accuracy: 0.7500\n",
      "Epoch 1408/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3983 - accuracy: 0.8160 - val_loss: 0.5345 - val_accuracy: 0.7500\n",
      "Epoch 1409/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3983 - accuracy: 0.8160 - val_loss: 0.5345 - val_accuracy: 0.7500\n",
      "Epoch 1410/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3983 - accuracy: 0.8160 - val_loss: 0.5345 - val_accuracy: 0.7500\n",
      "Epoch 1411/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3983 - accuracy: 0.8160 - val_loss: 0.5346 - val_accuracy: 0.7500\n",
      "Epoch 1412/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3982 - accuracy: 0.8160 - val_loss: 0.5346 - val_accuracy: 0.7500\n",
      "Epoch 1413/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3983 - accuracy: 0.8160 - val_loss: 0.5346 - val_accuracy: 0.7500\n",
      "Epoch 1414/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3982 - accuracy: 0.8160 - val_loss: 0.5346 - val_accuracy: 0.7500\n",
      "Epoch 1415/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3983 - accuracy: 0.8160 - val_loss: 0.5347 - val_accuracy: 0.7500\n",
      "Epoch 1416/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3982 - accuracy: 0.8160 - val_loss: 0.5347 - val_accuracy: 0.7500\n",
      "Epoch 1417/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3983 - accuracy: 0.8160 - val_loss: 0.5347 - val_accuracy: 0.7500\n",
      "Epoch 1418/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3982 - accuracy: 0.8160 - val_loss: 0.5347 - val_accuracy: 0.7500\n",
      "Epoch 1419/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3981 - accuracy: 0.8160 - val_loss: 0.5348 - val_accuracy: 0.7500\n",
      "Epoch 1420/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3982 - accuracy: 0.8160 - val_loss: 0.5348 - val_accuracy: 0.7500\n",
      "Epoch 1421/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3982 - accuracy: 0.8194 - val_loss: 0.5348 - val_accuracy: 0.7500\n",
      "Epoch 1422/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3981 - accuracy: 0.8160 - val_loss: 0.5348 - val_accuracy: 0.7500\n",
      "Epoch 1423/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3981 - accuracy: 0.8160 - val_loss: 0.5348 - val_accuracy: 0.7500\n",
      "Epoch 1424/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3981 - accuracy: 0.8160 - val_loss: 0.5348 - val_accuracy: 0.7500\n",
      "Epoch 1425/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3980 - accuracy: 0.8160 - val_loss: 0.5349 - val_accuracy: 0.7500\n",
      "Epoch 1426/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3980 - accuracy: 0.8177 - val_loss: 0.5349 - val_accuracy: 0.7500\n",
      "Epoch 1427/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3980 - accuracy: 0.8160 - val_loss: 0.5349 - val_accuracy: 0.7500\n",
      "Epoch 1428/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3981 - accuracy: 0.8160 - val_loss: 0.5349 - val_accuracy: 0.7500\n",
      "Epoch 1429/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3980 - accuracy: 0.8177 - val_loss: 0.5349 - val_accuracy: 0.7500\n",
      "Epoch 1430/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3981 - accuracy: 0.8160 - val_loss: 0.5350 - val_accuracy: 0.7500\n",
      "Epoch 1431/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3979 - accuracy: 0.8160 - val_loss: 0.5350 - val_accuracy: 0.7500\n",
      "Epoch 1432/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5274 - accuracy: 0.75 - 0s 33us/step - loss: 0.3980 - accuracy: 0.8160 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
      "Epoch 1433/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3979 - accuracy: 0.8177 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
      "Epoch 1434/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3979 - accuracy: 0.8177 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
      "Epoch 1435/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3979 - accuracy: 0.8177 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
      "Epoch 1436/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3980 - accuracy: 0.8177 - val_loss: 0.5352 - val_accuracy: 0.7500\n",
      "Epoch 1437/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3980 - accuracy: 0.8177 - val_loss: 0.5352 - val_accuracy: 0.7500\n",
      "Epoch 1438/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3978 - accuracy: 0.8177 - val_loss: 0.5352 - val_accuracy: 0.7500\n",
      "Epoch 1439/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3978 - accuracy: 0.8160 - val_loss: 0.5352 - val_accuracy: 0.7500\n",
      "Epoch 1440/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3979 - accuracy: 0.8160 - val_loss: 0.5352 - val_accuracy: 0.7500\n",
      "Epoch 1441/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3979 - accuracy: 0.8177 - val_loss: 0.5352 - val_accuracy: 0.7500\n",
      "Epoch 1442/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3978 - accuracy: 0.8160 - val_loss: 0.5353 - val_accuracy: 0.7500\n",
      "Epoch 1443/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3978 - accuracy: 0.8160 - val_loss: 0.5353 - val_accuracy: 0.7500\n",
      "Epoch 1444/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3978 - accuracy: 0.8177 - val_loss: 0.5353 - val_accuracy: 0.7500\n",
      "Epoch 1445/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3978 - accuracy: 0.8160 - val_loss: 0.5353 - val_accuracy: 0.7500\n",
      "Epoch 1446/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3977 - accuracy: 0.8177 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
      "Epoch 1447/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3977 - accuracy: 0.8177 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
      "Epoch 1448/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3977 - accuracy: 0.8177 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
      "Epoch 1449/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3977 - accuracy: 0.8160 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 1450/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3976 - accuracy: 0.8177 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 1451/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3978 - accuracy: 0.8177 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 1452/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3976 - accuracy: 0.8177 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 1453/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3976 - accuracy: 0.8177 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
      "Epoch 1454/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3977 - accuracy: 0.8177 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 1455/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3977 - accuracy: 0.8177 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 1456/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3976 - accuracy: 0.8177 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
      "Epoch 1457/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3976 - accuracy: 0.8160 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
      "Epoch 1458/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3975 - accuracy: 0.8177 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
      "Epoch 1459/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3976 - accuracy: 0.8160 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
      "Epoch 1460/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3977 - accuracy: 0.8160 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
      "Epoch 1461/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3974 - accuracy: 0.8177 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
      "Epoch 1462/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3977 - accuracy: 0.8194 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
      "Epoch 1463/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3975 - accuracy: 0.8177 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
      "Epoch 1464/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3975 - accuracy: 0.8177 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
      "Epoch 1465/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3975 - accuracy: 0.8177 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
      "Epoch 1466/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3975 - accuracy: 0.8194 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
      "Epoch 1467/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3974 - accuracy: 0.8194 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
      "Epoch 1468/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3974 - accuracy: 0.8177 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
      "Epoch 1469/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3974 - accuracy: 0.8194 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
      "Epoch 1470/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3974 - accuracy: 0.8160 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 1471/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3974 - accuracy: 0.8194 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 1472/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3973 - accuracy: 0.8194 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 1473/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3973 - accuracy: 0.8194 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 1474/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3974 - accuracy: 0.8194 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 1475/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3973 - accuracy: 0.8194 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 1476/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3973 - accuracy: 0.8212 - val_loss: 0.5356 - val_accuracy: 0.7500\n",
      "Epoch 1477/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3973 - accuracy: 0.8194 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 1478/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3972 - accuracy: 0.8194 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 1479/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3972 - accuracy: 0.8194 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 1480/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3972 - accuracy: 0.8194 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 1481/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3972 - accuracy: 0.8160 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 1482/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3972 - accuracy: 0.8194 - val_loss: 0.5356 - val_accuracy: 0.7500\n",
      "Epoch 1483/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3972 - accuracy: 0.8177 - val_loss: 0.5356 - val_accuracy: 0.7500\n",
      "Epoch 1484/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3972 - accuracy: 0.8194 - val_loss: 0.5356 - val_accuracy: 0.7500\n",
      "Epoch 1485/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3971 - accuracy: 0.8194 - val_loss: 0.5356 - val_accuracy: 0.7500\n",
      "Epoch 1486/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3972 - accuracy: 0.8194 - val_loss: 0.5356 - val_accuracy: 0.7500\n",
      "Epoch 1487/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3972 - accuracy: 0.8194 - val_loss: 0.5356 - val_accuracy: 0.7500\n",
      "Epoch 1488/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3971 - accuracy: 0.8194 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 1489/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3971 - accuracy: 0.8194 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 1490/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3970 - accuracy: 0.8194 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 1491/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3970 - accuracy: 0.8177 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 1492/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3971 - accuracy: 0.8194 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 1493/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3971 - accuracy: 0.8194 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 1494/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3969 - accuracy: 0.8212 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 1495/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3970 - accuracy: 0.8194 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 1496/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3970 - accuracy: 0.8212 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 1497/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3970 - accuracy: 0.8212 - val_loss: 0.5356 - val_accuracy: 0.7500\n",
      "Epoch 1498/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3969 - accuracy: 0.8194 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 1499/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3969 - accuracy: 0.8194 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 1500/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3969 - accuracy: 0.8194 - val_loss: 0.5356 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "model_student.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"]) # compiling the model and getting accuracy metrics\n",
    "run_hist_student= model_student.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs = 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_student.history.keys() # for my own purposes just to train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x21b900cb908>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_student.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_student.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "\n",
    "# losses still going down but seems to settle at around 0.4. Value loss is however increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class_nn_student = model_student.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_student = model_student.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_class_nn_student # getting view of predicted classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.88251615e-01],\n",
       "       [8.71926188e-01],\n",
       "       [3.99446845e-01],\n",
       "       [5.32833040e-02],\n",
       "       [1.54084057e-01],\n",
       "       [6.32225811e-01],\n",
       "       [1.39907598e-02],\n",
       "       [3.33203852e-01],\n",
       "       [9.11061406e-01],\n",
       "       [1.59324020e-01],\n",
       "       [2.52628922e-02],\n",
       "       [4.80701029e-02],\n",
       "       [8.54541957e-01],\n",
       "       [2.78702676e-02],\n",
       "       [9.06107545e-01],\n",
       "       [7.03934312e-01],\n",
       "       [5.33368587e-01],\n",
       "       [2.69754529e-01],\n",
       "       [9.19829130e-01],\n",
       "       [1.08952075e-01],\n",
       "       [3.43965024e-01],\n",
       "       [7.25075603e-03],\n",
       "       [1.76487118e-01],\n",
       "       [9.49058652e-01],\n",
       "       [7.35970438e-01],\n",
       "       [7.45358109e-01],\n",
       "       [9.08178091e-01],\n",
       "       [5.81291378e-01],\n",
       "       [3.07652652e-02],\n",
       "       [9.76920426e-01],\n",
       "       [1.67991370e-01],\n",
       "       [4.67354476e-01],\n",
       "       [1.03168398e-01],\n",
       "       [4.47079569e-01],\n",
       "       [2.97543794e-01],\n",
       "       [6.15961969e-01],\n",
       "       [9.39427018e-01],\n",
       "       [4.92034733e-01],\n",
       "       [2.54709840e-01],\n",
       "       [3.36990356e-01],\n",
       "       [8.89383495e-01],\n",
       "       [3.61149609e-01],\n",
       "       [7.74438977e-01],\n",
       "       [3.83644193e-01],\n",
       "       [6.34819269e-02],\n",
       "       [9.90119576e-02],\n",
       "       [3.05104911e-01],\n",
       "       [6.02718890e-02],\n",
       "       [2.56672502e-03],\n",
       "       [7.85625935e-01],\n",
       "       [7.83852458e-01],\n",
       "       [5.74815214e-01],\n",
       "       [9.14683640e-01],\n",
       "       [1.62359059e-01],\n",
       "       [5.12844920e-01],\n",
       "       [6.71331286e-02],\n",
       "       [2.92730927e-02],\n",
       "       [1.64914340e-01],\n",
       "       [4.57165509e-01],\n",
       "       [2.44076550e-02],\n",
       "       [3.31009328e-02],\n",
       "       [6.99513853e-02],\n",
       "       [8.22331309e-02],\n",
       "       [5.53554296e-03],\n",
       "       [8.44869018e-03],\n",
       "       [6.60690963e-01],\n",
       "       [4.75043058e-03],\n",
       "       [2.12723017e-03],\n",
       "       [1.08276904e-02],\n",
       "       [6.72223985e-01],\n",
       "       [9.59646940e-01],\n",
       "       [2.06679404e-02],\n",
       "       [2.61654258e-02],\n",
       "       [1.56098425e-01],\n",
       "       [7.66904831e-01],\n",
       "       [5.20764530e-01],\n",
       "       [2.97855765e-01],\n",
       "       [6.92552805e-01],\n",
       "       [3.24448287e-01],\n",
       "       [2.39100486e-01],\n",
       "       [9.54201102e-01],\n",
       "       [8.33281875e-03],\n",
       "       [4.53919172e-04],\n",
       "       [1.43001258e-01],\n",
       "       [6.55382693e-01],\n",
       "       [4.91806865e-03],\n",
       "       [2.07945764e-01],\n",
       "       [7.55775154e-01],\n",
       "       [5.28582096e-01],\n",
       "       [4.92868215e-01],\n",
       "       [8.46481323e-03],\n",
       "       [3.05462182e-02],\n",
       "       [9.16265845e-01],\n",
       "       [7.48866796e-01],\n",
       "       [7.56558836e-01],\n",
       "       [2.15813220e-02],\n",
       "       [2.41314888e-01],\n",
       "       [4.05332327e-01],\n",
       "       [4.78067696e-02],\n",
       "       [4.97135669e-01],\n",
       "       [1.09528661e-01],\n",
       "       [4.38153744e-03],\n",
       "       [2.11759537e-01],\n",
       "       [4.55674767e-01],\n",
       "       [2.85148680e-01],\n",
       "       [2.08547801e-01],\n",
       "       [3.29664052e-02],\n",
       "       [2.43904293e-02],\n",
       "       [2.44067103e-01],\n",
       "       [9.20907617e-01],\n",
       "       [1.23120695e-01],\n",
       "       [4.02842671e-01],\n",
       "       [2.99129188e-01],\n",
       "       [1.88306451e-01],\n",
       "       [8.64626765e-02],\n",
       "       [3.20822001e-03],\n",
       "       [7.11566508e-02],\n",
       "       [5.60108304e-01],\n",
       "       [4.72823083e-02],\n",
       "       [5.48353791e-03],\n",
       "       [2.71937072e-01],\n",
       "       [4.38562930e-02],\n",
       "       [7.27638841e-01],\n",
       "       [1.28074467e-01],\n",
       "       [8.62014472e-01],\n",
       "       [5.21850288e-01],\n",
       "       [3.72860640e-01],\n",
       "       [5.57600141e-01],\n",
       "       [3.40588957e-01],\n",
       "       [2.50037014e-02],\n",
       "       [9.43177104e-01],\n",
       "       [1.11170799e-01],\n",
       "       [4.90697682e-01],\n",
       "       [1.62198037e-01],\n",
       "       [1.65627569e-01],\n",
       "       [1.73043847e-01],\n",
       "       [1.10570818e-01],\n",
       "       [7.95192719e-02],\n",
       "       [2.29012966e-03],\n",
       "       [1.62042379e-02],\n",
       "       [1.01482123e-01],\n",
       "       [9.36748624e-01],\n",
       "       [9.75729465e-01],\n",
       "       [4.49097157e-02],\n",
       "       [5.67131639e-02],\n",
       "       [1.91496313e-02],\n",
       "       [1.30703241e-01],\n",
       "       [2.07232535e-02],\n",
       "       [9.35460329e-01],\n",
       "       [6.24733686e-01],\n",
       "       [2.12386131e-01],\n",
       "       [1.87708229e-01],\n",
       "       [1.61834478e-01],\n",
       "       [1.54466063e-01],\n",
       "       [3.26417685e-02],\n",
       "       [6.94190860e-02],\n",
       "       [2.62268662e-01],\n",
       "       [6.44907236e-01],\n",
       "       [2.69547254e-01],\n",
       "       [1.75642788e-01],\n",
       "       [4.77703631e-01],\n",
       "       [3.55699211e-01],\n",
       "       [3.55647802e-02],\n",
       "       [2.55173624e-01],\n",
       "       [4.82405394e-01],\n",
       "       [4.53127205e-01],\n",
       "       [1.73306763e-02],\n",
       "       [2.66965628e-01],\n",
       "       [1.20420188e-01],\n",
       "       [6.52396679e-02],\n",
       "       [8.51382017e-01],\n",
       "       [2.02855200e-01],\n",
       "       [5.49995720e-01],\n",
       "       [7.42679834e-03],\n",
       "       [7.23136306e-01],\n",
       "       [3.28996778e-03],\n",
       "       [5.73351979e-03],\n",
       "       [1.23462200e-01],\n",
       "       [6.13900244e-01],\n",
       "       [2.03063548e-01],\n",
       "       [8.01838160e-01],\n",
       "       [4.38564122e-02],\n",
       "       [1.26255840e-01],\n",
       "       [5.66102564e-02],\n",
       "       [3.89849782e-01],\n",
       "       [6.02561355e-01],\n",
       "       [3.49110365e-03],\n",
       "       [5.58047950e-01],\n",
       "       [6.54002070e-01],\n",
       "       [9.20985103e-01],\n",
       "       [9.14932251e-01],\n",
       "       [2.21245766e-01]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_student # getting view of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Type your code here to plot the loss accuracy and ROC curve\n",
    "plot_roc(y_test, y_pred_prob_nn_student, \"Exercise Model\") #plotting the ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x21b902437b8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_student.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_student.history[\"accuracy\"],'b', marker='.', label=\"Accuracy\")\n",
    "ax.legend()\n",
    "# due to more hidden layers loss as settled at 0.4 and accuracy also settled at 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.750\n",
      "roc-auc is 0.801\n"
     ]
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_student)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_student)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
